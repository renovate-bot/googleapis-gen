// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: google/cloud/dialogflow/cx/v3/audio_config.proto
// </auto-generated>
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Dialogflow.Cx.V3 {

  /// <summary>Holder for reflection information generated from google/cloud/dialogflow/cx/v3/audio_config.proto</summary>
  public static partial class AudioConfigReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/dialogflow/cx/v3/audio_config.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static AudioConfigReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "CjBnb29nbGUvY2xvdWQvZGlhbG9nZmxvdy9jeC92My9hdWRpb19jb25maWcu",
            "cHJvdG8SHWdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LmN4LnYzGh9nb29nbGUv",
            "YXBpL2ZpZWxkX2JlaGF2aW9yLnByb3RvGhlnb29nbGUvYXBpL3Jlc291cmNl",
            "LnByb3RvGh5nb29nbGUvcHJvdG9idWYvZHVyYXRpb24ucHJvdG8aH2dvb2ds",
            "ZS9wcm90b2J1Zi90aW1lc3RhbXAucHJvdG8aHGdvb2dsZS9hcGkvYW5ub3Rh",
            "dGlvbnMucHJvdG8ikgEKDlNwZWVjaFdvcmRJbmZvEgwKBHdvcmQYAyABKAkS",
            "LwoMc3RhcnRfb2Zmc2V0GAEgASgLMhkuZ29vZ2xlLnByb3RvYnVmLkR1cmF0",
            "aW9uEi0KCmVuZF9vZmZzZXQYAiABKAsyGS5nb29nbGUucHJvdG9idWYuRHVy",
            "YXRpb24SEgoKY29uZmlkZW5jZRgEIAEoAiKbAgoQSW5wdXRBdWRpb0NvbmZp",
            "ZxJJCg5hdWRpb19lbmNvZGluZxgBIAEoDjIsLmdvb2dsZS5jbG91ZC5kaWFs",
            "b2dmbG93LmN4LnYzLkF1ZGlvRW5jb2RpbmdCA+BBAhIZChFzYW1wbGVfcmF0",
            "ZV9oZXJ0ehgCIAEoBRIYChBlbmFibGVfd29yZF9pbmZvGA0gASgIEhQKDHBo",
            "cmFzZV9oaW50cxgEIAMoCRINCgVtb2RlbBgHIAEoCRJICg1tb2RlbF92YXJp",
            "YW50GAogASgOMjEuZ29vZ2xlLmNsb3VkLmRpYWxvZ2Zsb3cuY3gudjMuU3Bl",
            "ZWNoTW9kZWxWYXJpYW50EhgKEHNpbmdsZV91dHRlcmFuY2UYCCABKAgiaQoU",
            "Vm9pY2VTZWxlY3Rpb25QYXJhbXMSDAoEbmFtZRgBIAEoCRJDCgtzc21sX2dl",
            "bmRlchgCIAEoDjIuLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LmN4LnYzLlNz",
            "bWxWb2ljZUdlbmRlciK2AQoWU3ludGhlc2l6ZVNwZWVjaENvbmZpZxIVCg1z",
            "cGVha2luZ19yYXRlGAEgASgBEg0KBXBpdGNoGAIgASgBEhYKDnZvbHVtZV9n",
            "YWluX2RiGAMgASgBEhoKEmVmZmVjdHNfcHJvZmlsZV9pZBgFIAMoCRJCCgV2",
            "b2ljZRgEIAEoCzIzLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LmN4LnYzLlZv",
            "aWNlU2VsZWN0aW9uUGFyYW1zItgBChFPdXRwdXRBdWRpb0NvbmZpZxJPCg5h",
            "dWRpb19lbmNvZGluZxgBIAEoDjIyLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93",
            "LmN4LnYzLk91dHB1dEF1ZGlvRW5jb2RpbmdCA+BBAhIZChFzYW1wbGVfcmF0",
            "ZV9oZXJ0ehgCIAEoBRJXChhzeW50aGVzaXplX3NwZWVjaF9jb25maWcYAyAB",
            "KAsyNS5nb29nbGUuY2xvdWQuZGlhbG9nZmxvdy5jeC52My5TeW50aGVzaXpl",
            "U3BlZWNoQ29uZmlnKvsBCg1BdWRpb0VuY29kaW5nEh4KGkFVRElPX0VOQ09E",
            "SU5HX1VOU1BFQ0lGSUVEEAASHAoYQVVESU9fRU5DT0RJTkdfTElORUFSXzE2",
            "EAESFwoTQVVESU9fRU5DT0RJTkdfRkxBQxACEhgKFEFVRElPX0VOQ09ESU5H",
            "X01VTEFXEAMSFgoSQVVESU9fRU5DT0RJTkdfQU1SEAQSGQoVQVVESU9fRU5D",
            "T0RJTkdfQU1SX1dCEAUSGwoXQVVESU9fRU5DT0RJTkdfT0dHX09QVVMQBhIp",
            "CiVBVURJT19FTkNPRElOR19TUEVFWF9XSVRIX0hFQURFUl9CWVRFEAcqdgoS",
            "U3BlZWNoTW9kZWxWYXJpYW50EiQKIFNQRUVDSF9NT0RFTF9WQVJJQU5UX1VO",
            "U1BFQ0lGSUVEEAASFgoSVVNFX0JFU1RfQVZBSUxBQkxFEAESEAoMVVNFX1NU",
            "QU5EQVJEEAISEAoMVVNFX0VOSEFOQ0VEEAMqjQEKD1NzbWxWb2ljZUdlbmRl",
            "chIhCh1TU01MX1ZPSUNFX0dFTkRFUl9VTlNQRUNJRklFRBAAEhoKFlNTTUxf",
            "Vk9JQ0VfR0VOREVSX01BTEUQARIcChhTU01MX1ZPSUNFX0dFTkRFUl9GRU1B",
            "TEUQAhIdChlTU01MX1ZPSUNFX0dFTkRFUl9ORVVUUkFMEAMq7AEKE091dHB1",
            "dEF1ZGlvRW5jb2RpbmcSJQohT1VUUFVUX0FVRElPX0VOQ09ESU5HX1VOU1BF",
            "Q0lGSUVEEAASIwofT1VUUFVUX0FVRElPX0VOQ09ESU5HX0xJTkVBUl8xNhAB",
            "Eh0KGU9VVFBVVF9BVURJT19FTkNPRElOR19NUDMQAhIlCiFPVVRQVVRfQVVE",
            "SU9fRU5DT0RJTkdfTVAzXzY0X0tCUFMQBBIiCh5PVVRQVVRfQVVESU9fRU5D",
            "T0RJTkdfT0dHX09QVVMQAxIfChtPVVRQVVRfQVVESU9fRU5DT0RJTkdfTVVM",
            "QVcQBULEAQohY29tLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LmN4LnYzQhBB",
            "dWRpb0NvbmZpZ1Byb3RvUAFaP2dvb2dsZS5nb2xhbmcub3JnL2dlbnByb3Rv",
            "L2dvb2dsZWFwaXMvY2xvdWQvZGlhbG9nZmxvdy9jeC92MztjePgBAaICAkRG",
            "qgIdR29vZ2xlLkNsb3VkLkRpYWxvZ2Zsb3cuQ3guVjPqAiFHb29nbGU6OkNs",
            "b3VkOjpEaWFsb2dmbG93OjpDWDo6VjNiBnByb3RvMw=="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.FieldBehaviorReflection.Descriptor, global::Google.Api.ResourceReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.DurationReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.TimestampReflection.Descriptor, global::Google.Api.AnnotationsReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(new[] {typeof(global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding), typeof(global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant), typeof(global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender), typeof(global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding), }, null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.Cx.V3.SpeechWordInfo), global::Google.Cloud.Dialogflow.Cx.V3.SpeechWordInfo.Parser, new[]{ "Word", "StartOffset", "EndOffset", "Confidence" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.Cx.V3.InputAudioConfig), global::Google.Cloud.Dialogflow.Cx.V3.InputAudioConfig.Parser, new[]{ "AudioEncoding", "SampleRateHertz", "EnableWordInfo", "PhraseHints", "Model", "ModelVariant", "SingleUtterance" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams), global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams.Parser, new[]{ "Name", "SsmlGender" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig), global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig.Parser, new[]{ "SpeakingRate", "Pitch", "VolumeGainDb", "EffectsProfileId", "Voice" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioConfig), global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioConfig.Parser, new[]{ "AudioEncoding", "SampleRateHertz", "SynthesizeSpeechConfig" }, null, null, null, null)
          }));
    }
    #endregion

  }
  #region Enums
  /// <summary>
  /// Audio encoding of the audio content sent in the conversational query request.
  /// Refer to the
  /// [Cloud Speech API
  /// documentation](https://cloud.google.com/speech-to-text/docs/basics) for more
  /// details.
  /// </summary>
  public enum AudioEncoding {
    /// <summary>
    /// Not specified.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_LINEAR_16")] Linear16 = 1,
    /// <summary>
    /// [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
    /// Codec) is the recommended encoding because it is lossless (therefore
    /// recognition is not compromised) and requires only about half the
    /// bandwidth of `LINEAR16`. `FLAC` stream encoding supports 16-bit and
    /// 24-bit samples, however, not all fields in `STREAMINFO` are supported.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_FLAC")] Flac = 2,
    /// <summary>
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_MULAW")] Mulaw = 3,
    /// <summary>
    /// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_AMR")] Amr = 4,
    /// <summary>
    /// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_AMR_WB")] AmrWb = 5,
    /// <summary>
    /// Opus encoded audio frames in Ogg container
    /// ([OggOpus](https://wiki.xiph.org/OggOpus)).
    /// `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_OGG_OPUS")] OggOpus = 6,
    /// <summary>
    /// Although the use of lossy encodings is not recommended, if a very low
    /// bitrate encoding is required, `OGG_OPUS` is highly preferred over
    /// Speex encoding. The [Speex](https://speex.org/) encoding supported by
    /// Dialogflow API has a header byte in each block, as in MIME type
    /// `audio/x-speex-with-header-byte`.
    /// It is a variant of the RTP Speex encoding defined in
    /// [RFC 5574](https://tools.ietf.org/html/rfc5574).
    /// The stream is a sequence of blocks, one block per RTP packet. Each block
    /// starts with a byte containing the length of the block, in bytes, followed
    /// by one or more frames of Speex data, padded to an integral number of
    /// bytes (octets) as specified in RFC 5574. In other words, each RTP header
    /// is replaced with a single byte containing the block length. Only Speex
    /// wideband is supported. `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE")] SpeexWithHeaderByte = 7,
  }

  /// <summary>
  /// Variant of the specified [Speech model][google.cloud.dialogflow.cx.v3.InputAudioConfig.model] to use.
  ///
  /// See the [Cloud Speech
  /// documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
  /// for which models have different variants. For example, the "phone_call" model
  /// has both a standard and an enhanced variant. When you use an enhanced model,
  /// you will generally receive higher quality results than for a standard model.
  /// </summary>
  public enum SpeechModelVariant {
    /// <summary>
    /// No model variant specified. In this case Dialogflow defaults to
    /// USE_BEST_AVAILABLE.
    /// </summary>
    [pbr::OriginalName("SPEECH_MODEL_VARIANT_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Use the best available variant of the [Speech
    /// model][InputAudioConfig.model] that the caller is eligible for.
    ///
    /// Please see the [Dialogflow
    /// docs](https://cloud.google.com/dialogflow/docs/data-logging) for
    /// how to make your project eligible for enhanced models.
    /// </summary>
    [pbr::OriginalName("USE_BEST_AVAILABLE")] UseBestAvailable = 1,
    /// <summary>
    /// Use standard model variant even if an enhanced model is available.  See the
    /// [Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
    /// for details about enhanced models.
    /// </summary>
    [pbr::OriginalName("USE_STANDARD")] UseStandard = 2,
    /// <summary>
    /// Use an enhanced model variant:
    ///
    /// * If an enhanced variant does not exist for the given
    ///   [model][google.cloud.dialogflow.cx.v3.InputAudioConfig.model] and request language, Dialogflow falls
    ///   back to the standard variant.
    ///
    ///   The [Cloud Speech
    ///   documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
    ///   describes which models have enhanced variants.
    ///
    /// * If the API caller isn't eligible for enhanced models, Dialogflow returns
    ///   an error.  Please see the [Dialogflow
    ///   docs](https://cloud.google.com/dialogflow/docs/data-logging)
    ///   for how to make your project eligible.
    /// </summary>
    [pbr::OriginalName("USE_ENHANCED")] UseEnhanced = 3,
  }

  /// <summary>
  /// Gender of the voice as described in
  /// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
  /// </summary>
  public enum SsmlVoiceGender {
    /// <summary>
    /// An unspecified gender, which means that the client doesn't care which
    /// gender the selected voice will have.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// A male voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_MALE")] Male = 1,
    /// <summary>
    /// A female voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_FEMALE")] Female = 2,
    /// <summary>
    /// A gender-neutral voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_NEUTRAL")] Neutral = 3,
  }

  /// <summary>
  /// Audio encoding of the output audio format in Text-To-Speech.
  /// </summary>
  public enum OutputAudioEncoding {
    /// <summary>
    /// Not specified.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_LINEAR_16")] Linear16 = 1,
    /// <summary>
    /// MP3 audio at 32kbps.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MP3")] Mp3 = 2,
    /// <summary>
    /// MP3 audio at 64kbps.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MP3_64_KBPS")] Mp364Kbps = 4,
    /// <summary>
    /// Opus encoded audio wrapped in an ogg container. The result will be a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_OGG_OPUS")] OggOpus = 3,
    /// <summary>
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MULAW")] Mulaw = 5,
  }

  #endregion

  #region Messages
  /// <summary>
  /// Information for a word recognized by the speech recognizer.
  /// </summary>
  public sealed partial class SpeechWordInfo : pb::IMessage<SpeechWordInfo>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechWordInfo> _parser = new pb::MessageParser<SpeechWordInfo>(() => new SpeechWordInfo());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechWordInfo> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.Cx.V3.AudioConfigReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo(SpeechWordInfo other) : this() {
      word_ = other.word_;
      startOffset_ = other.startOffset_ != null ? other.startOffset_.Clone() : null;
      endOffset_ = other.endOffset_ != null ? other.endOffset_.Clone() : null;
      confidence_ = other.confidence_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo Clone() {
      return new SpeechWordInfo(this);
    }

    /// <summary>Field number for the "word" field.</summary>
    public const int WordFieldNumber = 3;
    private string word_ = "";
    /// <summary>
    /// The word this info is for.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Word {
      get { return word_; }
      set {
        word_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "start_offset" field.</summary>
    public const int StartOffsetFieldNumber = 1;
    private global::Google.Protobuf.WellKnownTypes.Duration startOffset_;
    /// <summary>
    /// Time offset relative to the beginning of the audio that corresponds to the
    /// start of the spoken word. This is an experimental feature and the accuracy
    /// of the time offset can vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration StartOffset {
      get { return startOffset_; }
      set {
        startOffset_ = value;
      }
    }

    /// <summary>Field number for the "end_offset" field.</summary>
    public const int EndOffsetFieldNumber = 2;
    private global::Google.Protobuf.WellKnownTypes.Duration endOffset_;
    /// <summary>
    /// Time offset relative to the beginning of the audio that corresponds to the
    /// end of the spoken word. This is an experimental feature and the accuracy of
    /// the time offset can vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration EndOffset {
      get { return endOffset_; }
      set {
        endOffset_ = value;
      }
    }

    /// <summary>Field number for the "confidence" field.</summary>
    public const int ConfidenceFieldNumber = 4;
    private float confidence_;
    /// <summary>
    /// The Speech confidence between 0.0 and 1.0 for this word. A higher number
    /// indicates an estimated greater likelihood that the recognized word is
    /// correct. The default of 0.0 is a sentinel value indicating that confidence
    /// was not set.
    ///
    /// This field is not guaranteed to be fully stable over time for the same
    /// audio input. Users should also not rely on it to always be provided.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Confidence {
      get { return confidence_; }
      set {
        confidence_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechWordInfo);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechWordInfo other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Word != other.Word) return false;
      if (!object.Equals(StartOffset, other.StartOffset)) return false;
      if (!object.Equals(EndOffset, other.EndOffset)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.Equals(Confidence, other.Confidence)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Word.Length != 0) hash ^= Word.GetHashCode();
      if (startOffset_ != null) hash ^= StartOffset.GetHashCode();
      if (endOffset_ != null) hash ^= EndOffset.GetHashCode();
      if (Confidence != 0F) hash ^= pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.GetHashCode(Confidence);
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (startOffset_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartOffset);
      }
      if (endOffset_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndOffset);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(37);
        output.WriteFloat(Confidence);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (startOffset_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartOffset);
      }
      if (endOffset_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndOffset);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(37);
        output.WriteFloat(Confidence);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Word.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Word);
      }
      if (startOffset_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StartOffset);
      }
      if (endOffset_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(EndOffset);
      }
      if (Confidence != 0F) {
        size += 1 + 4;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechWordInfo other) {
      if (other == null) {
        return;
      }
      if (other.Word.Length != 0) {
        Word = other.Word;
      }
      if (other.startOffset_ != null) {
        if (startOffset_ == null) {
          StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        StartOffset.MergeFrom(other.StartOffset);
      }
      if (other.endOffset_ != null) {
        if (endOffset_ == null) {
          EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        EndOffset.MergeFrom(other.EndOffset);
      }
      if (other.Confidence != 0F) {
        Confidence = other.Confidence;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (startOffset_ == null) {
              StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartOffset);
            break;
          }
          case 18: {
            if (endOffset_ == null) {
              EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndOffset);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 37: {
            Confidence = input.ReadFloat();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (startOffset_ == null) {
              StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartOffset);
            break;
          }
          case 18: {
            if (endOffset_ == null) {
              EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndOffset);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 37: {
            Confidence = input.ReadFloat();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Instructs the speech recognizer on how to process the audio content.
  /// </summary>
  public sealed partial class InputAudioConfig : pb::IMessage<InputAudioConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<InputAudioConfig> _parser = new pb::MessageParser<InputAudioConfig>(() => new InputAudioConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<InputAudioConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.Cx.V3.AudioConfigReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig(InputAudioConfig other) : this() {
      audioEncoding_ = other.audioEncoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      enableWordInfo_ = other.enableWordInfo_;
      phraseHints_ = other.phraseHints_.Clone();
      model_ = other.model_;
      modelVariant_ = other.modelVariant_;
      singleUtterance_ = other.singleUtterance_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig Clone() {
      return new InputAudioConfig(this);
    }

    /// <summary>Field number for the "audio_encoding" field.</summary>
    public const int AudioEncodingFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding audioEncoding_ = global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified;
    /// <summary>
    /// Required. Audio encoding of the audio content to process.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding AudioEncoding {
      get { return audioEncoding_; }
      set {
        audioEncoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// Sample rate (in Hertz) of the audio content sent in the query.
    /// Refer to
    /// [Cloud Speech API
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics) for
    /// more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "enable_word_info" field.</summary>
    public const int EnableWordInfoFieldNumber = 13;
    private bool enableWordInfo_;
    /// <summary>
    /// Optional. If `true`, Dialogflow returns [SpeechWordInfo][google.cloud.dialogflow.cx.v3.SpeechWordInfo] in
    /// [StreamingRecognitionResult][google.cloud.dialogflow.cx.v3.StreamingRecognitionResult] with information about the recognized speech
    /// words, e.g. start and end time offsets. If false or unspecified, Speech
    /// doesn't return any word-level information.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableWordInfo {
      get { return enableWordInfo_; }
      set {
        enableWordInfo_ = value;
      }
    }

    /// <summary>Field number for the "phrase_hints" field.</summary>
    public const int PhraseHintsFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_phraseHints_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> phraseHints_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// Optional. A list of strings containing words and phrases that the speech
    /// recognizer should recognize with higher likelihood.
    ///
    /// See [the Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
    /// for more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> PhraseHints {
      get { return phraseHints_; }
    }

    /// <summary>Field number for the "model" field.</summary>
    public const int ModelFieldNumber = 7;
    private string model_ = "";
    /// <summary>
    /// Optional. Which Speech model to select for the given request. Select the
    /// model best suited to your domain to get best results. If a model is not
    /// explicitly specified, then we auto-select a model based on the parameters
    /// in the InputAudioConfig.
    /// If enhanced speech model is enabled for the agent and an enhanced
    /// version of the specified model for the language does not exist, then the
    /// speech is recognized using the standard version of the specified model.
    /// Refer to
    /// [Cloud Speech API
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics#select-model)
    /// for more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Model {
      get { return model_; }
      set {
        model_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "model_variant" field.</summary>
    public const int ModelVariantFieldNumber = 10;
    private global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant modelVariant_ = global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified;
    /// <summary>
    /// Optional. Which variant of the [Speech model][google.cloud.dialogflow.cx.v3.InputAudioConfig.model] to use.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant ModelVariant {
      get { return modelVariant_; }
      set {
        modelVariant_ = value;
      }
    }

    /// <summary>Field number for the "single_utterance" field.</summary>
    public const int SingleUtteranceFieldNumber = 8;
    private bool singleUtterance_;
    /// <summary>
    /// Optional. If `false` (default), recognition does not cease until the
    /// client closes the stream.
    /// If `true`, the recognizer will detect a single spoken utterance in input
    /// audio. Recognition ceases when it detects the audio's voice has
    /// stopped or paused. In this case, once a detected intent is received, the
    /// client should close the stream and start a new request with a new stream as
    /// needed.
    /// Note: This setting is relevant only for streaming methods.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool SingleUtterance {
      get { return singleUtterance_; }
      set {
        singleUtterance_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as InputAudioConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(InputAudioConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioEncoding != other.AudioEncoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (EnableWordInfo != other.EnableWordInfo) return false;
      if(!phraseHints_.Equals(other.phraseHints_)) return false;
      if (Model != other.Model) return false;
      if (ModelVariant != other.ModelVariant) return false;
      if (SingleUtterance != other.SingleUtterance) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified) hash ^= AudioEncoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (EnableWordInfo != false) hash ^= EnableWordInfo.GetHashCode();
      hash ^= phraseHints_.GetHashCode();
      if (Model.Length != 0) hash ^= Model.GetHashCode();
      if (ModelVariant != global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified) hash ^= ModelVariant.GetHashCode();
      if (SingleUtterance != false) hash ^= SingleUtterance.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      phraseHints_.WriteTo(output, _repeated_phraseHints_codec);
      if (Model.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(Model);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(64);
        output.WriteBool(SingleUtterance);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(80);
        output.WriteEnum((int) ModelVariant);
      }
      if (EnableWordInfo != false) {
        output.WriteRawTag(104);
        output.WriteBool(EnableWordInfo);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      phraseHints_.WriteTo(ref output, _repeated_phraseHints_codec);
      if (Model.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(Model);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(64);
        output.WriteBool(SingleUtterance);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(80);
        output.WriteEnum((int) ModelVariant);
      }
      if (EnableWordInfo != false) {
        output.WriteRawTag(104);
        output.WriteBool(EnableWordInfo);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (EnableWordInfo != false) {
        size += 1 + 1;
      }
      size += phraseHints_.CalculateSize(_repeated_phraseHints_codec);
      if (Model.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Model);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) ModelVariant);
      }
      if (SingleUtterance != false) {
        size += 1 + 1;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(InputAudioConfig other) {
      if (other == null) {
        return;
      }
      if (other.AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding.Unspecified) {
        AudioEncoding = other.AudioEncoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.EnableWordInfo != false) {
        EnableWordInfo = other.EnableWordInfo;
      }
      phraseHints_.Add(other.phraseHints_);
      if (other.Model.Length != 0) {
        Model = other.Model;
      }
      if (other.ModelVariant != global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant.Unspecified) {
        ModelVariant = other.ModelVariant;
      }
      if (other.SingleUtterance != false) {
        SingleUtterance = other.SingleUtterance;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 34: {
            phraseHints_.AddEntriesFrom(input, _repeated_phraseHints_codec);
            break;
          }
          case 58: {
            Model = input.ReadString();
            break;
          }
          case 64: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 80: {
            ModelVariant = (global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant) input.ReadEnum();
            break;
          }
          case 104: {
            EnableWordInfo = input.ReadBool();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.Cx.V3.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 34: {
            phraseHints_.AddEntriesFrom(ref input, _repeated_phraseHints_codec);
            break;
          }
          case 58: {
            Model = input.ReadString();
            break;
          }
          case 64: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 80: {
            ModelVariant = (global::Google.Cloud.Dialogflow.Cx.V3.SpeechModelVariant) input.ReadEnum();
            break;
          }
          case 104: {
            EnableWordInfo = input.ReadBool();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Description of which voice to use for speech synthesis.
  /// </summary>
  public sealed partial class VoiceSelectionParams : pb::IMessage<VoiceSelectionParams>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<VoiceSelectionParams> _parser = new pb::MessageParser<VoiceSelectionParams>(() => new VoiceSelectionParams());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<VoiceSelectionParams> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.Cx.V3.AudioConfigReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams(VoiceSelectionParams other) : this() {
      name_ = other.name_;
      ssmlGender_ = other.ssmlGender_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams Clone() {
      return new VoiceSelectionParams(this);
    }

    /// <summary>Field number for the "name" field.</summary>
    public const int NameFieldNumber = 1;
    private string name_ = "";
    /// <summary>
    /// Optional. The name of the voice. If not set, the service will choose a
    /// voice based on the other parameters such as language_code and
    /// [ssml_gender][google.cloud.dialogflow.cx.v3.VoiceSelectionParams.ssml_gender].
    ///
    /// For the list of available voices, please refer to [Supported voices and
    /// languages](https://cloud.google.com/text-to-speech/docs/voices).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Name {
      get { return name_; }
      set {
        name_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "ssml_gender" field.</summary>
    public const int SsmlGenderFieldNumber = 2;
    private global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender ssmlGender_ = global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified;
    /// <summary>
    /// Optional. The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// [name][google.cloud.dialogflow.cx.v3.VoiceSelectionParams.name]. Note that this is only a preference, not requirement. If a
    /// voice of the appropriate gender is not available, the synthesizer
    /// substitutes a voice with a different gender rather than failing the
    /// request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender SsmlGender {
      get { return ssmlGender_; }
      set {
        ssmlGender_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as VoiceSelectionParams);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(VoiceSelectionParams other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Name != other.Name) return false;
      if (SsmlGender != other.SsmlGender) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Name.Length != 0) hash ^= Name.GetHashCode();
      if (SsmlGender != global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified) hash ^= SsmlGender.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (Name.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified) {
        output.WriteRawTag(16);
        output.WriteEnum((int) SsmlGender);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (Name.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified) {
        output.WriteRawTag(16);
        output.WriteEnum((int) SsmlGender);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Name.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) SsmlGender);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(VoiceSelectionParams other) {
      if (other == null) {
        return;
      }
      if (other.Name.Length != 0) {
        Name = other.Name;
      }
      if (other.SsmlGender != global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender.Unspecified) {
        SsmlGender = other.SsmlGender;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            Name = input.ReadString();
            break;
          }
          case 16: {
            SsmlGender = (global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender) input.ReadEnum();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            Name = input.ReadString();
            break;
          }
          case 16: {
            SsmlGender = (global::Google.Cloud.Dialogflow.Cx.V3.SsmlVoiceGender) input.ReadEnum();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Configuration of how speech should be synthesized.
  /// </summary>
  public sealed partial class SynthesizeSpeechConfig : pb::IMessage<SynthesizeSpeechConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SynthesizeSpeechConfig> _parser = new pb::MessageParser<SynthesizeSpeechConfig>(() => new SynthesizeSpeechConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SynthesizeSpeechConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.Cx.V3.AudioConfigReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig(SynthesizeSpeechConfig other) : this() {
      speakingRate_ = other.speakingRate_;
      pitch_ = other.pitch_;
      volumeGainDb_ = other.volumeGainDb_;
      effectsProfileId_ = other.effectsProfileId_.Clone();
      voice_ = other.voice_ != null ? other.voice_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig Clone() {
      return new SynthesizeSpeechConfig(this);
    }

    /// <summary>Field number for the "speaking_rate" field.</summary>
    public const int SpeakingRateFieldNumber = 1;
    private double speakingRate_;
    /// <summary>
    /// Optional. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is the normal
    /// native speed supported by the specific voice. 2.0 is twice as fast, and
    /// 0.5 is half as fast. If unset(0.0), defaults to the native 1.0 speed. Any
    /// other values &lt; 0.25 or > 4.0 will return an error.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double SpeakingRate {
      get { return speakingRate_; }
      set {
        speakingRate_ = value;
      }
    }

    /// <summary>Field number for the "pitch" field.</summary>
    public const int PitchFieldNumber = 2;
    private double pitch_;
    /// <summary>
    /// Optional. Speaking pitch, in the range [-20.0, 20.0]. 20 means increase 20
    /// semitones from the original pitch. -20 means decrease 20 semitones from the
    /// original pitch.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double Pitch {
      get { return pitch_; }
      set {
        pitch_ = value;
      }
    }

    /// <summary>Field number for the "volume_gain_db" field.</summary>
    public const int VolumeGainDbFieldNumber = 3;
    private double volumeGainDb_;
    /// <summary>
    /// Optional. Volume gain (in dB) of the normal native volume supported by the
    /// specific voice, in the range [-96.0, 16.0]. If unset, or set to a value of
    /// 0.0 (dB), will play at normal native signal amplitude. A value of -6.0 (dB)
    /// will play at approximately half the amplitude of the normal native signal
    /// amplitude. A value of +6.0 (dB) will play at approximately twice the
    /// amplitude of the normal native signal amplitude. We strongly recommend not
    /// to exceed +10 (dB) as there's usually no effective increase in loudness for
    /// any value greater than that.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double VolumeGainDb {
      get { return volumeGainDb_; }
      set {
        volumeGainDb_ = value;
      }
    }

    /// <summary>Field number for the "effects_profile_id" field.</summary>
    public const int EffectsProfileIdFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_effectsProfileId_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> effectsProfileId_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// Optional. An identifier which selects 'audio effects' profiles that are
    /// applied on (post synthesized) text to speech. Effects are applied on top of
    /// each other in the order they are given.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> EffectsProfileId {
      get { return effectsProfileId_; }
    }

    /// <summary>Field number for the "voice" field.</summary>
    public const int VoiceFieldNumber = 4;
    private global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams voice_;
    /// <summary>
    /// Optional. The desired voice of the synthesized audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams Voice {
      get { return voice_; }
      set {
        voice_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SynthesizeSpeechConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SynthesizeSpeechConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(SpeakingRate, other.SpeakingRate)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(Pitch, other.Pitch)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(VolumeGainDb, other.VolumeGainDb)) return false;
      if(!effectsProfileId_.Equals(other.effectsProfileId_)) return false;
      if (!object.Equals(Voice, other.Voice)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (SpeakingRate != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(SpeakingRate);
      if (Pitch != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(Pitch);
      if (VolumeGainDb != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(VolumeGainDb);
      hash ^= effectsProfileId_.GetHashCode();
      if (voice_ != null) hash ^= Voice.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (SpeakingRate != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(SpeakingRate);
      }
      if (Pitch != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Pitch);
      }
      if (VolumeGainDb != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(VolumeGainDb);
      }
      if (voice_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Voice);
      }
      effectsProfileId_.WriteTo(output, _repeated_effectsProfileId_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (SpeakingRate != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(SpeakingRate);
      }
      if (Pitch != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Pitch);
      }
      if (VolumeGainDb != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(VolumeGainDb);
      }
      if (voice_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Voice);
      }
      effectsProfileId_.WriteTo(ref output, _repeated_effectsProfileId_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (SpeakingRate != 0D) {
        size += 1 + 8;
      }
      if (Pitch != 0D) {
        size += 1 + 8;
      }
      if (VolumeGainDb != 0D) {
        size += 1 + 8;
      }
      size += effectsProfileId_.CalculateSize(_repeated_effectsProfileId_codec);
      if (voice_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Voice);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SynthesizeSpeechConfig other) {
      if (other == null) {
        return;
      }
      if (other.SpeakingRate != 0D) {
        SpeakingRate = other.SpeakingRate;
      }
      if (other.Pitch != 0D) {
        Pitch = other.Pitch;
      }
      if (other.VolumeGainDb != 0D) {
        VolumeGainDb = other.VolumeGainDb;
      }
      effectsProfileId_.Add(other.effectsProfileId_);
      if (other.voice_ != null) {
        if (voice_ == null) {
          Voice = new global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams();
        }
        Voice.MergeFrom(other.Voice);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 9: {
            SpeakingRate = input.ReadDouble();
            break;
          }
          case 17: {
            Pitch = input.ReadDouble();
            break;
          }
          case 25: {
            VolumeGainDb = input.ReadDouble();
            break;
          }
          case 34: {
            if (voice_ == null) {
              Voice = new global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams();
            }
            input.ReadMessage(Voice);
            break;
          }
          case 42: {
            effectsProfileId_.AddEntriesFrom(input, _repeated_effectsProfileId_codec);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 9: {
            SpeakingRate = input.ReadDouble();
            break;
          }
          case 17: {
            Pitch = input.ReadDouble();
            break;
          }
          case 25: {
            VolumeGainDb = input.ReadDouble();
            break;
          }
          case 34: {
            if (voice_ == null) {
              Voice = new global::Google.Cloud.Dialogflow.Cx.V3.VoiceSelectionParams();
            }
            input.ReadMessage(Voice);
            break;
          }
          case 42: {
            effectsProfileId_.AddEntriesFrom(ref input, _repeated_effectsProfileId_codec);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Instructs the speech synthesizer how to generate the output audio content.
  /// </summary>
  public sealed partial class OutputAudioConfig : pb::IMessage<OutputAudioConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<OutputAudioConfig> _parser = new pb::MessageParser<OutputAudioConfig>(() => new OutputAudioConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<OutputAudioConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.Cx.V3.AudioConfigReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig(OutputAudioConfig other) : this() {
      audioEncoding_ = other.audioEncoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      synthesizeSpeechConfig_ = other.synthesizeSpeechConfig_ != null ? other.synthesizeSpeechConfig_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig Clone() {
      return new OutputAudioConfig(this);
    }

    /// <summary>Field number for the "audio_encoding" field.</summary>
    public const int AudioEncodingFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding audioEncoding_ = global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified;
    /// <summary>
    /// Required. Audio encoding of the synthesized audio content.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding AudioEncoding {
      get { return audioEncoding_; }
      set {
        audioEncoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// Optional. The synthesis sample rate (in hertz) for this audio. If not
    /// provided, then the synthesizer will use the default sample rate based on
    /// the audio encoding. If this is different from the voice's natural sample
    /// rate, then the synthesizer will honor this request by converting to the
    /// desired sample rate (which might result in worse audio quality).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "synthesize_speech_config" field.</summary>
    public const int SynthesizeSpeechConfigFieldNumber = 3;
    private global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig synthesizeSpeechConfig_;
    /// <summary>
    /// Optional. Configuration of how speech should be synthesized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig SynthesizeSpeechConfig {
      get { return synthesizeSpeechConfig_; }
      set {
        synthesizeSpeechConfig_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as OutputAudioConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(OutputAudioConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioEncoding != other.AudioEncoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (!object.Equals(SynthesizeSpeechConfig, other.SynthesizeSpeechConfig)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified) hash ^= AudioEncoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (synthesizeSpeechConfig_ != null) hash ^= SynthesizeSpeechConfig.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(OutputAudioConfig other) {
      if (other == null) {
        return;
      }
      if (other.AudioEncoding != global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding.Unspecified) {
        AudioEncoding = other.AudioEncoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.synthesizeSpeechConfig_ != null) {
        if (synthesizeSpeechConfig_ == null) {
          SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig();
        }
        SynthesizeSpeechConfig.MergeFrom(other.SynthesizeSpeechConfig);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            if (synthesizeSpeechConfig_ == null) {
              SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig();
            }
            input.ReadMessage(SynthesizeSpeechConfig);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.Cx.V3.OutputAudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            if (synthesizeSpeechConfig_ == null) {
              SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.Cx.V3.SynthesizeSpeechConfig();
            }
            input.ReadMessage(SynthesizeSpeechConfig);
            break;
          }
        }
      }
    }
    #endif

  }

  #endregion

}

#endregion Designer generated code
