// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: google/cloud/dialogflow/v2/audio_config.proto
// </auto-generated>
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Dialogflow.V2 {

  /// <summary>Holder for reflection information generated from google/cloud/dialogflow/v2/audio_config.proto</summary>
  public static partial class AudioConfigReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/dialogflow/v2/audio_config.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static AudioConfigReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Ci1nb29nbGUvY2xvdWQvZGlhbG9nZmxvdy92Mi9hdWRpb19jb25maWcucHJv",
            "dG8SGmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyGh9nb29nbGUvYXBpL2Zp",
            "ZWxkX2JlaGF2aW9yLnByb3RvGhlnb29nbGUvYXBpL3Jlc291cmNlLnByb3Rv",
            "Gh5nb29nbGUvcHJvdG9idWYvZHVyYXRpb24ucHJvdG8aH2dvb2dsZS9wcm90",
            "b2J1Zi90aW1lc3RhbXAucHJvdG8aHGdvb2dsZS9hcGkvYW5ub3RhdGlvbnMu",
            "cHJvdG8iLwoNU3BlZWNoQ29udGV4dBIPCgdwaHJhc2VzGAEgAygJEg0KBWJv",
            "b3N0GAIgASgCIpIBCg5TcGVlY2hXb3JkSW5mbxIMCgR3b3JkGAMgASgJEi8K",
            "DHN0YXJ0X29mZnNldBgBIAEoCzIZLmdvb2dsZS5wcm90b2J1Zi5EdXJhdGlv",
            "bhItCgplbmRfb2Zmc2V0GAIgASgLMhkuZ29vZ2xlLnByb3RvYnVmLkR1cmF0",
            "aW9uEhIKCmNvbmZpZGVuY2UYBCABKAIimwMKEElucHV0QXVkaW9Db25maWcS",
            "QQoOYXVkaW9fZW5jb2RpbmcYASABKA4yKS5nb29nbGUuY2xvdWQuZGlhbG9n",
            "Zmxvdy52Mi5BdWRpb0VuY29kaW5nEhkKEXNhbXBsZV9yYXRlX2hlcnR6GAIg",
            "ASgFEhUKDWxhbmd1YWdlX2NvZGUYAyABKAkSGAoQZW5hYmxlX3dvcmRfaW5m",
            "bxgNIAEoCBIYCgxwaHJhc2VfaGludHMYBCADKAlCAhgBEkIKD3NwZWVjaF9j",
            "b250ZXh0cxgLIAMoCzIpLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlNw",
            "ZWVjaENvbnRleHQSDQoFbW9kZWwYByABKAkSRQoNbW9kZWxfdmFyaWFudBgK",
            "IAEoDjIuLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlNwZWVjaE1vZGVs",
            "VmFyaWFudBIYChBzaW5nbGVfdXR0ZXJhbmNlGAggASgIEioKImRpc2FibGVf",
            "bm9fc3BlZWNoX3JlY29nbml6ZWRfZXZlbnQYDiABKAgiZgoUVm9pY2VTZWxl",
            "Y3Rpb25QYXJhbXMSDAoEbmFtZRgBIAEoCRJACgtzc21sX2dlbmRlchgCIAEo",
            "DjIrLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlNzbWxWb2ljZUdlbmRl",
            "ciKzAQoWU3ludGhlc2l6ZVNwZWVjaENvbmZpZxIVCg1zcGVha2luZ19yYXRl",
            "GAEgASgBEg0KBXBpdGNoGAIgASgBEhYKDnZvbHVtZV9nYWluX2RiGAMgASgB",
            "EhoKEmVmZmVjdHNfcHJvZmlsZV9pZBgFIAMoCRI/CgV2b2ljZRgEIAEoCzIw",
            "Lmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlZvaWNlU2VsZWN0aW9uUGFy",
            "YW1zItIBChFPdXRwdXRBdWRpb0NvbmZpZxJMCg5hdWRpb19lbmNvZGluZxgB",
            "IAEoDjIvLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLk91dHB1dEF1ZGlv",
            "RW5jb2RpbmdCA+BBAhIZChFzYW1wbGVfcmF0ZV9oZXJ0ehgCIAEoBRJUChhz",
            "eW50aGVzaXplX3NwZWVjaF9jb25maWcYAyABKAsyMi5nb29nbGUuY2xvdWQu",
            "ZGlhbG9nZmxvdy52Mi5TeW50aGVzaXplU3BlZWNoQ29uZmlnImcKElNwZWVj",
            "aFRvVGV4dENvbmZpZxJRChRzcGVlY2hfbW9kZWxfdmFyaWFudBgBIAEoDjIu",
            "Lmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlNwZWVjaE1vZGVsVmFyaWFu",
            "dEID4EEBKvsBCg1BdWRpb0VuY29kaW5nEh4KGkFVRElPX0VOQ09ESU5HX1VO",
            "U1BFQ0lGSUVEEAASHAoYQVVESU9fRU5DT0RJTkdfTElORUFSXzE2EAESFwoT",
            "QVVESU9fRU5DT0RJTkdfRkxBQxACEhgKFEFVRElPX0VOQ09ESU5HX01VTEFX",
            "EAMSFgoSQVVESU9fRU5DT0RJTkdfQU1SEAQSGQoVQVVESU9fRU5DT0RJTkdf",
            "QU1SX1dCEAUSGwoXQVVESU9fRU5DT0RJTkdfT0dHX09QVVMQBhIpCiVBVURJ",
            "T19FTkNPRElOR19TUEVFWF9XSVRIX0hFQURFUl9CWVRFEAcqdgoSU3BlZWNo",
            "TW9kZWxWYXJpYW50EiQKIFNQRUVDSF9NT0RFTF9WQVJJQU5UX1VOU1BFQ0lG",
            "SUVEEAASFgoSVVNFX0JFU1RfQVZBSUxBQkxFEAESEAoMVVNFX1NUQU5EQVJE",
            "EAISEAoMVVNFX0VOSEFOQ0VEEAMqjQEKD1NzbWxWb2ljZUdlbmRlchIhCh1T",
            "U01MX1ZPSUNFX0dFTkRFUl9VTlNQRUNJRklFRBAAEhoKFlNTTUxfVk9JQ0Vf",
            "R0VOREVSX01BTEUQARIcChhTU01MX1ZPSUNFX0dFTkRFUl9GRU1BTEUQAhId",
            "ChlTU01MX1ZPSUNFX0dFTkRFUl9ORVVUUkFMEAMq7AEKE091dHB1dEF1ZGlv",
            "RW5jb2RpbmcSJQohT1VUUFVUX0FVRElPX0VOQ09ESU5HX1VOU1BFQ0lGSUVE",
            "EAASIwofT1VUUFVUX0FVRElPX0VOQ09ESU5HX0xJTkVBUl8xNhABEh0KGU9V",
            "VFBVVF9BVURJT19FTkNPRElOR19NUDMQAhIlCiFPVVRQVVRfQVVESU9fRU5D",
            "T0RJTkdfTVAzXzY0X0tCUFMQBBIiCh5PVVRQVVRfQVVESU9fRU5DT0RJTkdf",
            "T0dHX09QVVMQAxIfChtPVVRQVVRfQVVESU9fRU5DT0RJTkdfTVVMQVcQBUKf",
            "AQoeY29tLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyQhBBdWRpb0NvbmZp",
            "Z1Byb3RvUAFaRGdvb2dsZS5nb2xhbmcub3JnL2dlbnByb3RvL2dvb2dsZWFw",
            "aXMvY2xvdWQvZGlhbG9nZmxvdy92MjtkaWFsb2dmbG93+AEBogICREaqAhpH",
            "b29nbGUuQ2xvdWQuRGlhbG9nZmxvdy5WMmIGcHJvdG8z"));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.FieldBehaviorReflection.Descriptor, global::Google.Api.ResourceReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.DurationReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.TimestampReflection.Descriptor, global::Google.Api.AnnotationsReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(new[] {typeof(global::Google.Cloud.Dialogflow.V2.AudioEncoding), typeof(global::Google.Cloud.Dialogflow.V2.SpeechModelVariant), typeof(global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender), typeof(global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding), }, null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.SpeechContext), global::Google.Cloud.Dialogflow.V2.SpeechContext.Parser, new[]{ "Phrases", "Boost" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.SpeechWordInfo), global::Google.Cloud.Dialogflow.V2.SpeechWordInfo.Parser, new[]{ "Word", "StartOffset", "EndOffset", "Confidence" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.InputAudioConfig), global::Google.Cloud.Dialogflow.V2.InputAudioConfig.Parser, new[]{ "AudioEncoding", "SampleRateHertz", "LanguageCode", "EnableWordInfo", "PhraseHints", "SpeechContexts", "Model", "ModelVariant", "SingleUtterance", "DisableNoSpeechRecognizedEvent" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams), global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams.Parser, new[]{ "Name", "SsmlGender" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig), global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig.Parser, new[]{ "SpeakingRate", "Pitch", "VolumeGainDb", "EffectsProfileId", "Voice" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.OutputAudioConfig), global::Google.Cloud.Dialogflow.V2.OutputAudioConfig.Parser, new[]{ "AudioEncoding", "SampleRateHertz", "SynthesizeSpeechConfig" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.SpeechToTextConfig), global::Google.Cloud.Dialogflow.V2.SpeechToTextConfig.Parser, new[]{ "SpeechModelVariant" }, null, null, null, null)
          }));
    }
    #endregion

  }
  #region Enums
  /// <summary>
  /// Audio encoding of the audio content sent in the conversational query request.
  /// Refer to the
  /// [Cloud Speech API
  /// documentation](https://cloud.google.com/speech-to-text/docs/basics) for more
  /// details.
  /// </summary>
  public enum AudioEncoding {
    /// <summary>
    /// Not specified.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_LINEAR_16")] Linear16 = 1,
    /// <summary>
    /// [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
    /// Codec) is the recommended encoding because it is lossless (therefore
    /// recognition is not compromised) and requires only about half the
    /// bandwidth of `LINEAR16`. `FLAC` stream encoding supports 16-bit and
    /// 24-bit samples, however, not all fields in `STREAMINFO` are supported.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_FLAC")] Flac = 2,
    /// <summary>
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_MULAW")] Mulaw = 3,
    /// <summary>
    /// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_AMR")] Amr = 4,
    /// <summary>
    /// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_AMR_WB")] AmrWb = 5,
    /// <summary>
    /// Opus encoded audio frames in Ogg container
    /// ([OggOpus](https://wiki.xiph.org/OggOpus)).
    /// `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_OGG_OPUS")] OggOpus = 6,
    /// <summary>
    /// Although the use of lossy encodings is not recommended, if a very low
    /// bitrate encoding is required, `OGG_OPUS` is highly preferred over
    /// Speex encoding. The [Speex](https://speex.org/) encoding supported by
    /// Dialogflow API has a header byte in each block, as in MIME type
    /// `audio/x-speex-with-header-byte`.
    /// It is a variant of the RTP Speex encoding defined in
    /// [RFC 5574](https://tools.ietf.org/html/rfc5574).
    /// The stream is a sequence of blocks, one block per RTP packet. Each block
    /// starts with a byte containing the length of the block, in bytes, followed
    /// by one or more frames of Speex data, padded to an integral number of
    /// bytes (octets) as specified in RFC 5574. In other words, each RTP header
    /// is replaced with a single byte containing the block length. Only Speex
    /// wideband is supported. `sample_rate_hertz` must be 16000.
    /// </summary>
    [pbr::OriginalName("AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE")] SpeexWithHeaderByte = 7,
  }

  /// <summary>
  /// Variant of the specified [Speech model][google.cloud.dialogflow.v2.InputAudioConfig.model] to use.
  ///
  /// See the [Cloud Speech
  /// documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
  /// for which models have different variants. For example, the "phone_call" model
  /// has both a standard and an enhanced variant. When you use an enhanced model,
  /// you will generally receive higher quality results than for a standard model.
  /// </summary>
  public enum SpeechModelVariant {
    /// <summary>
    /// No model variant specified. In this case Dialogflow defaults to
    /// USE_BEST_AVAILABLE.
    /// </summary>
    [pbr::OriginalName("SPEECH_MODEL_VARIANT_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Use the best available variant of the [Speech
    /// model][InputAudioConfig.model] that the caller is eligible for.
    ///
    /// Please see the [Dialogflow
    /// docs](https://cloud.google.com/dialogflow/docs/data-logging) for
    /// how to make your project eligible for enhanced models.
    /// </summary>
    [pbr::OriginalName("USE_BEST_AVAILABLE")] UseBestAvailable = 1,
    /// <summary>
    /// Use standard model variant even if an enhanced model is available.  See the
    /// [Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
    /// for details about enhanced models.
    /// </summary>
    [pbr::OriginalName("USE_STANDARD")] UseStandard = 2,
    /// <summary>
    /// Use an enhanced model variant:
    ///
    /// * If an enhanced variant does not exist for the given
    ///   [model][google.cloud.dialogflow.v2.InputAudioConfig.model] and request language, Dialogflow falls
    ///   back to the standard variant.
    ///
    ///   The [Cloud Speech
    ///   documentation](https://cloud.google.com/speech-to-text/docs/enhanced-models)
    ///   describes which models have enhanced variants.
    ///
    /// * If the API caller isn't eligible for enhanced models, Dialogflow returns
    ///   an error. Please see the [Dialogflow
    ///   docs](https://cloud.google.com/dialogflow/docs/data-logging)
    ///   for how to make your project eligible.
    /// </summary>
    [pbr::OriginalName("USE_ENHANCED")] UseEnhanced = 3,
  }

  /// <summary>
  /// Gender of the voice as described in
  /// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
  /// </summary>
  public enum SsmlVoiceGender {
    /// <summary>
    /// An unspecified gender, which means that the client doesn't care which
    /// gender the selected voice will have.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// A male voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_MALE")] Male = 1,
    /// <summary>
    /// A female voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_FEMALE")] Female = 2,
    /// <summary>
    /// A gender-neutral voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_NEUTRAL")] Neutral = 3,
  }

  /// <summary>
  /// Audio encoding of the output audio format in Text-To-Speech.
  /// </summary>
  public enum OutputAudioEncoding {
    /// <summary>
    /// Not specified.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_LINEAR_16")] Linear16 = 1,
    /// <summary>
    /// MP3 audio at 32kbps.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MP3")] Mp3 = 2,
    /// <summary>
    /// MP3 audio at 64kbps.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MP3_64_KBPS")] Mp364Kbps = 4,
    /// <summary>
    /// Opus encoded audio wrapped in an ogg container. The result will be a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_OGG_OPUS")] OggOpus = 3,
    /// <summary>
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MULAW")] Mulaw = 5,
  }

  #endregion

  #region Messages
  /// <summary>
  /// Hints for the speech recognizer to help with recognition in a specific
  /// conversation state.
  /// </summary>
  public sealed partial class SpeechContext : pb::IMessage<SpeechContext>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechContext> _parser = new pb::MessageParser<SpeechContext>(() => new SpeechContext());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechContext> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext(SpeechContext other) : this() {
      phrases_ = other.phrases_.Clone();
      boost_ = other.boost_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext Clone() {
      return new SpeechContext(this);
    }

    /// <summary>Field number for the "phrases" field.</summary>
    public const int PhrasesFieldNumber = 1;
    private static readonly pb::FieldCodec<string> _repeated_phrases_codec
        = pb::FieldCodec.ForString(10);
    private readonly pbc::RepeatedField<string> phrases_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// Optional. A list of strings containing words and phrases that the speech
    /// recognizer should recognize with higher likelihood.
    ///
    /// This list can be used to:
    ///
    /// * improve accuracy for words and phrases you expect the user to say,
    ///   e.g. typical commands for your Dialogflow agent
    /// * add additional words to the speech recognizer vocabulary
    /// * ...
    ///
    /// See the [Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/quotas) for usage
    /// limits.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Phrases {
      get { return phrases_; }
    }

    /// <summary>Field number for the "boost" field.</summary>
    public const int BoostFieldNumber = 2;
    private float boost_;
    /// <summary>
    /// Optional. Boost for this context compared to other contexts:
    ///
    /// * If the boost is positive, Dialogflow will increase the probability that
    ///   the phrases in this context are recognized over similar sounding phrases.
    /// * If the boost is unspecified or non-positive, Dialogflow will not apply
    ///   any boost.
    ///
    /// Dialogflow recommends that you use boosts in the range (0, 20] and that you
    /// find a value that fits your use case with binary search.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Boost {
      get { return boost_; }
      set {
        boost_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechContext);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechContext other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!phrases_.Equals(other.phrases_)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.Equals(Boost, other.Boost)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= phrases_.GetHashCode();
      if (Boost != 0F) hash ^= pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.GetHashCode(Boost);
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      phrases_.WriteTo(output, _repeated_phrases_codec);
      if (Boost != 0F) {
        output.WriteRawTag(21);
        output.WriteFloat(Boost);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      phrases_.WriteTo(ref output, _repeated_phrases_codec);
      if (Boost != 0F) {
        output.WriteRawTag(21);
        output.WriteFloat(Boost);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += phrases_.CalculateSize(_repeated_phrases_codec);
      if (Boost != 0F) {
        size += 1 + 4;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechContext other) {
      if (other == null) {
        return;
      }
      phrases_.Add(other.phrases_);
      if (other.Boost != 0F) {
        Boost = other.Boost;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            phrases_.AddEntriesFrom(input, _repeated_phrases_codec);
            break;
          }
          case 21: {
            Boost = input.ReadFloat();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            phrases_.AddEntriesFrom(ref input, _repeated_phrases_codec);
            break;
          }
          case 21: {
            Boost = input.ReadFloat();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Information for a word recognized by the speech recognizer.
  /// </summary>
  public sealed partial class SpeechWordInfo : pb::IMessage<SpeechWordInfo>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechWordInfo> _parser = new pb::MessageParser<SpeechWordInfo>(() => new SpeechWordInfo());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechWordInfo> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo(SpeechWordInfo other) : this() {
      word_ = other.word_;
      startOffset_ = other.startOffset_ != null ? other.startOffset_.Clone() : null;
      endOffset_ = other.endOffset_ != null ? other.endOffset_.Clone() : null;
      confidence_ = other.confidence_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechWordInfo Clone() {
      return new SpeechWordInfo(this);
    }

    /// <summary>Field number for the "word" field.</summary>
    public const int WordFieldNumber = 3;
    private string word_ = "";
    /// <summary>
    /// The word this info is for.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Word {
      get { return word_; }
      set {
        word_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "start_offset" field.</summary>
    public const int StartOffsetFieldNumber = 1;
    private global::Google.Protobuf.WellKnownTypes.Duration startOffset_;
    /// <summary>
    /// Time offset relative to the beginning of the audio that corresponds to the
    /// start of the spoken word. This is an experimental feature and the accuracy
    /// of the time offset can vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration StartOffset {
      get { return startOffset_; }
      set {
        startOffset_ = value;
      }
    }

    /// <summary>Field number for the "end_offset" field.</summary>
    public const int EndOffsetFieldNumber = 2;
    private global::Google.Protobuf.WellKnownTypes.Duration endOffset_;
    /// <summary>
    /// Time offset relative to the beginning of the audio that corresponds to the
    /// end of the spoken word. This is an experimental feature and the accuracy of
    /// the time offset can vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration EndOffset {
      get { return endOffset_; }
      set {
        endOffset_ = value;
      }
    }

    /// <summary>Field number for the "confidence" field.</summary>
    public const int ConfidenceFieldNumber = 4;
    private float confidence_;
    /// <summary>
    /// The Speech confidence between 0.0 and 1.0 for this word. A higher number
    /// indicates an estimated greater likelihood that the recognized word is
    /// correct. The default of 0.0 is a sentinel value indicating that confidence
    /// was not set.
    ///
    /// This field is not guaranteed to be fully stable over time for the same
    /// audio input. Users should also not rely on it to always be provided.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Confidence {
      get { return confidence_; }
      set {
        confidence_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechWordInfo);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechWordInfo other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Word != other.Word) return false;
      if (!object.Equals(StartOffset, other.StartOffset)) return false;
      if (!object.Equals(EndOffset, other.EndOffset)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.Equals(Confidence, other.Confidence)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Word.Length != 0) hash ^= Word.GetHashCode();
      if (startOffset_ != null) hash ^= StartOffset.GetHashCode();
      if (endOffset_ != null) hash ^= EndOffset.GetHashCode();
      if (Confidence != 0F) hash ^= pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.GetHashCode(Confidence);
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (startOffset_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartOffset);
      }
      if (endOffset_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndOffset);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(37);
        output.WriteFloat(Confidence);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (startOffset_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartOffset);
      }
      if (endOffset_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndOffset);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(37);
        output.WriteFloat(Confidence);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Word.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Word);
      }
      if (startOffset_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StartOffset);
      }
      if (endOffset_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(EndOffset);
      }
      if (Confidence != 0F) {
        size += 1 + 4;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechWordInfo other) {
      if (other == null) {
        return;
      }
      if (other.Word.Length != 0) {
        Word = other.Word;
      }
      if (other.startOffset_ != null) {
        if (startOffset_ == null) {
          StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        StartOffset.MergeFrom(other.StartOffset);
      }
      if (other.endOffset_ != null) {
        if (endOffset_ == null) {
          EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        EndOffset.MergeFrom(other.EndOffset);
      }
      if (other.Confidence != 0F) {
        Confidence = other.Confidence;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (startOffset_ == null) {
              StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartOffset);
            break;
          }
          case 18: {
            if (endOffset_ == null) {
              EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndOffset);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 37: {
            Confidence = input.ReadFloat();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (startOffset_ == null) {
              StartOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartOffset);
            break;
          }
          case 18: {
            if (endOffset_ == null) {
              EndOffset = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndOffset);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 37: {
            Confidence = input.ReadFloat();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Instructs the speech recognizer how to process the audio content.
  /// </summary>
  public sealed partial class InputAudioConfig : pb::IMessage<InputAudioConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<InputAudioConfig> _parser = new pb::MessageParser<InputAudioConfig>(() => new InputAudioConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<InputAudioConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig(InputAudioConfig other) : this() {
      audioEncoding_ = other.audioEncoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      languageCode_ = other.languageCode_;
      enableWordInfo_ = other.enableWordInfo_;
      phraseHints_ = other.phraseHints_.Clone();
      speechContexts_ = other.speechContexts_.Clone();
      model_ = other.model_;
      modelVariant_ = other.modelVariant_;
      singleUtterance_ = other.singleUtterance_;
      disableNoSpeechRecognizedEvent_ = other.disableNoSpeechRecognizedEvent_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public InputAudioConfig Clone() {
      return new InputAudioConfig(this);
    }

    /// <summary>Field number for the "audio_encoding" field.</summary>
    public const int AudioEncodingFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.V2.AudioEncoding audioEncoding_ = global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified;
    /// <summary>
    /// Required. Audio encoding of the audio content to process.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.AudioEncoding AudioEncoding {
      get { return audioEncoding_; }
      set {
        audioEncoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// Required. Sample rate (in Hertz) of the audio content sent in the query.
    /// Refer to
    /// [Cloud Speech API
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics) for
    /// more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "language_code" field.</summary>
    public const int LanguageCodeFieldNumber = 3;
    private string languageCode_ = "";
    /// <summary>
    /// Required. The language of the supplied audio. Dialogflow does not do
    /// translations. See [Language
    /// Support](https://cloud.google.com/dialogflow/docs/reference/language)
    /// for a list of the currently supported language codes. Note that queries in
    /// the same session do not necessarily need to specify the same language.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string LanguageCode {
      get { return languageCode_; }
      set {
        languageCode_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "enable_word_info" field.</summary>
    public const int EnableWordInfoFieldNumber = 13;
    private bool enableWordInfo_;
    /// <summary>
    /// If `true`, Dialogflow returns [SpeechWordInfo][google.cloud.dialogflow.v2.SpeechWordInfo] in
    /// [StreamingRecognitionResult][google.cloud.dialogflow.v2.StreamingRecognitionResult] with information about the recognized speech
    /// words, e.g. start and end time offsets. If false or unspecified, Speech
    /// doesn't return any word-level information.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableWordInfo {
      get { return enableWordInfo_; }
      set {
        enableWordInfo_ = value;
      }
    }

    /// <summary>Field number for the "phrase_hints" field.</summary>
    public const int PhraseHintsFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_phraseHints_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> phraseHints_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// A list of strings containing words and phrases that the speech
    /// recognizer should recognize with higher likelihood.
    ///
    /// See [the Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
    /// for more details.
    ///
    /// This field is deprecated. Please use [speech_contexts]() instead. If you
    /// specify both [phrase_hints]() and [speech_contexts](), Dialogflow will
    /// treat the [phrase_hints]() as a single additional [SpeechContext]().
    /// </summary>
    [global::System.ObsoleteAttribute]
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> PhraseHints {
      get { return phraseHints_; }
    }

    /// <summary>Field number for the "speech_contexts" field.</summary>
    public const int SpeechContextsFieldNumber = 11;
    private static readonly pb::FieldCodec<global::Google.Cloud.Dialogflow.V2.SpeechContext> _repeated_speechContexts_codec
        = pb::FieldCodec.ForMessage(90, global::Google.Cloud.Dialogflow.V2.SpeechContext.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Dialogflow.V2.SpeechContext> speechContexts_ = new pbc::RepeatedField<global::Google.Cloud.Dialogflow.V2.SpeechContext>();
    /// <summary>
    /// Context information to assist speech recognition.
    ///
    /// See [the Cloud Speech
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
    /// for more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Dialogflow.V2.SpeechContext> SpeechContexts {
      get { return speechContexts_; }
    }

    /// <summary>Field number for the "model" field.</summary>
    public const int ModelFieldNumber = 7;
    private string model_ = "";
    /// <summary>
    /// Which Speech model to select for the given request. Select the
    /// model best suited to your domain to get best results. If a model is not
    /// explicitly specified, then we auto-select a model based on the parameters
    /// in the InputAudioConfig.
    /// If enhanced speech model is enabled for the agent and an enhanced
    /// version of the specified model for the language does not exist, then the
    /// speech is recognized using the standard version of the specified model.
    /// Refer to
    /// [Cloud Speech API
    /// documentation](https://cloud.google.com/speech-to-text/docs/basics#select-model)
    /// for more details.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Model {
      get { return model_; }
      set {
        model_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "model_variant" field.</summary>
    public const int ModelVariantFieldNumber = 10;
    private global::Google.Cloud.Dialogflow.V2.SpeechModelVariant modelVariant_ = global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified;
    /// <summary>
    /// Which variant of the [Speech model][google.cloud.dialogflow.v2.InputAudioConfig.model] to use.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SpeechModelVariant ModelVariant {
      get { return modelVariant_; }
      set {
        modelVariant_ = value;
      }
    }

    /// <summary>Field number for the "single_utterance" field.</summary>
    public const int SingleUtteranceFieldNumber = 8;
    private bool singleUtterance_;
    /// <summary>
    /// If `false` (default), recognition does not cease until the
    /// client closes the stream.
    /// If `true`, the recognizer will detect a single spoken utterance in input
    /// audio. Recognition ceases when it detects the audio's voice has
    /// stopped or paused. In this case, once a detected intent is received, the
    /// client should close the stream and start a new request with a new stream as
    /// needed.
    /// Note: This setting is relevant only for streaming methods.
    /// Note: When specified, InputAudioConfig.single_utterance takes precedence
    /// over StreamingDetectIntentRequest.single_utterance.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool SingleUtterance {
      get { return singleUtterance_; }
      set {
        singleUtterance_ = value;
      }
    }

    /// <summary>Field number for the "disable_no_speech_recognized_event" field.</summary>
    public const int DisableNoSpeechRecognizedEventFieldNumber = 14;
    private bool disableNoSpeechRecognizedEvent_;
    /// <summary>
    /// Only used in [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent] and
    /// [Participants.StreamingAnalyzeContent][google.cloud.dialogflow.v2.Participants.StreamingAnalyzeContent].
    /// If `false` and recognition doesn't return any result, trigger
    /// `NO_SPEECH_RECOGNIZED` event to Dialogflow agent.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DisableNoSpeechRecognizedEvent {
      get { return disableNoSpeechRecognizedEvent_; }
      set {
        disableNoSpeechRecognizedEvent_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as InputAudioConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(InputAudioConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioEncoding != other.AudioEncoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (LanguageCode != other.LanguageCode) return false;
      if (EnableWordInfo != other.EnableWordInfo) return false;
      if(!phraseHints_.Equals(other.phraseHints_)) return false;
      if(!speechContexts_.Equals(other.speechContexts_)) return false;
      if (Model != other.Model) return false;
      if (ModelVariant != other.ModelVariant) return false;
      if (SingleUtterance != other.SingleUtterance) return false;
      if (DisableNoSpeechRecognizedEvent != other.DisableNoSpeechRecognizedEvent) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified) hash ^= AudioEncoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (LanguageCode.Length != 0) hash ^= LanguageCode.GetHashCode();
      if (EnableWordInfo != false) hash ^= EnableWordInfo.GetHashCode();
      hash ^= phraseHints_.GetHashCode();
      hash ^= speechContexts_.GetHashCode();
      if (Model.Length != 0) hash ^= Model.GetHashCode();
      if (ModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) hash ^= ModelVariant.GetHashCode();
      if (SingleUtterance != false) hash ^= SingleUtterance.GetHashCode();
      if (DisableNoSpeechRecognizedEvent != false) hash ^= DisableNoSpeechRecognizedEvent.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(LanguageCode);
      }
      phraseHints_.WriteTo(output, _repeated_phraseHints_codec);
      if (Model.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(Model);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(64);
        output.WriteBool(SingleUtterance);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(80);
        output.WriteEnum((int) ModelVariant);
      }
      speechContexts_.WriteTo(output, _repeated_speechContexts_codec);
      if (EnableWordInfo != false) {
        output.WriteRawTag(104);
        output.WriteBool(EnableWordInfo);
      }
      if (DisableNoSpeechRecognizedEvent != false) {
        output.WriteRawTag(112);
        output.WriteBool(DisableNoSpeechRecognizedEvent);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(LanguageCode);
      }
      phraseHints_.WriteTo(ref output, _repeated_phraseHints_codec);
      if (Model.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(Model);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(64);
        output.WriteBool(SingleUtterance);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(80);
        output.WriteEnum((int) ModelVariant);
      }
      speechContexts_.WriteTo(ref output, _repeated_speechContexts_codec);
      if (EnableWordInfo != false) {
        output.WriteRawTag(104);
        output.WriteBool(EnableWordInfo);
      }
      if (DisableNoSpeechRecognizedEvent != false) {
        output.WriteRawTag(112);
        output.WriteBool(DisableNoSpeechRecognizedEvent);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (LanguageCode.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(LanguageCode);
      }
      if (EnableWordInfo != false) {
        size += 1 + 1;
      }
      size += phraseHints_.CalculateSize(_repeated_phraseHints_codec);
      size += speechContexts_.CalculateSize(_repeated_speechContexts_codec);
      if (Model.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Model);
      }
      if (ModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) ModelVariant);
      }
      if (SingleUtterance != false) {
        size += 1 + 1;
      }
      if (DisableNoSpeechRecognizedEvent != false) {
        size += 1 + 1;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(InputAudioConfig other) {
      if (other == null) {
        return;
      }
      if (other.AudioEncoding != global::Google.Cloud.Dialogflow.V2.AudioEncoding.Unspecified) {
        AudioEncoding = other.AudioEncoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.LanguageCode.Length != 0) {
        LanguageCode = other.LanguageCode;
      }
      if (other.EnableWordInfo != false) {
        EnableWordInfo = other.EnableWordInfo;
      }
      phraseHints_.Add(other.phraseHints_);
      speechContexts_.Add(other.speechContexts_);
      if (other.Model.Length != 0) {
        Model = other.Model;
      }
      if (other.ModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        ModelVariant = other.ModelVariant;
      }
      if (other.SingleUtterance != false) {
        SingleUtterance = other.SingleUtterance;
      }
      if (other.DisableNoSpeechRecognizedEvent != false) {
        DisableNoSpeechRecognizedEvent = other.DisableNoSpeechRecognizedEvent;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.V2.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            LanguageCode = input.ReadString();
            break;
          }
          case 34: {
            phraseHints_.AddEntriesFrom(input, _repeated_phraseHints_codec);
            break;
          }
          case 58: {
            Model = input.ReadString();
            break;
          }
          case 64: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 80: {
            ModelVariant = (global::Google.Cloud.Dialogflow.V2.SpeechModelVariant) input.ReadEnum();
            break;
          }
          case 90: {
            speechContexts_.AddEntriesFrom(input, _repeated_speechContexts_codec);
            break;
          }
          case 104: {
            EnableWordInfo = input.ReadBool();
            break;
          }
          case 112: {
            DisableNoSpeechRecognizedEvent = input.ReadBool();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.V2.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            LanguageCode = input.ReadString();
            break;
          }
          case 34: {
            phraseHints_.AddEntriesFrom(ref input, _repeated_phraseHints_codec);
            break;
          }
          case 58: {
            Model = input.ReadString();
            break;
          }
          case 64: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 80: {
            ModelVariant = (global::Google.Cloud.Dialogflow.V2.SpeechModelVariant) input.ReadEnum();
            break;
          }
          case 90: {
            speechContexts_.AddEntriesFrom(ref input, _repeated_speechContexts_codec);
            break;
          }
          case 104: {
            EnableWordInfo = input.ReadBool();
            break;
          }
          case 112: {
            DisableNoSpeechRecognizedEvent = input.ReadBool();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Description of which voice to use for speech synthesis.
  /// </summary>
  public sealed partial class VoiceSelectionParams : pb::IMessage<VoiceSelectionParams>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<VoiceSelectionParams> _parser = new pb::MessageParser<VoiceSelectionParams>(() => new VoiceSelectionParams());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<VoiceSelectionParams> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams(VoiceSelectionParams other) : this() {
      name_ = other.name_;
      ssmlGender_ = other.ssmlGender_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams Clone() {
      return new VoiceSelectionParams(this);
    }

    /// <summary>Field number for the "name" field.</summary>
    public const int NameFieldNumber = 1;
    private string name_ = "";
    /// <summary>
    /// Optional. The name of the voice. If not set, the service will choose a
    /// voice based on the other parameters such as language_code and
    /// [ssml_gender][google.cloud.dialogflow.v2.VoiceSelectionParams.ssml_gender].
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Name {
      get { return name_; }
      set {
        name_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "ssml_gender" field.</summary>
    public const int SsmlGenderFieldNumber = 2;
    private global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender ssmlGender_ = global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified;
    /// <summary>
    /// Optional. The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// [name][google.cloud.dialogflow.v2.VoiceSelectionParams.name]. Note that this is only a preference, not requirement. If a
    /// voice of the appropriate gender is not available, the synthesizer should
    /// substitute a voice with a different gender rather than failing the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender SsmlGender {
      get { return ssmlGender_; }
      set {
        ssmlGender_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as VoiceSelectionParams);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(VoiceSelectionParams other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Name != other.Name) return false;
      if (SsmlGender != other.SsmlGender) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Name.Length != 0) hash ^= Name.GetHashCode();
      if (SsmlGender != global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified) hash ^= SsmlGender.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (Name.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified) {
        output.WriteRawTag(16);
        output.WriteEnum((int) SsmlGender);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (Name.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified) {
        output.WriteRawTag(16);
        output.WriteEnum((int) SsmlGender);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Name.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Name);
      }
      if (SsmlGender != global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) SsmlGender);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(VoiceSelectionParams other) {
      if (other == null) {
        return;
      }
      if (other.Name.Length != 0) {
        Name = other.Name;
      }
      if (other.SsmlGender != global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender.Unspecified) {
        SsmlGender = other.SsmlGender;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            Name = input.ReadString();
            break;
          }
          case 16: {
            SsmlGender = (global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender) input.ReadEnum();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            Name = input.ReadString();
            break;
          }
          case 16: {
            SsmlGender = (global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender) input.ReadEnum();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Configuration of how speech should be synthesized.
  /// </summary>
  public sealed partial class SynthesizeSpeechConfig : pb::IMessage<SynthesizeSpeechConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SynthesizeSpeechConfig> _parser = new pb::MessageParser<SynthesizeSpeechConfig>(() => new SynthesizeSpeechConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SynthesizeSpeechConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig(SynthesizeSpeechConfig other) : this() {
      speakingRate_ = other.speakingRate_;
      pitch_ = other.pitch_;
      volumeGainDb_ = other.volumeGainDb_;
      effectsProfileId_ = other.effectsProfileId_.Clone();
      voice_ = other.voice_ != null ? other.voice_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig Clone() {
      return new SynthesizeSpeechConfig(this);
    }

    /// <summary>Field number for the "speaking_rate" field.</summary>
    public const int SpeakingRateFieldNumber = 1;
    private double speakingRate_;
    /// <summary>
    /// Optional. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is the normal
    /// native speed supported by the specific voice. 2.0 is twice as fast, and
    /// 0.5 is half as fast. If unset(0.0), defaults to the native 1.0 speed. Any
    /// other values &lt; 0.25 or > 4.0 will return an error.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double SpeakingRate {
      get { return speakingRate_; }
      set {
        speakingRate_ = value;
      }
    }

    /// <summary>Field number for the "pitch" field.</summary>
    public const int PitchFieldNumber = 2;
    private double pitch_;
    /// <summary>
    /// Optional. Speaking pitch, in the range [-20.0, 20.0]. 20 means increase 20
    /// semitones from the original pitch. -20 means decrease 20 semitones from the
    /// original pitch.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double Pitch {
      get { return pitch_; }
      set {
        pitch_ = value;
      }
    }

    /// <summary>Field number for the "volume_gain_db" field.</summary>
    public const int VolumeGainDbFieldNumber = 3;
    private double volumeGainDb_;
    /// <summary>
    /// Optional. Volume gain (in dB) of the normal native volume supported by the
    /// specific voice, in the range [-96.0, 16.0]. If unset, or set to a value of
    /// 0.0 (dB), will play at normal native signal amplitude. A value of -6.0 (dB)
    /// will play at approximately half the amplitude of the normal native signal
    /// amplitude. A value of +6.0 (dB) will play at approximately twice the
    /// amplitude of the normal native signal amplitude. We strongly recommend not
    /// to exceed +10 (dB) as there's usually no effective increase in loudness for
    /// any value greater than that.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double VolumeGainDb {
      get { return volumeGainDb_; }
      set {
        volumeGainDb_ = value;
      }
    }

    /// <summary>Field number for the "effects_profile_id" field.</summary>
    public const int EffectsProfileIdFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_effectsProfileId_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> effectsProfileId_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// Optional. An identifier which selects 'audio effects' profiles that are
    /// applied on (post synthesized) text to speech. Effects are applied on top of
    /// each other in the order they are given.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> EffectsProfileId {
      get { return effectsProfileId_; }
    }

    /// <summary>Field number for the "voice" field.</summary>
    public const int VoiceFieldNumber = 4;
    private global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams voice_;
    /// <summary>
    /// Optional. The desired voice of the synthesized audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams Voice {
      get { return voice_; }
      set {
        voice_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SynthesizeSpeechConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SynthesizeSpeechConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(SpeakingRate, other.SpeakingRate)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(Pitch, other.Pitch)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(VolumeGainDb, other.VolumeGainDb)) return false;
      if(!effectsProfileId_.Equals(other.effectsProfileId_)) return false;
      if (!object.Equals(Voice, other.Voice)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (SpeakingRate != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(SpeakingRate);
      if (Pitch != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(Pitch);
      if (VolumeGainDb != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(VolumeGainDb);
      hash ^= effectsProfileId_.GetHashCode();
      if (voice_ != null) hash ^= Voice.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (SpeakingRate != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(SpeakingRate);
      }
      if (Pitch != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Pitch);
      }
      if (VolumeGainDb != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(VolumeGainDb);
      }
      if (voice_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Voice);
      }
      effectsProfileId_.WriteTo(output, _repeated_effectsProfileId_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (SpeakingRate != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(SpeakingRate);
      }
      if (Pitch != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Pitch);
      }
      if (VolumeGainDb != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(VolumeGainDb);
      }
      if (voice_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Voice);
      }
      effectsProfileId_.WriteTo(ref output, _repeated_effectsProfileId_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (SpeakingRate != 0D) {
        size += 1 + 8;
      }
      if (Pitch != 0D) {
        size += 1 + 8;
      }
      if (VolumeGainDb != 0D) {
        size += 1 + 8;
      }
      size += effectsProfileId_.CalculateSize(_repeated_effectsProfileId_codec);
      if (voice_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Voice);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SynthesizeSpeechConfig other) {
      if (other == null) {
        return;
      }
      if (other.SpeakingRate != 0D) {
        SpeakingRate = other.SpeakingRate;
      }
      if (other.Pitch != 0D) {
        Pitch = other.Pitch;
      }
      if (other.VolumeGainDb != 0D) {
        VolumeGainDb = other.VolumeGainDb;
      }
      effectsProfileId_.Add(other.effectsProfileId_);
      if (other.voice_ != null) {
        if (voice_ == null) {
          Voice = new global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams();
        }
        Voice.MergeFrom(other.Voice);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 9: {
            SpeakingRate = input.ReadDouble();
            break;
          }
          case 17: {
            Pitch = input.ReadDouble();
            break;
          }
          case 25: {
            VolumeGainDb = input.ReadDouble();
            break;
          }
          case 34: {
            if (voice_ == null) {
              Voice = new global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams();
            }
            input.ReadMessage(Voice);
            break;
          }
          case 42: {
            effectsProfileId_.AddEntriesFrom(input, _repeated_effectsProfileId_codec);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 9: {
            SpeakingRate = input.ReadDouble();
            break;
          }
          case 17: {
            Pitch = input.ReadDouble();
            break;
          }
          case 25: {
            VolumeGainDb = input.ReadDouble();
            break;
          }
          case 34: {
            if (voice_ == null) {
              Voice = new global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams();
            }
            input.ReadMessage(Voice);
            break;
          }
          case 42: {
            effectsProfileId_.AddEntriesFrom(ref input, _repeated_effectsProfileId_codec);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Instructs the speech synthesizer on how to generate the output audio content.
  /// If this audio config is supplied in a request, it overrides all existing
  /// text-to-speech settings applied to the agent.
  /// </summary>
  public sealed partial class OutputAudioConfig : pb::IMessage<OutputAudioConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<OutputAudioConfig> _parser = new pb::MessageParser<OutputAudioConfig>(() => new OutputAudioConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<OutputAudioConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig(OutputAudioConfig other) : this() {
      audioEncoding_ = other.audioEncoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      synthesizeSpeechConfig_ = other.synthesizeSpeechConfig_ != null ? other.synthesizeSpeechConfig_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig Clone() {
      return new OutputAudioConfig(this);
    }

    /// <summary>Field number for the "audio_encoding" field.</summary>
    public const int AudioEncodingFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding audioEncoding_ = global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified;
    /// <summary>
    /// Required. Audio encoding of the synthesized audio content.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding AudioEncoding {
      get { return audioEncoding_; }
      set {
        audioEncoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// The synthesis sample rate (in hertz) for this audio. If not
    /// provided, then the synthesizer will use the default sample rate based on
    /// the audio encoding. If this is different from the voice's natural sample
    /// rate, then the synthesizer will honor this request by converting to the
    /// desired sample rate (which might result in worse audio quality).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "synthesize_speech_config" field.</summary>
    public const int SynthesizeSpeechConfigFieldNumber = 3;
    private global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig synthesizeSpeechConfig_;
    /// <summary>
    /// Configuration of how speech should be synthesized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig SynthesizeSpeechConfig {
      get { return synthesizeSpeechConfig_; }
      set {
        synthesizeSpeechConfig_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as OutputAudioConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(OutputAudioConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioEncoding != other.AudioEncoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (!object.Equals(SynthesizeSpeechConfig, other.SynthesizeSpeechConfig)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified) hash ^= AudioEncoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (synthesizeSpeechConfig_ != null) hash ^= SynthesizeSpeechConfig.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioEncoding != global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(OutputAudioConfig other) {
      if (other == null) {
        return;
      }
      if (other.AudioEncoding != global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding.Unspecified) {
        AudioEncoding = other.AudioEncoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.synthesizeSpeechConfig_ != null) {
        if (synthesizeSpeechConfig_ == null) {
          SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig();
        }
        SynthesizeSpeechConfig.MergeFrom(other.SynthesizeSpeechConfig);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            if (synthesizeSpeechConfig_ == null) {
              SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig();
            }
            input.ReadMessage(SynthesizeSpeechConfig);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            AudioEncoding = (global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            if (synthesizeSpeechConfig_ == null) {
              SynthesizeSpeechConfig = new global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig();
            }
            input.ReadMessage(SynthesizeSpeechConfig);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Configures speech transcription for [ConversationProfile][google.cloud.dialogflow.v2.ConversationProfile].
  /// </summary>
  public sealed partial class SpeechToTextConfig : pb::IMessage<SpeechToTextConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechToTextConfig> _parser = new pb::MessageParser<SpeechToTextConfig>(() => new SpeechToTextConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechToTextConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechToTextConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechToTextConfig(SpeechToTextConfig other) : this() {
      speechModelVariant_ = other.speechModelVariant_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechToTextConfig Clone() {
      return new SpeechToTextConfig(this);
    }

    /// <summary>Field number for the "speech_model_variant" field.</summary>
    public const int SpeechModelVariantFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.V2.SpeechModelVariant speechModelVariant_ = global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified;
    /// <summary>
    /// Optional. The speech model used in speech to text.
    /// `SPEECH_MODEL_VARIANT_UNSPECIFIED`, `USE_BEST_AVAILABLE` will be treated as
    /// `USE_ENHANCED`. It can be overridden in [AnalyzeContentRequest][google.cloud.dialogflow.v2.AnalyzeContentRequest] and
    /// [StreamingAnalyzeContentRequest][google.cloud.dialogflow.v2.StreamingAnalyzeContentRequest] request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SpeechModelVariant SpeechModelVariant {
      get { return speechModelVariant_; }
      set {
        speechModelVariant_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechToTextConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechToTextConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (SpeechModelVariant != other.SpeechModelVariant) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (SpeechModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) hash ^= SpeechModelVariant.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (SpeechModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) SpeechModelVariant);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (SpeechModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) SpeechModelVariant);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (SpeechModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) SpeechModelVariant);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechToTextConfig other) {
      if (other == null) {
        return;
      }
      if (other.SpeechModelVariant != global::Google.Cloud.Dialogflow.V2.SpeechModelVariant.Unspecified) {
        SpeechModelVariant = other.SpeechModelVariant;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            SpeechModelVariant = (global::Google.Cloud.Dialogflow.V2.SpeechModelVariant) input.ReadEnum();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            SpeechModelVariant = (global::Google.Cloud.Dialogflow.V2.SpeechModelVariant) input.ReadEnum();
            break;
          }
        }
      }
    }
    #endif

  }

  #endregion

}

#endregion Designer generated code
