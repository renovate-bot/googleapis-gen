// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: google/cloud/speech/v1/cloud_speech.proto
// </auto-generated>
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Speech.V1 {

  /// <summary>Holder for reflection information generated from google/cloud/speech/v1/cloud_speech.proto</summary>
  public static partial class CloudSpeechReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/speech/v1/cloud_speech.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static CloudSpeechReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Cilnb29nbGUvY2xvdWQvc3BlZWNoL3YxL2Nsb3VkX3NwZWVjaC5wcm90bxIW",
            "Z29vZ2xlLmNsb3VkLnNwZWVjaC52MRocZ29vZ2xlL2FwaS9hbm5vdGF0aW9u",
            "cy5wcm90bxoXZ29vZ2xlL2FwaS9jbGllbnQucHJvdG8aH2dvb2dsZS9hcGkv",
            "ZmllbGRfYmVoYXZpb3IucHJvdG8aI2dvb2dsZS9sb25ncnVubmluZy9vcGVy",
            "YXRpb25zLnByb3RvGhlnb29nbGUvcHJvdG9idWYvYW55LnByb3RvGh5nb29n",
            "bGUvcHJvdG9idWYvZHVyYXRpb24ucHJvdG8aH2dvb2dsZS9wcm90b2J1Zi90",
            "aW1lc3RhbXAucHJvdG8aHmdvb2dsZS9wcm90b2J1Zi93cmFwcGVycy5wcm90",
            "bxoXZ29vZ2xlL3JwYy9zdGF0dXMucHJvdG8ikAEKEFJlY29nbml6ZVJlcXVl",
            "c3QSPgoGY29uZmlnGAEgASgLMikuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MS5S",
            "ZWNvZ25pdGlvbkNvbmZpZ0ID4EECEjwKBWF1ZGlvGAIgASgLMiguZ29vZ2xl",
            "LmNsb3VkLnNwZWVjaC52MS5SZWNvZ25pdGlvbkF1ZGlvQgPgQQIimwEKG0xv",
            "bmdSdW5uaW5nUmVjb2duaXplUmVxdWVzdBI+CgZjb25maWcYASABKAsyKS5n",
            "b29nbGUuY2xvdWQuc3BlZWNoLnYxLlJlY29nbml0aW9uQ29uZmlnQgPgQQIS",
            "PAoFYXVkaW8YAiABKAsyKC5nb29nbGUuY2xvdWQuc3BlZWNoLnYxLlJlY29n",
            "bml0aW9uQXVkaW9CA+BBAiKZAQoZU3RyZWFtaW5nUmVjb2duaXplUmVxdWVz",
            "dBJOChBzdHJlYW1pbmdfY29uZmlnGAEgASgLMjIuZ29vZ2xlLmNsb3VkLnNw",
            "ZWVjaC52MS5TdHJlYW1pbmdSZWNvZ25pdGlvbkNvbmZpZ0gAEhcKDWF1ZGlv",
            "X2NvbnRlbnQYAiABKAxIAEITChFzdHJlYW1pbmdfcmVxdWVzdCKPAQoaU3Ry",
            "ZWFtaW5nUmVjb2duaXRpb25Db25maWcSPgoGY29uZmlnGAEgASgLMikuZ29v",
            "Z2xlLmNsb3VkLnNwZWVjaC52MS5SZWNvZ25pdGlvbkNvbmZpZ0ID4EECEhgK",
            "EHNpbmdsZV91dHRlcmFuY2UYAiABKAgSFwoPaW50ZXJpbV9yZXN1bHRzGAMg",
            "ASgIIt8FChFSZWNvZ25pdGlvbkNvbmZpZxJJCghlbmNvZGluZxgBIAEoDjI3",
            "Lmdvb2dsZS5jbG91ZC5zcGVlY2gudjEuUmVjb2duaXRpb25Db25maWcuQXVk",
            "aW9FbmNvZGluZxIZChFzYW1wbGVfcmF0ZV9oZXJ0ehgCIAEoBRIbChNhdWRp",
            "b19jaGFubmVsX2NvdW50GAcgASgFEi8KJ2VuYWJsZV9zZXBhcmF0ZV9yZWNv",
            "Z25pdGlvbl9wZXJfY2hhbm5lbBgMIAEoCBIaCg1sYW5ndWFnZV9jb2RlGAMg",
            "ASgJQgPgQQISGAoQbWF4X2FsdGVybmF0aXZlcxgEIAEoBRIYChBwcm9mYW5p",
            "dHlfZmlsdGVyGAUgASgIEj4KD3NwZWVjaF9jb250ZXh0cxgGIAMoCzIlLmdv",
            "b2dsZS5jbG91ZC5zcGVlY2gudjEuU3BlZWNoQ29udGV4dBIgChhlbmFibGVf",
            "d29yZF90aW1lX29mZnNldHMYCCABKAgSJAocZW5hYmxlX2F1dG9tYXRpY19w",
            "dW5jdHVhdGlvbhgLIAEoCBJMChJkaWFyaXphdGlvbl9jb25maWcYEyABKAsy",
            "MC5nb29nbGUuY2xvdWQuc3BlZWNoLnYxLlNwZWFrZXJEaWFyaXphdGlvbkNv",
            "bmZpZxI9CghtZXRhZGF0YRgJIAEoCzIrLmdvb2dsZS5jbG91ZC5zcGVlY2gu",
            "djEuUmVjb2duaXRpb25NZXRhZGF0YRINCgVtb2RlbBgNIAEoCRIUCgx1c2Vf",
            "ZW5oYW5jZWQYDiABKAgiiwEKDUF1ZGlvRW5jb2RpbmcSGAoURU5DT0RJTkdf",
            "VU5TUEVDSUZJRUQQABIMCghMSU5FQVIxNhABEggKBEZMQUMQAhIJCgVNVUxB",
            "VxADEgcKA0FNUhAEEgoKBkFNUl9XQhAFEgwKCE9HR19PUFVTEAYSGgoWU1BF",
            "RVhfV0lUSF9IRUFERVJfQllURRAHIpABChhTcGVha2VyRGlhcml6YXRpb25D",
            "b25maWcSIgoaZW5hYmxlX3NwZWFrZXJfZGlhcml6YXRpb24YASABKAgSGQoR",
            "bWluX3NwZWFrZXJfY291bnQYAiABKAUSGQoRbWF4X3NwZWFrZXJfY291bnQY",
            "AyABKAUSGgoLc3BlYWtlcl90YWcYBSABKAVCBRgB4EEDIqAIChNSZWNvZ25p",
            "dGlvbk1ldGFkYXRhElUKEGludGVyYWN0aW9uX3R5cGUYASABKA4yOy5nb29n",
            "bGUuY2xvdWQuc3BlZWNoLnYxLlJlY29nbml0aW9uTWV0YWRhdGEuSW50ZXJh",
            "Y3Rpb25UeXBlEiQKHGluZHVzdHJ5X25haWNzX2NvZGVfb2ZfYXVkaW8YAyAB",
            "KA0SWwoTbWljcm9waG9uZV9kaXN0YW5jZRgEIAEoDjI+Lmdvb2dsZS5jbG91",
            "ZC5zcGVlY2gudjEuUmVjb2duaXRpb25NZXRhZGF0YS5NaWNyb3Bob25lRGlz",
            "dGFuY2USWgoTb3JpZ2luYWxfbWVkaWFfdHlwZRgFIAEoDjI9Lmdvb2dsZS5j",
            "bG91ZC5zcGVlY2gudjEuUmVjb2duaXRpb25NZXRhZGF0YS5PcmlnaW5hbE1l",
            "ZGlhVHlwZRJeChVyZWNvcmRpbmdfZGV2aWNlX3R5cGUYBiABKA4yPy5nb29n",
            "bGUuY2xvdWQuc3BlZWNoLnYxLlJlY29nbml0aW9uTWV0YWRhdGEuUmVjb3Jk",
            "aW5nRGV2aWNlVHlwZRIdChVyZWNvcmRpbmdfZGV2aWNlX25hbWUYByABKAkS",
            "GgoSb3JpZ2luYWxfbWltZV90eXBlGAggASgJEhMKC2F1ZGlvX3RvcGljGAog",
            "ASgJIsUBCg9JbnRlcmFjdGlvblR5cGUSIAocSU5URVJBQ1RJT05fVFlQRV9V",
            "TlNQRUNJRklFRBAAEg4KCkRJU0NVU1NJT04QARIQCgxQUkVTRU5UQVRJT04Q",
            "AhIOCgpQSE9ORV9DQUxMEAMSDQoJVk9JQ0VNQUlMEAQSGwoXUFJPRkVTU0lP",
            "TkFMTFlfUFJPRFVDRUQQBRIQCgxWT0lDRV9TRUFSQ0gQBhIRCg1WT0lDRV9D",
            "T01NQU5EEAcSDQoJRElDVEFUSU9OEAgiZAoSTWljcm9waG9uZURpc3RhbmNl",
            "EiMKH01JQ1JPUEhPTkVfRElTVEFOQ0VfVU5TUEVDSUZJRUQQABINCglORUFS",
            "RklFTEQQARIMCghNSURGSUVMRBACEgwKCEZBUkZJRUxEEAMiTgoRT3JpZ2lu",
            "YWxNZWRpYVR5cGUSIwofT1JJR0lOQUxfTUVESUFfVFlQRV9VTlNQRUNJRklF",
            "RBAAEgkKBUFVRElPEAESCQoFVklERU8QAiKkAQoTUmVjb3JkaW5nRGV2aWNl",
            "VHlwZRIlCiFSRUNPUkRJTkdfREVWSUNFX1RZUEVfVU5TUEVDSUZJRUQQABIO",
            "CgpTTUFSVFBIT05FEAESBgoCUEMQAhIOCgpQSE9ORV9MSU5FEAMSCwoHVkVI",
            "SUNMRRAEEhgKFE9USEVSX09VVERPT1JfREVWSUNFEAUSFwoTT1RIRVJfSU5E",
            "T09SX0RFVklDRRAGIiAKDVNwZWVjaENvbnRleHQSDwoHcGhyYXNlcxgBIAMo",
            "CSJEChBSZWNvZ25pdGlvbkF1ZGlvEhEKB2NvbnRlbnQYASABKAxIABINCgN1",
            "cmkYAiABKAlIAEIOCgxhdWRpb19zb3VyY2UiiwEKEVJlY29nbml6ZVJlc3Bv",
            "bnNlEkAKB3Jlc3VsdHMYAiADKAsyLy5nb29nbGUuY2xvdWQuc3BlZWNoLnYx",
            "LlNwZWVjaFJlY29nbml0aW9uUmVzdWx0EjQKEXRvdGFsX2JpbGxlZF90aW1l",
            "GAMgASgLMhkuZ29vZ2xlLnByb3RvYnVmLkR1cmF0aW9uIpYBChxMb25nUnVu",
            "bmluZ1JlY29nbml6ZVJlc3BvbnNlEkAKB3Jlc3VsdHMYAiADKAsyLy5nb29n",
            "bGUuY2xvdWQuc3BlZWNoLnYxLlNwZWVjaFJlY29nbml0aW9uUmVzdWx0EjQK",
            "EXRvdGFsX2JpbGxlZF90aW1lGAMgASgLMhkuZ29vZ2xlLnByb3RvYnVmLkR1",
            "cmF0aW9uIrABChxMb25nUnVubmluZ1JlY29nbml6ZU1ldGFkYXRhEhgKEHBy",
            "b2dyZXNzX3BlcmNlbnQYASABKAUSLgoKc3RhcnRfdGltZRgCIAEoCzIaLmdv",
            "b2dsZS5wcm90b2J1Zi5UaW1lc3RhbXASNAoQbGFzdF91cGRhdGVfdGltZRgD",
            "IAEoCzIaLmdvb2dsZS5wcm90b2J1Zi5UaW1lc3RhbXASEAoDdXJpGAQgASgJ",
            "QgPgQQMi5wIKGlN0cmVhbWluZ1JlY29nbml6ZVJlc3BvbnNlEiEKBWVycm9y",
            "GAEgASgLMhIuZ29vZ2xlLnJwYy5TdGF0dXMSQwoHcmVzdWx0cxgCIAMoCzIy",
            "Lmdvb2dsZS5jbG91ZC5zcGVlY2gudjEuU3RyZWFtaW5nUmVjb2duaXRpb25S",
            "ZXN1bHQSXQoRc3BlZWNoX2V2ZW50X3R5cGUYBCABKA4yQi5nb29nbGUuY2xv",
            "dWQuc3BlZWNoLnYxLlN0cmVhbWluZ1JlY29nbml6ZVJlc3BvbnNlLlNwZWVj",
            "aEV2ZW50VHlwZRI0ChF0b3RhbF9iaWxsZWRfdGltZRgFIAEoCzIZLmdvb2ds",
            "ZS5wcm90b2J1Zi5EdXJhdGlvbiJMCg9TcGVlY2hFdmVudFR5cGUSHAoYU1BF",
            "RUNIX0VWRU5UX1VOU1BFQ0lGSUVEEAASGwoXRU5EX09GX1NJTkdMRV9VVFRF",
            "UkFOQ0UQASLyAQoaU3RyZWFtaW5nUmVjb2duaXRpb25SZXN1bHQSSgoMYWx0",
            "ZXJuYXRpdmVzGAEgAygLMjQuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MS5TcGVl",
            "Y2hSZWNvZ25pdGlvbkFsdGVybmF0aXZlEhAKCGlzX2ZpbmFsGAIgASgIEhEK",
            "CXN0YWJpbGl0eRgDIAEoAhIyCg9yZXN1bHRfZW5kX3RpbWUYBCABKAsyGS5n",
            "b29nbGUucHJvdG9idWYuRHVyYXRpb24SEwoLY2hhbm5lbF90YWcYBSABKAUS",
            "GgoNbGFuZ3VhZ2VfY29kZRgGIAEoCUID4EEDInoKF1NwZWVjaFJlY29nbml0",
            "aW9uUmVzdWx0EkoKDGFsdGVybmF0aXZlcxgBIAMoCzI0Lmdvb2dsZS5jbG91",
            "ZC5zcGVlY2gudjEuU3BlZWNoUmVjb2duaXRpb25BbHRlcm5hdGl2ZRITCgtj",
            "aGFubmVsX3RhZxgCIAEoBSJ3ChxTcGVlY2hSZWNvZ25pdGlvbkFsdGVybmF0",
            "aXZlEhIKCnRyYW5zY3JpcHQYASABKAkSEgoKY29uZmlkZW5jZRgCIAEoAhIv",
            "CgV3b3JkcxgDIAMoCzIgLmdvb2dsZS5jbG91ZC5zcGVlY2gudjEuV29yZElu",
            "Zm8ijgEKCFdvcmRJbmZvEi0KCnN0YXJ0X3RpbWUYASABKAsyGS5nb29nbGUu",
            "cHJvdG9idWYuRHVyYXRpb24SKwoIZW5kX3RpbWUYAiABKAsyGS5nb29nbGUu",
            "cHJvdG9idWYuRHVyYXRpb24SDAoEd29yZBgDIAEoCRIYCgtzcGVha2VyX3Rh",
            "ZxgFIAEoBUID4EEDMtEECgZTcGVlY2gSkAEKCVJlY29nbml6ZRIoLmdvb2ds",
            "ZS5jbG91ZC5zcGVlY2gudjEuUmVjb2duaXplUmVxdWVzdBopLmdvb2dsZS5j",
            "bG91ZC5zcGVlY2gudjEuUmVjb2duaXplUmVzcG9uc2UiLoLT5JMCGSIUL3Yx",
            "L3NwZWVjaDpyZWNvZ25pemU6ASraQQxjb25maWcsYXVkaW8S5AEKFExvbmdS",
            "dW5uaW5nUmVjb2duaXplEjMuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MS5Mb25n",
            "UnVubmluZ1JlY29nbml6ZVJlcXVlc3QaHS5nb29nbGUubG9uZ3J1bm5pbmcu",
            "T3BlcmF0aW9uIniC0+STAiQiHy92MS9zcGVlY2g6bG9uZ3J1bm5pbmdyZWNv",
            "Z25pemU6ASraQQxjb25maWcsYXVkaW/KQTwKHExvbmdSdW5uaW5nUmVjb2du",
            "aXplUmVzcG9uc2USHExvbmdSdW5uaW5nUmVjb2duaXplTWV0YWRhdGESgQEK",
            "ElN0cmVhbWluZ1JlY29nbml6ZRIxLmdvb2dsZS5jbG91ZC5zcGVlY2gudjEu",
            "U3RyZWFtaW5nUmVjb2duaXplUmVxdWVzdBoyLmdvb2dsZS5jbG91ZC5zcGVl",
            "Y2gudjEuU3RyZWFtaW5nUmVjb2duaXplUmVzcG9uc2UiACgBMAEaScpBFXNw",
            "ZWVjaC5nb29nbGVhcGlzLmNvbdJBLmh0dHBzOi8vd3d3Lmdvb2dsZWFwaXMu",
            "Y29tL2F1dGgvY2xvdWQtcGxhdGZvcm1CcgoaY29tLmdvb2dsZS5jbG91ZC5z",
            "cGVlY2gudjFCC1NwZWVjaFByb3RvUAFaPGdvb2dsZS5nb2xhbmcub3JnL2dl",
            "bnByb3RvL2dvb2dsZWFwaXMvY2xvdWQvc3BlZWNoL3YxO3NwZWVjaPgBAaIC",
            "A0dDU2IGcHJvdG8z"));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, global::Google.Api.ClientReflection.Descriptor, global::Google.Api.FieldBehaviorReflection.Descriptor, global::Google.LongRunning.OperationsReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.AnyReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.DurationReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.TimestampReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.WrappersReflection.Descriptor, global::Google.Rpc.StatusReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.RecognizeRequest), global::Google.Cloud.Speech.V1.RecognizeRequest.Parser, new[]{ "Config", "Audio" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.LongRunningRecognizeRequest), global::Google.Cloud.Speech.V1.LongRunningRecognizeRequest.Parser, new[]{ "Config", "Audio" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.StreamingRecognizeRequest), global::Google.Cloud.Speech.V1.StreamingRecognizeRequest.Parser, new[]{ "StreamingConfig", "AudioContent" }, new[]{ "StreamingRequest" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.StreamingRecognitionConfig), global::Google.Cloud.Speech.V1.StreamingRecognitionConfig.Parser, new[]{ "Config", "SingleUtterance", "InterimResults" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.RecognitionConfig), global::Google.Cloud.Speech.V1.RecognitionConfig.Parser, new[]{ "Encoding", "SampleRateHertz", "AudioChannelCount", "EnableSeparateRecognitionPerChannel", "LanguageCode", "MaxAlternatives", "ProfanityFilter", "SpeechContexts", "EnableWordTimeOffsets", "EnableAutomaticPunctuation", "DiarizationConfig", "Metadata", "Model", "UseEnhanced" }, null, new[]{ typeof(global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding) }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig), global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig.Parser, new[]{ "EnableSpeakerDiarization", "MinSpeakerCount", "MaxSpeakerCount", "SpeakerTag" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.RecognitionMetadata), global::Google.Cloud.Speech.V1.RecognitionMetadata.Parser, new[]{ "InteractionType", "IndustryNaicsCodeOfAudio", "MicrophoneDistance", "OriginalMediaType", "RecordingDeviceType", "RecordingDeviceName", "OriginalMimeType", "AudioTopic" }, null, new[]{ typeof(global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType), typeof(global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance), typeof(global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType), typeof(global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType) }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.SpeechContext), global::Google.Cloud.Speech.V1.SpeechContext.Parser, new[]{ "Phrases" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.RecognitionAudio), global::Google.Cloud.Speech.V1.RecognitionAudio.Parser, new[]{ "Content", "Uri" }, new[]{ "AudioSource" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.RecognizeResponse), global::Google.Cloud.Speech.V1.RecognizeResponse.Parser, new[]{ "Results", "TotalBilledTime" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.LongRunningRecognizeResponse), global::Google.Cloud.Speech.V1.LongRunningRecognizeResponse.Parser, new[]{ "Results", "TotalBilledTime" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.LongRunningRecognizeMetadata), global::Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.Parser, new[]{ "ProgressPercent", "StartTime", "LastUpdateTime", "Uri" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.StreamingRecognizeResponse), global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Parser, new[]{ "Error", "Results", "SpeechEventType", "TotalBilledTime" }, null, new[]{ typeof(global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType) }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.StreamingRecognitionResult), global::Google.Cloud.Speech.V1.StreamingRecognitionResult.Parser, new[]{ "Alternatives", "IsFinal", "Stability", "ResultEndTime", "ChannelTag", "LanguageCode" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.SpeechRecognitionResult), global::Google.Cloud.Speech.V1.SpeechRecognitionResult.Parser, new[]{ "Alternatives", "ChannelTag" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative), global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative.Parser, new[]{ "Transcript", "Confidence", "Words" }, null, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1.WordInfo), global::Google.Cloud.Speech.V1.WordInfo.Parser, new[]{ "StartTime", "EndTime", "Word", "SpeakerTag" }, null, null, null, null)
          }));
    }
    #endregion

  }
  #region Messages
  /// <summary>
  /// The top-level message sent by the client for the `Recognize` method.
  /// </summary>
  public sealed partial class RecognizeRequest : pb::IMessage<RecognizeRequest>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<RecognizeRequest> _parser = new pb::MessageParser<RecognizeRequest>(() => new RecognizeRequest());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeRequest(RecognizeRequest other) : this() {
      config_ = other.config_ != null ? other.config_.Clone() : null;
      audio_ = other.audio_ != null ? other.audio_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeRequest Clone() {
      return new RecognizeRequest(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1.RecognitionConfig config_;
    /// <summary>
    /// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "audio" field.</summary>
    public const int AudioFieldNumber = 2;
    private global::Google.Cloud.Speech.V1.RecognitionAudio audio_;
    /// <summary>
    /// Required. The audio data to be recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionAudio Audio {
      get { return audio_; }
      set {
        audio_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (!object.Equals(Audio, other.Audio)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (audio_ != null) hash ^= Audio.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (audio_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Audio);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognizeRequest other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.audio_ != null) {
        if (audio_ == null) {
          Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
        }
        Audio.MergeFrom(other.Audio);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 18: {
            if (audio_ == null) {
              Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
            }
            input.ReadMessage(Audio);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 18: {
            if (audio_ == null) {
              Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
            }
            input.ReadMessage(Audio);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// The top-level message sent by the client for the `LongRunningRecognize`
  /// method.
  /// </summary>
  public sealed partial class LongRunningRecognizeRequest : pb::IMessage<LongRunningRecognizeRequest>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<LongRunningRecognizeRequest> _parser = new pb::MessageParser<LongRunningRecognizeRequest>(() => new LongRunningRecognizeRequest());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<LongRunningRecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeRequest(LongRunningRecognizeRequest other) : this() {
      config_ = other.config_ != null ? other.config_.Clone() : null;
      audio_ = other.audio_ != null ? other.audio_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeRequest Clone() {
      return new LongRunningRecognizeRequest(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1.RecognitionConfig config_;
    /// <summary>
    /// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "audio" field.</summary>
    public const int AudioFieldNumber = 2;
    private global::Google.Cloud.Speech.V1.RecognitionAudio audio_;
    /// <summary>
    /// Required. The audio data to be recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionAudio Audio {
      get { return audio_; }
      set {
        audio_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as LongRunningRecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(LongRunningRecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (!object.Equals(Audio, other.Audio)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (audio_ != null) hash ^= Audio.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (audio_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Audio);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(LongRunningRecognizeRequest other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.audio_ != null) {
        if (audio_ == null) {
          Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
        }
        Audio.MergeFrom(other.Audio);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 18: {
            if (audio_ == null) {
              Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
            }
            input.ReadMessage(Audio);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 18: {
            if (audio_ == null) {
              Audio = new global::Google.Cloud.Speech.V1.RecognitionAudio();
            }
            input.ReadMessage(Audio);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// The top-level message sent by the client for the `StreamingRecognize` method.
  /// Multiple `StreamingRecognizeRequest` messages are sent. The first message
  /// must contain a `streaming_config` message and must not contain
  /// `audio_content`. All subsequent messages must contain `audio_content` and
  /// must not contain a `streaming_config` message.
  /// </summary>
  public sealed partial class StreamingRecognizeRequest : pb::IMessage<StreamingRecognizeRequest>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<StreamingRecognizeRequest> _parser = new pb::MessageParser<StreamingRecognizeRequest>(() => new StreamingRecognizeRequest());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest(StreamingRecognizeRequest other) : this() {
      switch (other.StreamingRequestCase) {
        case StreamingRequestOneofCase.StreamingConfig:
          StreamingConfig = other.StreamingConfig.Clone();
          break;
        case StreamingRequestOneofCase.AudioContent:
          AudioContent = other.AudioContent;
          break;
      }

      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest Clone() {
      return new StreamingRecognizeRequest(this);
    }

    /// <summary>Field number for the "streaming_config" field.</summary>
    public const int StreamingConfigFieldNumber = 1;
    /// <summary>
    /// Provides information to the recognizer that specifies how to process the
    /// request. The first `StreamingRecognizeRequest` message must contain a
    /// `streaming_config`  message.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.StreamingRecognitionConfig StreamingConfig {
      get { return streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig ? (global::Google.Cloud.Speech.V1.StreamingRecognitionConfig) streamingRequest_ : null; }
      set {
        streamingRequest_ = value;
        streamingRequestCase_ = value == null ? StreamingRequestOneofCase.None : StreamingRequestOneofCase.StreamingConfig;
      }
    }

    /// <summary>Field number for the "audio_content" field.</summary>
    public const int AudioContentFieldNumber = 2;
    /// <summary>
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `StreamingRecognizeRequest` messages. The first
    /// `StreamingRecognizeRequest` message must not contain `audio_content` data
    /// and all subsequent `StreamingRecognizeRequest` messages must contain
    /// `audio_content` data. The audio bytes must be encoded as specified in
    /// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
    /// pure binary representation (not base64). See
    /// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString AudioContent {
      get { return streamingRequestCase_ == StreamingRequestOneofCase.AudioContent ? (pb::ByteString) streamingRequest_ : pb::ByteString.Empty; }
      set {
        streamingRequest_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        streamingRequestCase_ = StreamingRequestOneofCase.AudioContent;
      }
    }

    private object streamingRequest_;
    /// <summary>Enum of possible cases for the "streaming_request" oneof.</summary>
    public enum StreamingRequestOneofCase {
      None = 0,
      StreamingConfig = 1,
      AudioContent = 2,
    }
    private StreamingRequestOneofCase streamingRequestCase_ = StreamingRequestOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRequestOneofCase StreamingRequestCase {
      get { return streamingRequestCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearStreamingRequest() {
      streamingRequestCase_ = StreamingRequestOneofCase.None;
      streamingRequest_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(StreamingConfig, other.StreamingConfig)) return false;
      if (AudioContent != other.AudioContent) return false;
      if (StreamingRequestCase != other.StreamingRequestCase) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) hash ^= StreamingConfig.GetHashCode();
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) hash ^= AudioContent.GetHashCode();
      hash ^= (int) streamingRequestCase_;
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
        output.WriteRawTag(10);
        output.WriteMessage(StreamingConfig);
      }
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) {
        output.WriteRawTag(18);
        output.WriteBytes(AudioContent);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
        output.WriteRawTag(10);
        output.WriteMessage(StreamingConfig);
      }
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) {
        output.WriteRawTag(18);
        output.WriteBytes(AudioContent);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StreamingConfig);
      }
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(AudioContent);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognizeRequest other) {
      if (other == null) {
        return;
      }
      switch (other.StreamingRequestCase) {
        case StreamingRequestOneofCase.StreamingConfig:
          if (StreamingConfig == null) {
            StreamingConfig = new global::Google.Cloud.Speech.V1.StreamingRecognitionConfig();
          }
          StreamingConfig.MergeFrom(other.StreamingConfig);
          break;
        case StreamingRequestOneofCase.AudioContent:
          AudioContent = other.AudioContent;
          break;
      }

      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            global::Google.Cloud.Speech.V1.StreamingRecognitionConfig subBuilder = new global::Google.Cloud.Speech.V1.StreamingRecognitionConfig();
            if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
              subBuilder.MergeFrom(StreamingConfig);
            }
            input.ReadMessage(subBuilder);
            StreamingConfig = subBuilder;
            break;
          }
          case 18: {
            AudioContent = input.ReadBytes();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            global::Google.Cloud.Speech.V1.StreamingRecognitionConfig subBuilder = new global::Google.Cloud.Speech.V1.StreamingRecognitionConfig();
            if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
              subBuilder.MergeFrom(StreamingConfig);
            }
            input.ReadMessage(subBuilder);
            StreamingConfig = subBuilder;
            break;
          }
          case 18: {
            AudioContent = input.ReadBytes();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Provides information to the recognizer that specifies how to process the
  /// request.
  /// </summary>
  public sealed partial class StreamingRecognitionConfig : pb::IMessage<StreamingRecognitionConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<StreamingRecognitionConfig> _parser = new pb::MessageParser<StreamingRecognitionConfig>(() => new StreamingRecognitionConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognitionConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig(StreamingRecognitionConfig other) : this() {
      config_ = other.config_ != null ? other.config_.Clone() : null;
      singleUtterance_ = other.singleUtterance_;
      interimResults_ = other.interimResults_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig Clone() {
      return new StreamingRecognitionConfig(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1.RecognitionConfig config_;
    /// <summary>
    /// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "single_utterance" field.</summary>
    public const int SingleUtteranceFieldNumber = 2;
    private bool singleUtterance_;
    /// <summary>
    /// If `false` or omitted, the recognizer will perform continuous
    /// recognition (continuing to wait for and process audio even if the user
    /// pauses speaking) until the client closes the input stream (gRPC API) or
    /// until the maximum time limit has been reached. May return multiple
    /// `StreamingRecognitionResult`s with the `is_final` flag set to `true`.
    ///
    /// If `true`, the recognizer will detect a single spoken utterance. When it
    /// detects that the user has paused or stopped speaking, it will return an
    /// `END_OF_SINGLE_UTTERANCE` event and cease recognition. It will return no
    /// more than one `StreamingRecognitionResult` with the `is_final` flag set to
    /// `true`.
    ///
    /// The `single_utterance` field can only be used with specified models,
    /// otherwise an error is thrown. The `model` field in [`RecognitionConfig`][]
    /// must be set to:
    ///
    /// * `command_and_search`
    /// * `phone_call` AND additional field `useEnhanced`=`true`
    /// * The `model` field is left undefined. In this case the API auto-selects
    ///   a model based on any other parameters that you set in
    ///   `RecognitionConfig`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool SingleUtterance {
      get { return singleUtterance_; }
      set {
        singleUtterance_ = value;
      }
    }

    /// <summary>Field number for the "interim_results" field.</summary>
    public const int InterimResultsFieldNumber = 3;
    private bool interimResults_;
    /// <summary>
    /// If `true`, interim results (tentative hypotheses) may be
    /// returned as they become available (these interim results are indicated with
    /// the `is_final=false` flag).
    /// If `false` or omitted, only `is_final=true` result(s) are returned.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool InterimResults {
      get { return interimResults_; }
      set {
        interimResults_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognitionConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognitionConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (SingleUtterance != other.SingleUtterance) return false;
      if (InterimResults != other.InterimResults) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (SingleUtterance != false) hash ^= SingleUtterance.GetHashCode();
      if (InterimResults != false) hash ^= InterimResults.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(16);
        output.WriteBool(SingleUtterance);
      }
      if (InterimResults != false) {
        output.WriteRawTag(24);
        output.WriteBool(InterimResults);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(16);
        output.WriteBool(SingleUtterance);
      }
      if (InterimResults != false) {
        output.WriteRawTag(24);
        output.WriteBool(InterimResults);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (SingleUtterance != false) {
        size += 1 + 1;
      }
      if (InterimResults != false) {
        size += 1 + 1;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognitionConfig other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.SingleUtterance != false) {
        SingleUtterance = other.SingleUtterance;
      }
      if (other.InterimResults != false) {
        InterimResults = other.InterimResults;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 16: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 24: {
            InterimResults = input.ReadBool();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (config_ == null) {
              Config = new global::Google.Cloud.Speech.V1.RecognitionConfig();
            }
            input.ReadMessage(Config);
            break;
          }
          case 16: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 24: {
            InterimResults = input.ReadBool();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Provides information to the recognizer that specifies how to process the
  /// request.
  /// </summary>
  public sealed partial class RecognitionConfig : pb::IMessage<RecognitionConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<RecognitionConfig> _parser = new pb::MessageParser<RecognitionConfig>(() => new RecognitionConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognitionConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig(RecognitionConfig other) : this() {
      encoding_ = other.encoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      audioChannelCount_ = other.audioChannelCount_;
      enableSeparateRecognitionPerChannel_ = other.enableSeparateRecognitionPerChannel_;
      languageCode_ = other.languageCode_;
      maxAlternatives_ = other.maxAlternatives_;
      profanityFilter_ = other.profanityFilter_;
      speechContexts_ = other.speechContexts_.Clone();
      enableWordTimeOffsets_ = other.enableWordTimeOffsets_;
      enableAutomaticPunctuation_ = other.enableAutomaticPunctuation_;
      diarizationConfig_ = other.diarizationConfig_ != null ? other.diarizationConfig_.Clone() : null;
      metadata_ = other.metadata_ != null ? other.metadata_.Clone() : null;
      model_ = other.model_;
      useEnhanced_ = other.useEnhanced_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig Clone() {
      return new RecognitionConfig(this);
    }

    /// <summary>Field number for the "encoding" field.</summary>
    public const int EncodingFieldNumber = 1;
    private global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding encoding_ = global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified;
    /// <summary>
    /// Encoding of audio data sent in all `RecognitionAudio` messages.
    /// This field is optional for `FLAC` and `WAV` audio files and required
    /// for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding Encoding {
      get { return encoding_; }
      set {
        encoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// Sample rate in Hertz of the audio data sent in all
    /// `RecognitionAudio` messages. Valid values are: 8000-48000.
    /// 16000 is optimal. For best results, set the sampling rate of the audio
    /// source to 16000 Hz. If that's not possible, use the native sample rate of
    /// the audio source (instead of re-sampling).
    /// This field is optional for FLAC and WAV audio files, but is
    /// required for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "audio_channel_count" field.</summary>
    public const int AudioChannelCountFieldNumber = 7;
    private int audioChannelCount_;
    /// <summary>
    /// The number of channels in the input audio data.
    /// ONLY set this for MULTI-CHANNEL recognition.
    /// Valid values for LINEAR16 and FLAC are `1`-`8`.
    /// Valid values for OGG_OPUS are '1'-'254'.
    /// Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
    /// If `0` or omitted, defaults to one channel (mono).
    /// Note: We only recognize the first channel by default.
    /// To perform independent recognition on each channel set
    /// `enable_separate_recognition_per_channel` to 'true'.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int AudioChannelCount {
      get { return audioChannelCount_; }
      set {
        audioChannelCount_ = value;
      }
    }

    /// <summary>Field number for the "enable_separate_recognition_per_channel" field.</summary>
    public const int EnableSeparateRecognitionPerChannelFieldNumber = 12;
    private bool enableSeparateRecognitionPerChannel_;
    /// <summary>
    /// This needs to be set to `true` explicitly and `audio_channel_count` > 1
    /// to get each channel recognized separately. The recognition result will
    /// contain a `channel_tag` field to state which channel that result belongs
    /// to. If this is not true, we will only recognize the first channel. The
    /// request is billed cumulatively for all channels recognized:
    /// `audio_channel_count` multiplied by the length of the audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableSeparateRecognitionPerChannel {
      get { return enableSeparateRecognitionPerChannel_; }
      set {
        enableSeparateRecognitionPerChannel_ = value;
      }
    }

    /// <summary>Field number for the "language_code" field.</summary>
    public const int LanguageCodeFieldNumber = 3;
    private string languageCode_ = "";
    /// <summary>
    /// Required. The language of the supplied audio as a
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    /// Example: "en-US".
    /// See [Language
    /// Support](https://cloud.google.com/speech-to-text/docs/languages) for a list
    /// of the currently supported language codes.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string LanguageCode {
      get { return languageCode_; }
      set {
        languageCode_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "max_alternatives" field.</summary>
    public const int MaxAlternativesFieldNumber = 4;
    private int maxAlternatives_;
    /// <summary>
    /// Maximum number of recognition hypotheses to be returned.
    /// Specifically, the maximum number of `SpeechRecognitionAlternative` messages
    /// within each `SpeechRecognitionResult`.
    /// The server may return fewer than `max_alternatives`.
    /// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
    /// one. If omitted, will return a maximum of one.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int MaxAlternatives {
      get { return maxAlternatives_; }
      set {
        maxAlternatives_ = value;
      }
    }

    /// <summary>Field number for the "profanity_filter" field.</summary>
    public const int ProfanityFilterFieldNumber = 5;
    private bool profanityFilter_;
    /// <summary>
    /// If set to `true`, the server will attempt to filter out
    /// profanities, replacing all but the initial character in each filtered word
    /// with asterisks, e.g. "f***". If set to `false` or omitted, profanities
    /// won't be filtered out.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ProfanityFilter {
      get { return profanityFilter_; }
      set {
        profanityFilter_ = value;
      }
    }

    /// <summary>Field number for the "speech_contexts" field.</summary>
    public const int SpeechContextsFieldNumber = 6;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.SpeechContext> _repeated_speechContexts_codec
        = pb::FieldCodec.ForMessage(50, global::Google.Cloud.Speech.V1.SpeechContext.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechContext> speechContexts_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechContext>();
    /// <summary>
    /// Array of [SpeechContext][google.cloud.speech.v1.SpeechContext].
    /// A means to provide context to assist the speech recognition. For more
    /// information, see
    /// [speech
    /// adaptation](https://cloud.google.com/speech-to-text/docs/adaptation).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechContext> SpeechContexts {
      get { return speechContexts_; }
    }

    /// <summary>Field number for the "enable_word_time_offsets" field.</summary>
    public const int EnableWordTimeOffsetsFieldNumber = 8;
    private bool enableWordTimeOffsets_;
    /// <summary>
    /// If `true`, the top result includes a list of words and
    /// the start and end time offsets (timestamps) for those words. If
    /// `false`, no word-level time offset information is returned. The default is
    /// `false`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableWordTimeOffsets {
      get { return enableWordTimeOffsets_; }
      set {
        enableWordTimeOffsets_ = value;
      }
    }

    /// <summary>Field number for the "enable_automatic_punctuation" field.</summary>
    public const int EnableAutomaticPunctuationFieldNumber = 11;
    private bool enableAutomaticPunctuation_;
    /// <summary>
    /// If 'true', adds punctuation to recognition result hypotheses.
    /// This feature is only available in select languages. Setting this for
    /// requests in other languages has no effect at all.
    /// The default 'false' value does not add punctuation to result hypotheses.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableAutomaticPunctuation {
      get { return enableAutomaticPunctuation_; }
      set {
        enableAutomaticPunctuation_ = value;
      }
    }

    /// <summary>Field number for the "diarization_config" field.</summary>
    public const int DiarizationConfigFieldNumber = 19;
    private global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig diarizationConfig_;
    /// <summary>
    /// Config to enable speaker diarization and set additional
    /// parameters to make diarization better suited for your application.
    /// Note: When this is enabled, we send all the words from the beginning of the
    /// audio for the top alternative in every consecutive STREAMING responses.
    /// This is done in order to improve our speaker tags as our models learn to
    /// identify the speakers in the conversation over time.
    /// For non-streaming requests, the diarization results will be provided only
    /// in the top alternative of the FINAL SpeechRecognitionResult.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig DiarizationConfig {
      get { return diarizationConfig_; }
      set {
        diarizationConfig_ = value;
      }
    }

    /// <summary>Field number for the "metadata" field.</summary>
    public const int MetadataFieldNumber = 9;
    private global::Google.Cloud.Speech.V1.RecognitionMetadata metadata_;
    /// <summary>
    /// Metadata regarding this request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionMetadata Metadata {
      get { return metadata_; }
      set {
        metadata_ = value;
      }
    }

    /// <summary>Field number for the "model" field.</summary>
    public const int ModelFieldNumber = 13;
    private string model_ = "";
    /// <summary>
    /// Which model to select for the given request. Select the model
    /// best suited to your domain to get best results. If a model is not
    /// explicitly specified, then we auto-select a model based on the parameters
    /// in the RecognitionConfig.
    /// &lt;table>
    ///   &lt;tr>
    ///     &lt;td>&lt;b>Model&lt;/b>&lt;/td>
    ///     &lt;td>&lt;b>Description&lt;/b>&lt;/td>
    ///   &lt;/tr>
    ///   &lt;tr>
    ///     &lt;td>&lt;code>command_and_search&lt;/code>&lt;/td>
    ///     &lt;td>Best for short queries such as voice commands or voice search.&lt;/td>
    ///   &lt;/tr>
    ///   &lt;tr>
    ///     &lt;td>&lt;code>phone_call&lt;/code>&lt;/td>
    ///     &lt;td>Best for audio that originated from a phone call (typically
    ///     recorded at an 8khz sampling rate).&lt;/td>
    ///   &lt;/tr>
    ///   &lt;tr>
    ///     &lt;td>&lt;code>video&lt;/code>&lt;/td>
    ///     &lt;td>Best for audio that originated from video or includes multiple
    ///         speakers. Ideally the audio is recorded at a 16khz or greater
    ///         sampling rate. This is a premium model that costs more than the
    ///         standard rate.&lt;/td>
    ///   &lt;/tr>
    ///   &lt;tr>
    ///     &lt;td>&lt;code>default&lt;/code>&lt;/td>
    ///     &lt;td>Best for audio that is not one of the specific audio models.
    ///         For example, long-form audio. Ideally the audio is high-fidelity,
    ///         recorded at a 16khz or greater sampling rate.&lt;/td>
    ///   &lt;/tr>
    /// &lt;/table>
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Model {
      get { return model_; }
      set {
        model_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "use_enhanced" field.</summary>
    public const int UseEnhancedFieldNumber = 14;
    private bool useEnhanced_;
    /// <summary>
    /// Set to true to use an enhanced model for speech recognition.
    /// If `use_enhanced` is set to true and the `model` field is not set, then
    /// an appropriate enhanced model is chosen if an enhanced model exists for
    /// the audio.
    ///
    /// If `use_enhanced` is true and an enhanced version of the specified model
    /// does not exist, then the speech is recognized using the standard version
    /// of the specified model.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool UseEnhanced {
      get { return useEnhanced_; }
      set {
        useEnhanced_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognitionConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognitionConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Encoding != other.Encoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (AudioChannelCount != other.AudioChannelCount) return false;
      if (EnableSeparateRecognitionPerChannel != other.EnableSeparateRecognitionPerChannel) return false;
      if (LanguageCode != other.LanguageCode) return false;
      if (MaxAlternatives != other.MaxAlternatives) return false;
      if (ProfanityFilter != other.ProfanityFilter) return false;
      if(!speechContexts_.Equals(other.speechContexts_)) return false;
      if (EnableWordTimeOffsets != other.EnableWordTimeOffsets) return false;
      if (EnableAutomaticPunctuation != other.EnableAutomaticPunctuation) return false;
      if (!object.Equals(DiarizationConfig, other.DiarizationConfig)) return false;
      if (!object.Equals(Metadata, other.Metadata)) return false;
      if (Model != other.Model) return false;
      if (UseEnhanced != other.UseEnhanced) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Encoding != global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified) hash ^= Encoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (AudioChannelCount != 0) hash ^= AudioChannelCount.GetHashCode();
      if (EnableSeparateRecognitionPerChannel != false) hash ^= EnableSeparateRecognitionPerChannel.GetHashCode();
      if (LanguageCode.Length != 0) hash ^= LanguageCode.GetHashCode();
      if (MaxAlternatives != 0) hash ^= MaxAlternatives.GetHashCode();
      if (ProfanityFilter != false) hash ^= ProfanityFilter.GetHashCode();
      hash ^= speechContexts_.GetHashCode();
      if (EnableWordTimeOffsets != false) hash ^= EnableWordTimeOffsets.GetHashCode();
      if (EnableAutomaticPunctuation != false) hash ^= EnableAutomaticPunctuation.GetHashCode();
      if (diarizationConfig_ != null) hash ^= DiarizationConfig.GetHashCode();
      if (metadata_ != null) hash ^= Metadata.GetHashCode();
      if (Model.Length != 0) hash ^= Model.GetHashCode();
      if (UseEnhanced != false) hash ^= UseEnhanced.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (Encoding != global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(LanguageCode);
      }
      if (MaxAlternatives != 0) {
        output.WriteRawTag(32);
        output.WriteInt32(MaxAlternatives);
      }
      if (ProfanityFilter != false) {
        output.WriteRawTag(40);
        output.WriteBool(ProfanityFilter);
      }
      speechContexts_.WriteTo(output, _repeated_speechContexts_codec);
      if (AudioChannelCount != 0) {
        output.WriteRawTag(56);
        output.WriteInt32(AudioChannelCount);
      }
      if (EnableWordTimeOffsets != false) {
        output.WriteRawTag(64);
        output.WriteBool(EnableWordTimeOffsets);
      }
      if (metadata_ != null) {
        output.WriteRawTag(74);
        output.WriteMessage(Metadata);
      }
      if (EnableAutomaticPunctuation != false) {
        output.WriteRawTag(88);
        output.WriteBool(EnableAutomaticPunctuation);
      }
      if (EnableSeparateRecognitionPerChannel != false) {
        output.WriteRawTag(96);
        output.WriteBool(EnableSeparateRecognitionPerChannel);
      }
      if (Model.Length != 0) {
        output.WriteRawTag(106);
        output.WriteString(Model);
      }
      if (UseEnhanced != false) {
        output.WriteRawTag(112);
        output.WriteBool(UseEnhanced);
      }
      if (diarizationConfig_ != null) {
        output.WriteRawTag(154, 1);
        output.WriteMessage(DiarizationConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (Encoding != global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(LanguageCode);
      }
      if (MaxAlternatives != 0) {
        output.WriteRawTag(32);
        output.WriteInt32(MaxAlternatives);
      }
      if (ProfanityFilter != false) {
        output.WriteRawTag(40);
        output.WriteBool(ProfanityFilter);
      }
      speechContexts_.WriteTo(ref output, _repeated_speechContexts_codec);
      if (AudioChannelCount != 0) {
        output.WriteRawTag(56);
        output.WriteInt32(AudioChannelCount);
      }
      if (EnableWordTimeOffsets != false) {
        output.WriteRawTag(64);
        output.WriteBool(EnableWordTimeOffsets);
      }
      if (metadata_ != null) {
        output.WriteRawTag(74);
        output.WriteMessage(Metadata);
      }
      if (EnableAutomaticPunctuation != false) {
        output.WriteRawTag(88);
        output.WriteBool(EnableAutomaticPunctuation);
      }
      if (EnableSeparateRecognitionPerChannel != false) {
        output.WriteRawTag(96);
        output.WriteBool(EnableSeparateRecognitionPerChannel);
      }
      if (Model.Length != 0) {
        output.WriteRawTag(106);
        output.WriteString(Model);
      }
      if (UseEnhanced != false) {
        output.WriteRawTag(112);
        output.WriteBool(UseEnhanced);
      }
      if (diarizationConfig_ != null) {
        output.WriteRawTag(154, 1);
        output.WriteMessage(DiarizationConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Encoding != global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (AudioChannelCount != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(AudioChannelCount);
      }
      if (EnableSeparateRecognitionPerChannel != false) {
        size += 1 + 1;
      }
      if (LanguageCode.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(LanguageCode);
      }
      if (MaxAlternatives != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(MaxAlternatives);
      }
      if (ProfanityFilter != false) {
        size += 1 + 1;
      }
      size += speechContexts_.CalculateSize(_repeated_speechContexts_codec);
      if (EnableWordTimeOffsets != false) {
        size += 1 + 1;
      }
      if (EnableAutomaticPunctuation != false) {
        size += 1 + 1;
      }
      if (diarizationConfig_ != null) {
        size += 2 + pb::CodedOutputStream.ComputeMessageSize(DiarizationConfig);
      }
      if (metadata_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Metadata);
      }
      if (Model.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Model);
      }
      if (UseEnhanced != false) {
        size += 1 + 1;
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognitionConfig other) {
      if (other == null) {
        return;
      }
      if (other.Encoding != global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding.EncodingUnspecified) {
        Encoding = other.Encoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.AudioChannelCount != 0) {
        AudioChannelCount = other.AudioChannelCount;
      }
      if (other.EnableSeparateRecognitionPerChannel != false) {
        EnableSeparateRecognitionPerChannel = other.EnableSeparateRecognitionPerChannel;
      }
      if (other.LanguageCode.Length != 0) {
        LanguageCode = other.LanguageCode;
      }
      if (other.MaxAlternatives != 0) {
        MaxAlternatives = other.MaxAlternatives;
      }
      if (other.ProfanityFilter != false) {
        ProfanityFilter = other.ProfanityFilter;
      }
      speechContexts_.Add(other.speechContexts_);
      if (other.EnableWordTimeOffsets != false) {
        EnableWordTimeOffsets = other.EnableWordTimeOffsets;
      }
      if (other.EnableAutomaticPunctuation != false) {
        EnableAutomaticPunctuation = other.EnableAutomaticPunctuation;
      }
      if (other.diarizationConfig_ != null) {
        if (diarizationConfig_ == null) {
          DiarizationConfig = new global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig();
        }
        DiarizationConfig.MergeFrom(other.DiarizationConfig);
      }
      if (other.metadata_ != null) {
        if (metadata_ == null) {
          Metadata = new global::Google.Cloud.Speech.V1.RecognitionMetadata();
        }
        Metadata.MergeFrom(other.Metadata);
      }
      if (other.Model.Length != 0) {
        Model = other.Model;
      }
      if (other.UseEnhanced != false) {
        UseEnhanced = other.UseEnhanced;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            Encoding = (global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            LanguageCode = input.ReadString();
            break;
          }
          case 32: {
            MaxAlternatives = input.ReadInt32();
            break;
          }
          case 40: {
            ProfanityFilter = input.ReadBool();
            break;
          }
          case 50: {
            speechContexts_.AddEntriesFrom(input, _repeated_speechContexts_codec);
            break;
          }
          case 56: {
            AudioChannelCount = input.ReadInt32();
            break;
          }
          case 64: {
            EnableWordTimeOffsets = input.ReadBool();
            break;
          }
          case 74: {
            if (metadata_ == null) {
              Metadata = new global::Google.Cloud.Speech.V1.RecognitionMetadata();
            }
            input.ReadMessage(Metadata);
            break;
          }
          case 88: {
            EnableAutomaticPunctuation = input.ReadBool();
            break;
          }
          case 96: {
            EnableSeparateRecognitionPerChannel = input.ReadBool();
            break;
          }
          case 106: {
            Model = input.ReadString();
            break;
          }
          case 112: {
            UseEnhanced = input.ReadBool();
            break;
          }
          case 154: {
            if (diarizationConfig_ == null) {
              DiarizationConfig = new global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig();
            }
            input.ReadMessage(DiarizationConfig);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            Encoding = (global::Google.Cloud.Speech.V1.RecognitionConfig.Types.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            LanguageCode = input.ReadString();
            break;
          }
          case 32: {
            MaxAlternatives = input.ReadInt32();
            break;
          }
          case 40: {
            ProfanityFilter = input.ReadBool();
            break;
          }
          case 50: {
            speechContexts_.AddEntriesFrom(ref input, _repeated_speechContexts_codec);
            break;
          }
          case 56: {
            AudioChannelCount = input.ReadInt32();
            break;
          }
          case 64: {
            EnableWordTimeOffsets = input.ReadBool();
            break;
          }
          case 74: {
            if (metadata_ == null) {
              Metadata = new global::Google.Cloud.Speech.V1.RecognitionMetadata();
            }
            input.ReadMessage(Metadata);
            break;
          }
          case 88: {
            EnableAutomaticPunctuation = input.ReadBool();
            break;
          }
          case 96: {
            EnableSeparateRecognitionPerChannel = input.ReadBool();
            break;
          }
          case 106: {
            Model = input.ReadString();
            break;
          }
          case 112: {
            UseEnhanced = input.ReadBool();
            break;
          }
          case 154: {
            if (diarizationConfig_ == null) {
              DiarizationConfig = new global::Google.Cloud.Speech.V1.SpeakerDiarizationConfig();
            }
            input.ReadMessage(DiarizationConfig);
            break;
          }
        }
      }
    }
    #endif

    #region Nested types
    /// <summary>Container for nested types declared in the RecognitionConfig message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// The encoding of the audio data sent in the request.
      ///
      /// All encodings support only 1 channel (mono) audio, unless the
      /// `audio_channel_count` and `enable_separate_recognition_per_channel` fields
      /// are set.
      ///
      /// For best results, the audio source should be captured and transmitted using
      /// a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
      /// recognition can be reduced if lossy codecs are used to capture or transmit
      /// audio, particularly if background noise is present. Lossy codecs include
      /// `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, `SPEEX_WITH_HEADER_BYTE`, `MP3`.
      ///
      /// The `FLAC` and `WAV` audio file formats include a header that describes the
      /// included audio content. You can request recognition for `WAV` files that
      /// contain either `LINEAR16` or `MULAW` encoded audio.
      /// If you send `FLAC` or `WAV` audio file format in
      /// your request, you do not need to specify an `AudioEncoding`; the audio
      /// encoding format is determined from the file header. If you specify
      /// an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
      /// encoding configuration must match the encoding described in the audio
      /// header; otherwise the request returns an
      /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT] error code.
      /// </summary>
      public enum AudioEncoding {
        /// <summary>
        /// Not specified.
        /// </summary>
        [pbr::OriginalName("ENCODING_UNSPECIFIED")] EncodingUnspecified = 0,
        /// <summary>
        /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
        /// </summary>
        [pbr::OriginalName("LINEAR16")] Linear16 = 1,
        /// <summary>
        /// `FLAC` (Free Lossless Audio
        /// Codec) is the recommended encoding because it is
        /// lossless--therefore recognition is not compromised--and
        /// requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
        /// encoding supports 16-bit and 24-bit samples, however, not all fields in
        /// `STREAMINFO` are supported.
        /// </summary>
        [pbr::OriginalName("FLAC")] Flac = 2,
        /// <summary>
        /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
        /// </summary>
        [pbr::OriginalName("MULAW")] Mulaw = 3,
        /// <summary>
        /// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
        /// </summary>
        [pbr::OriginalName("AMR")] Amr = 4,
        /// <summary>
        /// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
        /// </summary>
        [pbr::OriginalName("AMR_WB")] AmrWb = 5,
        /// <summary>
        /// Opus encoded audio frames in Ogg container
        /// ([OggOpus](https://wiki.xiph.org/OggOpus)).
        /// `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
        /// </summary>
        [pbr::OriginalName("OGG_OPUS")] OggOpus = 6,
        /// <summary>
        /// Although the use of lossy encodings is not recommended, if a very low
        /// bitrate encoding is required, `OGG_OPUS` is highly preferred over
        /// Speex encoding. The [Speex](https://speex.org/)  encoding supported by
        /// Cloud Speech API has a header byte in each block, as in MIME type
        /// `audio/x-speex-with-header-byte`.
        /// It is a variant of the RTP Speex encoding defined in
        /// [RFC 5574](https://tools.ietf.org/html/rfc5574).
        /// The stream is a sequence of blocks, one block per RTP packet. Each block
        /// starts with a byte containing the length of the block, in bytes, followed
        /// by one or more frames of Speex data, padded to an integral number of
        /// bytes (octets) as specified in RFC 5574. In other words, each RTP header
        /// is replaced with a single byte containing the block length. Only Speex
        /// wideband is supported. `sample_rate_hertz` must be 16000.
        /// </summary>
        [pbr::OriginalName("SPEEX_WITH_HEADER_BYTE")] SpeexWithHeaderByte = 7,
      }

    }
    #endregion

  }

  /// <summary>
  /// Config to enable speaker diarization.
  /// </summary>
  public sealed partial class SpeakerDiarizationConfig : pb::IMessage<SpeakerDiarizationConfig>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeakerDiarizationConfig> _parser = new pb::MessageParser<SpeakerDiarizationConfig>(() => new SpeakerDiarizationConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeakerDiarizationConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeakerDiarizationConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeakerDiarizationConfig(SpeakerDiarizationConfig other) : this() {
      enableSpeakerDiarization_ = other.enableSpeakerDiarization_;
      minSpeakerCount_ = other.minSpeakerCount_;
      maxSpeakerCount_ = other.maxSpeakerCount_;
      speakerTag_ = other.speakerTag_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeakerDiarizationConfig Clone() {
      return new SpeakerDiarizationConfig(this);
    }

    /// <summary>Field number for the "enable_speaker_diarization" field.</summary>
    public const int EnableSpeakerDiarizationFieldNumber = 1;
    private bool enableSpeakerDiarization_;
    /// <summary>
    /// If 'true', enables speaker detection for each recognized word in
    /// the top alternative of the recognition result using a speaker_tag provided
    /// in the WordInfo.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableSpeakerDiarization {
      get { return enableSpeakerDiarization_; }
      set {
        enableSpeakerDiarization_ = value;
      }
    }

    /// <summary>Field number for the "min_speaker_count" field.</summary>
    public const int MinSpeakerCountFieldNumber = 2;
    private int minSpeakerCount_;
    /// <summary>
    /// Minimum number of speakers in the conversation. This range gives you more
    /// flexibility by allowing the system to automatically determine the correct
    /// number of speakers. If not set, the default value is 2.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int MinSpeakerCount {
      get { return minSpeakerCount_; }
      set {
        minSpeakerCount_ = value;
      }
    }

    /// <summary>Field number for the "max_speaker_count" field.</summary>
    public const int MaxSpeakerCountFieldNumber = 3;
    private int maxSpeakerCount_;
    /// <summary>
    /// Maximum number of speakers in the conversation. This range gives you more
    /// flexibility by allowing the system to automatically determine the correct
    /// number of speakers. If not set, the default value is 6.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int MaxSpeakerCount {
      get { return maxSpeakerCount_; }
      set {
        maxSpeakerCount_ = value;
      }
    }

    /// <summary>Field number for the "speaker_tag" field.</summary>
    public const int SpeakerTagFieldNumber = 5;
    private int speakerTag_;
    /// <summary>
    /// Output only. Unused.
    /// </summary>
    [global::System.ObsoleteAttribute]
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SpeakerTag {
      get { return speakerTag_; }
      set {
        speakerTag_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeakerDiarizationConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeakerDiarizationConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (EnableSpeakerDiarization != other.EnableSpeakerDiarization) return false;
      if (MinSpeakerCount != other.MinSpeakerCount) return false;
      if (MaxSpeakerCount != other.MaxSpeakerCount) return false;
      if (SpeakerTag != other.SpeakerTag) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (EnableSpeakerDiarization != false) hash ^= EnableSpeakerDiarization.GetHashCode();
      if (MinSpeakerCount != 0) hash ^= MinSpeakerCount.GetHashCode();
      if (MaxSpeakerCount != 0) hash ^= MaxSpeakerCount.GetHashCode();
      if (SpeakerTag != 0) hash ^= SpeakerTag.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (EnableSpeakerDiarization != false) {
        output.WriteRawTag(8);
        output.WriteBool(EnableSpeakerDiarization);
      }
      if (MinSpeakerCount != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(MinSpeakerCount);
      }
      if (MaxSpeakerCount != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(MaxSpeakerCount);
      }
      if (SpeakerTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(SpeakerTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (EnableSpeakerDiarization != false) {
        output.WriteRawTag(8);
        output.WriteBool(EnableSpeakerDiarization);
      }
      if (MinSpeakerCount != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(MinSpeakerCount);
      }
      if (MaxSpeakerCount != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(MaxSpeakerCount);
      }
      if (SpeakerTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(SpeakerTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (EnableSpeakerDiarization != false) {
        size += 1 + 1;
      }
      if (MinSpeakerCount != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(MinSpeakerCount);
      }
      if (MaxSpeakerCount != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(MaxSpeakerCount);
      }
      if (SpeakerTag != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SpeakerTag);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeakerDiarizationConfig other) {
      if (other == null) {
        return;
      }
      if (other.EnableSpeakerDiarization != false) {
        EnableSpeakerDiarization = other.EnableSpeakerDiarization;
      }
      if (other.MinSpeakerCount != 0) {
        MinSpeakerCount = other.MinSpeakerCount;
      }
      if (other.MaxSpeakerCount != 0) {
        MaxSpeakerCount = other.MaxSpeakerCount;
      }
      if (other.SpeakerTag != 0) {
        SpeakerTag = other.SpeakerTag;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            EnableSpeakerDiarization = input.ReadBool();
            break;
          }
          case 16: {
            MinSpeakerCount = input.ReadInt32();
            break;
          }
          case 24: {
            MaxSpeakerCount = input.ReadInt32();
            break;
          }
          case 40: {
            SpeakerTag = input.ReadInt32();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            EnableSpeakerDiarization = input.ReadBool();
            break;
          }
          case 16: {
            MinSpeakerCount = input.ReadInt32();
            break;
          }
          case 24: {
            MaxSpeakerCount = input.ReadInt32();
            break;
          }
          case 40: {
            SpeakerTag = input.ReadInt32();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Description of audio data to be recognized.
  /// </summary>
  public sealed partial class RecognitionMetadata : pb::IMessage<RecognitionMetadata>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<RecognitionMetadata> _parser = new pb::MessageParser<RecognitionMetadata>(() => new RecognitionMetadata());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognitionMetadata> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionMetadata() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionMetadata(RecognitionMetadata other) : this() {
      interactionType_ = other.interactionType_;
      industryNaicsCodeOfAudio_ = other.industryNaicsCodeOfAudio_;
      microphoneDistance_ = other.microphoneDistance_;
      originalMediaType_ = other.originalMediaType_;
      recordingDeviceType_ = other.recordingDeviceType_;
      recordingDeviceName_ = other.recordingDeviceName_;
      originalMimeType_ = other.originalMimeType_;
      audioTopic_ = other.audioTopic_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionMetadata Clone() {
      return new RecognitionMetadata(this);
    }

    /// <summary>Field number for the "interaction_type" field.</summary>
    public const int InteractionTypeFieldNumber = 1;
    private global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType interactionType_ = global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified;
    /// <summary>
    /// The use case most closely describing the audio content to be recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType InteractionType {
      get { return interactionType_; }
      set {
        interactionType_ = value;
      }
    }

    /// <summary>Field number for the "industry_naics_code_of_audio" field.</summary>
    public const int IndustryNaicsCodeOfAudioFieldNumber = 3;
    private uint industryNaicsCodeOfAudio_;
    /// <summary>
    /// The industry vertical to which this speech recognition request most
    /// closely applies. This is most indicative of the topics contained
    /// in the audio.  Use the 6-digit NAICS code to identify the industry
    /// vertical - see https://www.naics.com/search/.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public uint IndustryNaicsCodeOfAudio {
      get { return industryNaicsCodeOfAudio_; }
      set {
        industryNaicsCodeOfAudio_ = value;
      }
    }

    /// <summary>Field number for the "microphone_distance" field.</summary>
    public const int MicrophoneDistanceFieldNumber = 4;
    private global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance microphoneDistance_ = global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified;
    /// <summary>
    /// The audio type that most closely describes the audio being recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance MicrophoneDistance {
      get { return microphoneDistance_; }
      set {
        microphoneDistance_ = value;
      }
    }

    /// <summary>Field number for the "original_media_type" field.</summary>
    public const int OriginalMediaTypeFieldNumber = 5;
    private global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType originalMediaType_ = global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified;
    /// <summary>
    /// The original media the speech was recorded on.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType OriginalMediaType {
      get { return originalMediaType_; }
      set {
        originalMediaType_ = value;
      }
    }

    /// <summary>Field number for the "recording_device_type" field.</summary>
    public const int RecordingDeviceTypeFieldNumber = 6;
    private global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType recordingDeviceType_ = global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified;
    /// <summary>
    /// The type of device the speech was recorded with.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType RecordingDeviceType {
      get { return recordingDeviceType_; }
      set {
        recordingDeviceType_ = value;
      }
    }

    /// <summary>Field number for the "recording_device_name" field.</summary>
    public const int RecordingDeviceNameFieldNumber = 7;
    private string recordingDeviceName_ = "";
    /// <summary>
    /// The device used to make the recording.  Examples 'Nexus 5X' or
    /// 'Polycom SoundStation IP 6000' or 'POTS' or 'VoIP' or
    /// 'Cardioid Microphone'.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string RecordingDeviceName {
      get { return recordingDeviceName_; }
      set {
        recordingDeviceName_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "original_mime_type" field.</summary>
    public const int OriginalMimeTypeFieldNumber = 8;
    private string originalMimeType_ = "";
    /// <summary>
    /// Mime type of the original audio file.  For example `audio/m4a`,
    /// `audio/x-alaw-basic`, `audio/mp3`, `audio/3gpp`.
    /// A list of possible audio mime types is maintained at
    /// http://www.iana.org/assignments/media-types/media-types.xhtml#audio
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string OriginalMimeType {
      get { return originalMimeType_; }
      set {
        originalMimeType_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "audio_topic" field.</summary>
    public const int AudioTopicFieldNumber = 10;
    private string audioTopic_ = "";
    /// <summary>
    /// Description of the content. Eg. "Recordings of federal supreme court
    /// hearings from 2012".
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string AudioTopic {
      get { return audioTopic_; }
      set {
        audioTopic_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognitionMetadata);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognitionMetadata other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (InteractionType != other.InteractionType) return false;
      if (IndustryNaicsCodeOfAudio != other.IndustryNaicsCodeOfAudio) return false;
      if (MicrophoneDistance != other.MicrophoneDistance) return false;
      if (OriginalMediaType != other.OriginalMediaType) return false;
      if (RecordingDeviceType != other.RecordingDeviceType) return false;
      if (RecordingDeviceName != other.RecordingDeviceName) return false;
      if (OriginalMimeType != other.OriginalMimeType) return false;
      if (AudioTopic != other.AudioTopic) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (InteractionType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified) hash ^= InteractionType.GetHashCode();
      if (IndustryNaicsCodeOfAudio != 0) hash ^= IndustryNaicsCodeOfAudio.GetHashCode();
      if (MicrophoneDistance != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified) hash ^= MicrophoneDistance.GetHashCode();
      if (OriginalMediaType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified) hash ^= OriginalMediaType.GetHashCode();
      if (RecordingDeviceType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified) hash ^= RecordingDeviceType.GetHashCode();
      if (RecordingDeviceName.Length != 0) hash ^= RecordingDeviceName.GetHashCode();
      if (OriginalMimeType.Length != 0) hash ^= OriginalMimeType.GetHashCode();
      if (AudioTopic.Length != 0) hash ^= AudioTopic.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (InteractionType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) InteractionType);
      }
      if (IndustryNaicsCodeOfAudio != 0) {
        output.WriteRawTag(24);
        output.WriteUInt32(IndustryNaicsCodeOfAudio);
      }
      if (MicrophoneDistance != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified) {
        output.WriteRawTag(32);
        output.WriteEnum((int) MicrophoneDistance);
      }
      if (OriginalMediaType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified) {
        output.WriteRawTag(40);
        output.WriteEnum((int) OriginalMediaType);
      }
      if (RecordingDeviceType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified) {
        output.WriteRawTag(48);
        output.WriteEnum((int) RecordingDeviceType);
      }
      if (RecordingDeviceName.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(RecordingDeviceName);
      }
      if (OriginalMimeType.Length != 0) {
        output.WriteRawTag(66);
        output.WriteString(OriginalMimeType);
      }
      if (AudioTopic.Length != 0) {
        output.WriteRawTag(82);
        output.WriteString(AudioTopic);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (InteractionType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified) {
        output.WriteRawTag(8);
        output.WriteEnum((int) InteractionType);
      }
      if (IndustryNaicsCodeOfAudio != 0) {
        output.WriteRawTag(24);
        output.WriteUInt32(IndustryNaicsCodeOfAudio);
      }
      if (MicrophoneDistance != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified) {
        output.WriteRawTag(32);
        output.WriteEnum((int) MicrophoneDistance);
      }
      if (OriginalMediaType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified) {
        output.WriteRawTag(40);
        output.WriteEnum((int) OriginalMediaType);
      }
      if (RecordingDeviceType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified) {
        output.WriteRawTag(48);
        output.WriteEnum((int) RecordingDeviceType);
      }
      if (RecordingDeviceName.Length != 0) {
        output.WriteRawTag(58);
        output.WriteString(RecordingDeviceName);
      }
      if (OriginalMimeType.Length != 0) {
        output.WriteRawTag(66);
        output.WriteString(OriginalMimeType);
      }
      if (AudioTopic.Length != 0) {
        output.WriteRawTag(82);
        output.WriteString(AudioTopic);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (InteractionType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) InteractionType);
      }
      if (IndustryNaicsCodeOfAudio != 0) {
        size += 1 + pb::CodedOutputStream.ComputeUInt32Size(IndustryNaicsCodeOfAudio);
      }
      if (MicrophoneDistance != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) MicrophoneDistance);
      }
      if (OriginalMediaType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) OriginalMediaType);
      }
      if (RecordingDeviceType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) RecordingDeviceType);
      }
      if (RecordingDeviceName.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(RecordingDeviceName);
      }
      if (OriginalMimeType.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(OriginalMimeType);
      }
      if (AudioTopic.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(AudioTopic);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognitionMetadata other) {
      if (other == null) {
        return;
      }
      if (other.InteractionType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType.Unspecified) {
        InteractionType = other.InteractionType;
      }
      if (other.IndustryNaicsCodeOfAudio != 0) {
        IndustryNaicsCodeOfAudio = other.IndustryNaicsCodeOfAudio;
      }
      if (other.MicrophoneDistance != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance.Unspecified) {
        MicrophoneDistance = other.MicrophoneDistance;
      }
      if (other.OriginalMediaType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType.Unspecified) {
        OriginalMediaType = other.OriginalMediaType;
      }
      if (other.RecordingDeviceType != global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType.Unspecified) {
        RecordingDeviceType = other.RecordingDeviceType;
      }
      if (other.RecordingDeviceName.Length != 0) {
        RecordingDeviceName = other.RecordingDeviceName;
      }
      if (other.OriginalMimeType.Length != 0) {
        OriginalMimeType = other.OriginalMimeType;
      }
      if (other.AudioTopic.Length != 0) {
        AudioTopic = other.AudioTopic;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            InteractionType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType) input.ReadEnum();
            break;
          }
          case 24: {
            IndustryNaicsCodeOfAudio = input.ReadUInt32();
            break;
          }
          case 32: {
            MicrophoneDistance = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance) input.ReadEnum();
            break;
          }
          case 40: {
            OriginalMediaType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType) input.ReadEnum();
            break;
          }
          case 48: {
            RecordingDeviceType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType) input.ReadEnum();
            break;
          }
          case 58: {
            RecordingDeviceName = input.ReadString();
            break;
          }
          case 66: {
            OriginalMimeType = input.ReadString();
            break;
          }
          case 82: {
            AudioTopic = input.ReadString();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            InteractionType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.InteractionType) input.ReadEnum();
            break;
          }
          case 24: {
            IndustryNaicsCodeOfAudio = input.ReadUInt32();
            break;
          }
          case 32: {
            MicrophoneDistance = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.MicrophoneDistance) input.ReadEnum();
            break;
          }
          case 40: {
            OriginalMediaType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.OriginalMediaType) input.ReadEnum();
            break;
          }
          case 48: {
            RecordingDeviceType = (global::Google.Cloud.Speech.V1.RecognitionMetadata.Types.RecordingDeviceType) input.ReadEnum();
            break;
          }
          case 58: {
            RecordingDeviceName = input.ReadString();
            break;
          }
          case 66: {
            OriginalMimeType = input.ReadString();
            break;
          }
          case 82: {
            AudioTopic = input.ReadString();
            break;
          }
        }
      }
    }
    #endif

    #region Nested types
    /// <summary>Container for nested types declared in the RecognitionMetadata message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Use case categories that the audio recognition request can be described
      /// by.
      /// </summary>
      public enum InteractionType {
        /// <summary>
        /// Use case is either unknown or is something other than one of the other
        /// values below.
        /// </summary>
        [pbr::OriginalName("INTERACTION_TYPE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// Multiple people in a conversation or discussion. For example in a
        /// meeting with two or more people actively participating. Typically
        /// all the primary people speaking would be in the same room (if not,
        /// see PHONE_CALL)
        /// </summary>
        [pbr::OriginalName("DISCUSSION")] Discussion = 1,
        /// <summary>
        /// One or more persons lecturing or presenting to others, mostly
        /// uninterrupted.
        /// </summary>
        [pbr::OriginalName("PRESENTATION")] Presentation = 2,
        /// <summary>
        /// A phone-call or video-conference in which two or more people, who are
        /// not in the same room, are actively participating.
        /// </summary>
        [pbr::OriginalName("PHONE_CALL")] PhoneCall = 3,
        /// <summary>
        /// A recorded message intended for another person to listen to.
        /// </summary>
        [pbr::OriginalName("VOICEMAIL")] Voicemail = 4,
        /// <summary>
        /// Professionally produced audio (eg. TV Show, Podcast).
        /// </summary>
        [pbr::OriginalName("PROFESSIONALLY_PRODUCED")] ProfessionallyProduced = 5,
        /// <summary>
        /// Transcribe spoken questions and queries into text.
        /// </summary>
        [pbr::OriginalName("VOICE_SEARCH")] VoiceSearch = 6,
        /// <summary>
        /// Transcribe voice commands, such as for controlling a device.
        /// </summary>
        [pbr::OriginalName("VOICE_COMMAND")] VoiceCommand = 7,
        /// <summary>
        /// Transcribe speech to text to create a written document, such as a
        /// text-message, email or report.
        /// </summary>
        [pbr::OriginalName("DICTATION")] Dictation = 8,
      }

      /// <summary>
      /// Enumerates the types of capture settings describing an audio file.
      /// </summary>
      public enum MicrophoneDistance {
        /// <summary>
        /// Audio type is not known.
        /// </summary>
        [pbr::OriginalName("MICROPHONE_DISTANCE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// The audio was captured from a closely placed microphone. Eg. phone,
        /// dictaphone, or handheld microphone. Generally if there speaker is within
        /// 1 meter of the microphone.
        /// </summary>
        [pbr::OriginalName("NEARFIELD")] Nearfield = 1,
        /// <summary>
        /// The speaker if within 3 meters of the microphone.
        /// </summary>
        [pbr::OriginalName("MIDFIELD")] Midfield = 2,
        /// <summary>
        /// The speaker is more than 3 meters away from the microphone.
        /// </summary>
        [pbr::OriginalName("FARFIELD")] Farfield = 3,
      }

      /// <summary>
      /// The original media the speech was recorded on.
      /// </summary>
      public enum OriginalMediaType {
        /// <summary>
        /// Unknown original media type.
        /// </summary>
        [pbr::OriginalName("ORIGINAL_MEDIA_TYPE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// The speech data is an audio recording.
        /// </summary>
        [pbr::OriginalName("AUDIO")] Audio = 1,
        /// <summary>
        /// The speech data originally recorded on a video.
        /// </summary>
        [pbr::OriginalName("VIDEO")] Video = 2,
      }

      /// <summary>
      /// The type of device the speech was recorded with.
      /// </summary>
      public enum RecordingDeviceType {
        /// <summary>
        /// The recording device is unknown.
        /// </summary>
        [pbr::OriginalName("RECORDING_DEVICE_TYPE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// Speech was recorded on a smartphone.
        /// </summary>
        [pbr::OriginalName("SMARTPHONE")] Smartphone = 1,
        /// <summary>
        /// Speech was recorded using a personal computer or tablet.
        /// </summary>
        [pbr::OriginalName("PC")] Pc = 2,
        /// <summary>
        /// Speech was recorded over a phone line.
        /// </summary>
        [pbr::OriginalName("PHONE_LINE")] PhoneLine = 3,
        /// <summary>
        /// Speech was recorded in a vehicle.
        /// </summary>
        [pbr::OriginalName("VEHICLE")] Vehicle = 4,
        /// <summary>
        /// Speech was recorded outdoors.
        /// </summary>
        [pbr::OriginalName("OTHER_OUTDOOR_DEVICE")] OtherOutdoorDevice = 5,
        /// <summary>
        /// Speech was recorded indoors.
        /// </summary>
        [pbr::OriginalName("OTHER_INDOOR_DEVICE")] OtherIndoorDevice = 6,
      }

    }
    #endregion

  }

  /// <summary>
  /// Provides "hints" to the speech recognizer to favor specific words and phrases
  /// in the results.
  /// </summary>
  public sealed partial class SpeechContext : pb::IMessage<SpeechContext>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechContext> _parser = new pb::MessageParser<SpeechContext>(() => new SpeechContext());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechContext> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext(SpeechContext other) : this() {
      phrases_ = other.phrases_.Clone();
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext Clone() {
      return new SpeechContext(this);
    }

    /// <summary>Field number for the "phrases" field.</summary>
    public const int PhrasesFieldNumber = 1;
    private static readonly pb::FieldCodec<string> _repeated_phrases_codec
        = pb::FieldCodec.ForString(10);
    private readonly pbc::RepeatedField<string> phrases_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// A list of strings containing words and phrases "hints" so that
    /// the speech recognition is more likely to recognize them. This can be used
    /// to improve the accuracy for specific words and phrases, for example, if
    /// specific commands are typically spoken by the user. This can also be used
    /// to add additional words to the vocabulary of the recognizer. See
    /// [usage limits](https://cloud.google.com/speech-to-text/quotas#content).
    ///
    /// List items can also be set to classes for groups of words that represent
    /// common concepts that occur in natural language. For example, rather than
    /// providing phrase hints for every month of the year, using the $MONTH class
    /// improves the likelihood of correctly transcribing audio that includes
    /// months.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Phrases {
      get { return phrases_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechContext);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechContext other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!phrases_.Equals(other.phrases_)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= phrases_.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      phrases_.WriteTo(output, _repeated_phrases_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      phrases_.WriteTo(ref output, _repeated_phrases_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += phrases_.CalculateSize(_repeated_phrases_codec);
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechContext other) {
      if (other == null) {
        return;
      }
      phrases_.Add(other.phrases_);
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            phrases_.AddEntriesFrom(input, _repeated_phrases_codec);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            phrases_.AddEntriesFrom(ref input, _repeated_phrases_codec);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Contains audio data in the encoding specified in the `RecognitionConfig`.
  /// Either `content` or `uri` must be supplied. Supplying both or neither
  /// returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See
  /// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
  /// </summary>
  public sealed partial class RecognitionAudio : pb::IMessage<RecognitionAudio>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<RecognitionAudio> _parser = new pb::MessageParser<RecognitionAudio>(() => new RecognitionAudio());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognitionAudio> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[8]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio(RecognitionAudio other) : this() {
      switch (other.AudioSourceCase) {
        case AudioSourceOneofCase.Content:
          Content = other.Content;
          break;
        case AudioSourceOneofCase.Uri:
          Uri = other.Uri;
          break;
      }

      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio Clone() {
      return new RecognitionAudio(this);
    }

    /// <summary>Field number for the "content" field.</summary>
    public const int ContentFieldNumber = 1;
    /// <summary>
    /// The audio data bytes encoded as specified in
    /// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
    /// pure binary representation, whereas JSON representations use base64.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString Content {
      get { return audioSourceCase_ == AudioSourceOneofCase.Content ? (pb::ByteString) audioSource_ : pb::ByteString.Empty; }
      set {
        audioSource_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        audioSourceCase_ = AudioSourceOneofCase.Content;
      }
    }

    /// <summary>Field number for the "uri" field.</summary>
    public const int UriFieldNumber = 2;
    /// <summary>
    /// URI that points to a file that contains audio data bytes as specified in
    /// `RecognitionConfig`. The file must not be compressed (for example, gzip).
    /// Currently, only Google Cloud Storage URIs are
    /// supported, which must be specified in the following format:
    /// `gs://bucket_name/object_name` (other URI formats return
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
    /// [Request URIs](https://cloud.google.com/storage/docs/reference-uris).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Uri {
      get { return audioSourceCase_ == AudioSourceOneofCase.Uri ? (string) audioSource_ : ""; }
      set {
        audioSource_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        audioSourceCase_ = AudioSourceOneofCase.Uri;
      }
    }

    private object audioSource_;
    /// <summary>Enum of possible cases for the "audio_source" oneof.</summary>
    public enum AudioSourceOneofCase {
      None = 0,
      Content = 1,
      Uri = 2,
    }
    private AudioSourceOneofCase audioSourceCase_ = AudioSourceOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioSourceOneofCase AudioSourceCase {
      get { return audioSourceCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearAudioSource() {
      audioSourceCase_ = AudioSourceOneofCase.None;
      audioSource_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognitionAudio);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognitionAudio other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Content != other.Content) return false;
      if (Uri != other.Uri) return false;
      if (AudioSourceCase != other.AudioSourceCase) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (audioSourceCase_ == AudioSourceOneofCase.Content) hash ^= Content.GetHashCode();
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) hash ^= Uri.GetHashCode();
      hash ^= (int) audioSourceCase_;
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (audioSourceCase_ == AudioSourceOneofCase.Content) {
        output.WriteRawTag(10);
        output.WriteBytes(Content);
      }
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) {
        output.WriteRawTag(18);
        output.WriteString(Uri);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (audioSourceCase_ == AudioSourceOneofCase.Content) {
        output.WriteRawTag(10);
        output.WriteBytes(Content);
      }
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) {
        output.WriteRawTag(18);
        output.WriteString(Uri);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (audioSourceCase_ == AudioSourceOneofCase.Content) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(Content);
      }
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Uri);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognitionAudio other) {
      if (other == null) {
        return;
      }
      switch (other.AudioSourceCase) {
        case AudioSourceOneofCase.Content:
          Content = other.Content;
          break;
        case AudioSourceOneofCase.Uri:
          Uri = other.Uri;
          break;
      }

      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            Content = input.ReadBytes();
            break;
          }
          case 18: {
            Uri = input.ReadString();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            Content = input.ReadBytes();
            break;
          }
          case 18: {
            Uri = input.ReadString();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// The only message returned to the client by the `Recognize` method. It
  /// contains the result as zero or more sequential `SpeechRecognitionResult`
  /// messages.
  /// </summary>
  public sealed partial class RecognizeResponse : pb::IMessage<RecognizeResponse>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<RecognizeResponse> _parser = new pb::MessageParser<RecognizeResponse>(() => new RecognizeResponse());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[9]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeResponse(RecognizeResponse other) : this() {
      results_ = other.results_.Clone();
      totalBilledTime_ = other.totalBilledTime_ != null ? other.totalBilledTime_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognizeResponse Clone() {
      return new RecognizeResponse(this);
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1.SpeechRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult>();
    /// <summary>
    /// Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> Results {
      get { return results_; }
    }

    /// <summary>Field number for the "total_billed_time" field.</summary>
    public const int TotalBilledTimeFieldNumber = 3;
    private global::Google.Protobuf.WellKnownTypes.Duration totalBilledTime_;
    /// <summary>
    /// When available, billed audio seconds for the corresponding request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration TotalBilledTime {
      get { return totalBilledTime_; }
      set {
        totalBilledTime_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!results_.Equals(other.results_)) return false;
      if (!object.Equals(TotalBilledTime, other.TotalBilledTime)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= results_.GetHashCode();
      if (totalBilledTime_ != null) hash ^= TotalBilledTime.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      results_.WriteTo(output, _repeated_results_codec);
      if (totalBilledTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      results_.WriteTo(ref output, _repeated_results_codec);
      if (totalBilledTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += results_.CalculateSize(_repeated_results_codec);
      if (totalBilledTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(TotalBilledTime);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognizeResponse other) {
      if (other == null) {
        return;
      }
      results_.Add(other.results_);
      if (other.totalBilledTime_ != null) {
        if (totalBilledTime_ == null) {
          TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        TotalBilledTime.MergeFrom(other.TotalBilledTime);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
          case 26: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 18: {
            results_.AddEntriesFrom(ref input, _repeated_results_codec);
            break;
          }
          case 26: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// The only message returned to the client by the `LongRunningRecognize` method.
  /// It contains the result as zero or more sequential `SpeechRecognitionResult`
  /// messages. It is included in the `result.response` field of the `Operation`
  /// returned by the `GetOperation` call of the `google::longrunning::Operations`
  /// service.
  /// </summary>
  public sealed partial class LongRunningRecognizeResponse : pb::IMessage<LongRunningRecognizeResponse>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<LongRunningRecognizeResponse> _parser = new pb::MessageParser<LongRunningRecognizeResponse>(() => new LongRunningRecognizeResponse());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<LongRunningRecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[10]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeResponse(LongRunningRecognizeResponse other) : this() {
      results_ = other.results_.Clone();
      totalBilledTime_ = other.totalBilledTime_ != null ? other.totalBilledTime_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeResponse Clone() {
      return new LongRunningRecognizeResponse(this);
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1.SpeechRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult>();
    /// <summary>
    /// Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionResult> Results {
      get { return results_; }
    }

    /// <summary>Field number for the "total_billed_time" field.</summary>
    public const int TotalBilledTimeFieldNumber = 3;
    private global::Google.Protobuf.WellKnownTypes.Duration totalBilledTime_;
    /// <summary>
    /// When available, billed audio seconds for the corresponding request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration TotalBilledTime {
      get { return totalBilledTime_; }
      set {
        totalBilledTime_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as LongRunningRecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(LongRunningRecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!results_.Equals(other.results_)) return false;
      if (!object.Equals(TotalBilledTime, other.TotalBilledTime)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= results_.GetHashCode();
      if (totalBilledTime_ != null) hash ^= TotalBilledTime.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      results_.WriteTo(output, _repeated_results_codec);
      if (totalBilledTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      results_.WriteTo(ref output, _repeated_results_codec);
      if (totalBilledTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += results_.CalculateSize(_repeated_results_codec);
      if (totalBilledTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(TotalBilledTime);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(LongRunningRecognizeResponse other) {
      if (other == null) {
        return;
      }
      results_.Add(other.results_);
      if (other.totalBilledTime_ != null) {
        if (totalBilledTime_ == null) {
          TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        TotalBilledTime.MergeFrom(other.TotalBilledTime);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
          case 26: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 18: {
            results_.AddEntriesFrom(ref input, _repeated_results_codec);
            break;
          }
          case 26: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Describes the progress of a long-running `LongRunningRecognize` call. It is
  /// included in the `metadata` field of the `Operation` returned by the
  /// `GetOperation` call of the `google::longrunning::Operations` service.
  /// </summary>
  public sealed partial class LongRunningRecognizeMetadata : pb::IMessage<LongRunningRecognizeMetadata>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<LongRunningRecognizeMetadata> _parser = new pb::MessageParser<LongRunningRecognizeMetadata>(() => new LongRunningRecognizeMetadata());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<LongRunningRecognizeMetadata> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[11]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeMetadata() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeMetadata(LongRunningRecognizeMetadata other) : this() {
      progressPercent_ = other.progressPercent_;
      startTime_ = other.startTime_ != null ? other.startTime_.Clone() : null;
      lastUpdateTime_ = other.lastUpdateTime_ != null ? other.lastUpdateTime_.Clone() : null;
      uri_ = other.uri_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public LongRunningRecognizeMetadata Clone() {
      return new LongRunningRecognizeMetadata(this);
    }

    /// <summary>Field number for the "progress_percent" field.</summary>
    public const int ProgressPercentFieldNumber = 1;
    private int progressPercent_;
    /// <summary>
    /// Approximate percentage of audio processed thus far. Guaranteed to be 100
    /// when the audio is fully processed and the results are available.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int ProgressPercent {
      get { return progressPercent_; }
      set {
        progressPercent_ = value;
      }
    }

    /// <summary>Field number for the "start_time" field.</summary>
    public const int StartTimeFieldNumber = 2;
    private global::Google.Protobuf.WellKnownTypes.Timestamp startTime_;
    /// <summary>
    /// Time when the request was received.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Timestamp StartTime {
      get { return startTime_; }
      set {
        startTime_ = value;
      }
    }

    /// <summary>Field number for the "last_update_time" field.</summary>
    public const int LastUpdateTimeFieldNumber = 3;
    private global::Google.Protobuf.WellKnownTypes.Timestamp lastUpdateTime_;
    /// <summary>
    /// Time of the most recent processing update.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Timestamp LastUpdateTime {
      get { return lastUpdateTime_; }
      set {
        lastUpdateTime_ = value;
      }
    }

    /// <summary>Field number for the "uri" field.</summary>
    public const int UriFieldNumber = 4;
    private string uri_ = "";
    /// <summary>
    /// Output only. The URI of the audio file being transcribed. Empty if the audio was sent
    /// as byte content.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Uri {
      get { return uri_; }
      set {
        uri_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as LongRunningRecognizeMetadata);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(LongRunningRecognizeMetadata other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ProgressPercent != other.ProgressPercent) return false;
      if (!object.Equals(StartTime, other.StartTime)) return false;
      if (!object.Equals(LastUpdateTime, other.LastUpdateTime)) return false;
      if (Uri != other.Uri) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ProgressPercent != 0) hash ^= ProgressPercent.GetHashCode();
      if (startTime_ != null) hash ^= StartTime.GetHashCode();
      if (lastUpdateTime_ != null) hash ^= LastUpdateTime.GetHashCode();
      if (Uri.Length != 0) hash ^= Uri.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (ProgressPercent != 0) {
        output.WriteRawTag(8);
        output.WriteInt32(ProgressPercent);
      }
      if (startTime_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(StartTime);
      }
      if (lastUpdateTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(LastUpdateTime);
      }
      if (Uri.Length != 0) {
        output.WriteRawTag(34);
        output.WriteString(Uri);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (ProgressPercent != 0) {
        output.WriteRawTag(8);
        output.WriteInt32(ProgressPercent);
      }
      if (startTime_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(StartTime);
      }
      if (lastUpdateTime_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(LastUpdateTime);
      }
      if (Uri.Length != 0) {
        output.WriteRawTag(34);
        output.WriteString(Uri);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ProgressPercent != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(ProgressPercent);
      }
      if (startTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StartTime);
      }
      if (lastUpdateTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(LastUpdateTime);
      }
      if (Uri.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Uri);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(LongRunningRecognizeMetadata other) {
      if (other == null) {
        return;
      }
      if (other.ProgressPercent != 0) {
        ProgressPercent = other.ProgressPercent;
      }
      if (other.startTime_ != null) {
        if (startTime_ == null) {
          StartTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
        }
        StartTime.MergeFrom(other.StartTime);
      }
      if (other.lastUpdateTime_ != null) {
        if (lastUpdateTime_ == null) {
          LastUpdateTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
        }
        LastUpdateTime.MergeFrom(other.LastUpdateTime);
      }
      if (other.Uri.Length != 0) {
        Uri = other.Uri;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            ProgressPercent = input.ReadInt32();
            break;
          }
          case 18: {
            if (startTime_ == null) {
              StartTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
            }
            input.ReadMessage(StartTime);
            break;
          }
          case 26: {
            if (lastUpdateTime_ == null) {
              LastUpdateTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
            }
            input.ReadMessage(LastUpdateTime);
            break;
          }
          case 34: {
            Uri = input.ReadString();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 8: {
            ProgressPercent = input.ReadInt32();
            break;
          }
          case 18: {
            if (startTime_ == null) {
              StartTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
            }
            input.ReadMessage(StartTime);
            break;
          }
          case 26: {
            if (lastUpdateTime_ == null) {
              LastUpdateTime = new global::Google.Protobuf.WellKnownTypes.Timestamp();
            }
            input.ReadMessage(LastUpdateTime);
            break;
          }
          case 34: {
            Uri = input.ReadString();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// `StreamingRecognizeResponse` is the only message returned to the client by
  /// `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
  /// messages are streamed back to the client. If there is no recognizable
  /// audio, and `single_utterance` is set to false, then no messages are streamed
  /// back to the client.
  ///
  /// Here's an example of a series of `StreamingRecognizeResponse`s that might be
  /// returned while processing audio:
  ///
  /// 1. results { alternatives { transcript: "tube" } stability: 0.01 }
  ///
  /// 2. results { alternatives { transcript: "to be a" } stability: 0.01 }
  ///
  /// 3. results { alternatives { transcript: "to be" } stability: 0.9 }
  ///    results { alternatives { transcript: " or not to be" } stability: 0.01 }
  ///
  /// 4. results { alternatives { transcript: "to be or not to be"
  ///                             confidence: 0.92 }
  ///              alternatives { transcript: "to bee or not to bee" }
  ///              is_final: true }
  ///
  /// 5. results { alternatives { transcript: " that's" } stability: 0.01 }
  ///
  /// 6. results { alternatives { transcript: " that is" } stability: 0.9 }
  ///    results { alternatives { transcript: " the question" } stability: 0.01 }
  ///
  /// 7. results { alternatives { transcript: " that is the question"
  ///                             confidence: 0.98 }
  ///              alternatives { transcript: " that was the question" }
  ///              is_final: true }
  ///
  /// Notes:
  ///
  /// - Only two of the above responses #4 and #7 contain final results; they are
  ///   indicated by `is_final: true`. Concatenating these together generates the
  ///   full transcript: "to be or not to be that is the question".
  ///
  /// - The others contain interim `results`. #3 and #6 contain two interim
  ///   `results`: the first portion has a high stability and is less likely to
  ///   change; the second portion has a low stability and is very likely to
  ///   change. A UI designer might choose to show only high stability `results`.
  ///
  /// - The specific `stability` and `confidence` values shown above are only for
  ///   illustrative purposes. Actual values may vary.
  ///
  /// - In each response, only one of these fields will be set:
  ///     `error`,
  ///     `speech_event_type`, or
  ///     one or more (repeated) `results`.
  /// </summary>
  public sealed partial class StreamingRecognizeResponse : pb::IMessage<StreamingRecognizeResponse>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<StreamingRecognizeResponse> _parser = new pb::MessageParser<StreamingRecognizeResponse>(() => new StreamingRecognizeResponse());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[12]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse(StreamingRecognizeResponse other) : this() {
      error_ = other.error_ != null ? other.error_.Clone() : null;
      results_ = other.results_.Clone();
      speechEventType_ = other.speechEventType_;
      totalBilledTime_ = other.totalBilledTime_ != null ? other.totalBilledTime_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse Clone() {
      return new StreamingRecognizeResponse(this);
    }

    /// <summary>Field number for the "error" field.</summary>
    public const int ErrorFieldNumber = 1;
    private global::Google.Rpc.Status error_;
    /// <summary>
    /// If set, returns a [google.rpc.Status][google.rpc.Status] message that
    /// specifies the error for the operation.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Rpc.Status Error {
      get { return error_; }
      set {
        error_ = value;
      }
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.StreamingRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1.StreamingRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.StreamingRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.StreamingRecognitionResult>();
    /// <summary>
    /// This repeated list contains zero or more results that
    /// correspond to consecutive portions of the audio currently being processed.
    /// It contains zero or one `is_final=true` result (the newly settled portion),
    /// followed by zero or more `is_final=false` results (the interim results).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.StreamingRecognitionResult> Results {
      get { return results_; }
    }

    /// <summary>Field number for the "speech_event_type" field.</summary>
    public const int SpeechEventTypeFieldNumber = 4;
    private global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType speechEventType_ = global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified;
    /// <summary>
    /// Indicates the type of speech event.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType SpeechEventType {
      get { return speechEventType_; }
      set {
        speechEventType_ = value;
      }
    }

    /// <summary>Field number for the "total_billed_time" field.</summary>
    public const int TotalBilledTimeFieldNumber = 5;
    private global::Google.Protobuf.WellKnownTypes.Duration totalBilledTime_;
    /// <summary>
    /// When available, billed audio seconds for the stream.
    /// Set only if this is the last response in the stream.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration TotalBilledTime {
      get { return totalBilledTime_; }
      set {
        totalBilledTime_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Error, other.Error)) return false;
      if(!results_.Equals(other.results_)) return false;
      if (SpeechEventType != other.SpeechEventType) return false;
      if (!object.Equals(TotalBilledTime, other.TotalBilledTime)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (error_ != null) hash ^= Error.GetHashCode();
      hash ^= results_.GetHashCode();
      if (SpeechEventType != global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified) hash ^= SpeechEventType.GetHashCode();
      if (totalBilledTime_ != null) hash ^= TotalBilledTime.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (error_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Error);
      }
      results_.WriteTo(output, _repeated_results_codec);
      if (SpeechEventType != global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified) {
        output.WriteRawTag(32);
        output.WriteEnum((int) SpeechEventType);
      }
      if (totalBilledTime_ != null) {
        output.WriteRawTag(42);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (error_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Error);
      }
      results_.WriteTo(ref output, _repeated_results_codec);
      if (SpeechEventType != global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified) {
        output.WriteRawTag(32);
        output.WriteEnum((int) SpeechEventType);
      }
      if (totalBilledTime_ != null) {
        output.WriteRawTag(42);
        output.WriteMessage(TotalBilledTime);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (error_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Error);
      }
      size += results_.CalculateSize(_repeated_results_codec);
      if (SpeechEventType != global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) SpeechEventType);
      }
      if (totalBilledTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(TotalBilledTime);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognizeResponse other) {
      if (other == null) {
        return;
      }
      if (other.error_ != null) {
        if (error_ == null) {
          Error = new global::Google.Rpc.Status();
        }
        Error.MergeFrom(other.Error);
      }
      results_.Add(other.results_);
      if (other.SpeechEventType != global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType.SpeechEventUnspecified) {
        SpeechEventType = other.SpeechEventType;
      }
      if (other.totalBilledTime_ != null) {
        if (totalBilledTime_ == null) {
          TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        TotalBilledTime.MergeFrom(other.TotalBilledTime);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (error_ == null) {
              Error = new global::Google.Rpc.Status();
            }
            input.ReadMessage(Error);
            break;
          }
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
          case 32: {
            SpeechEventType = (global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType) input.ReadEnum();
            break;
          }
          case 42: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (error_ == null) {
              Error = new global::Google.Rpc.Status();
            }
            input.ReadMessage(Error);
            break;
          }
          case 18: {
            results_.AddEntriesFrom(ref input, _repeated_results_codec);
            break;
          }
          case 32: {
            SpeechEventType = (global::Google.Cloud.Speech.V1.StreamingRecognizeResponse.Types.SpeechEventType) input.ReadEnum();
            break;
          }
          case 42: {
            if (totalBilledTime_ == null) {
              TotalBilledTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(TotalBilledTime);
            break;
          }
        }
      }
    }
    #endif

    #region Nested types
    /// <summary>Container for nested types declared in the StreamingRecognizeResponse message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Indicates the type of speech event.
      /// </summary>
      public enum SpeechEventType {
        /// <summary>
        /// No speech event specified.
        /// </summary>
        [pbr::OriginalName("SPEECH_EVENT_UNSPECIFIED")] SpeechEventUnspecified = 0,
        /// <summary>
        /// This event indicates that the server has detected the end of the user's
        /// speech utterance and expects no additional speech. Therefore, the server
        /// will not process additional audio (although it may subsequently return
        /// additional results). The client should stop sending additional audio
        /// data, half-close the gRPC connection, and wait for any additional results
        /// until the server closes the gRPC connection. This event is only sent if
        /// `single_utterance` was set to `true`, and is not used otherwise.
        /// </summary>
        [pbr::OriginalName("END_OF_SINGLE_UTTERANCE")] EndOfSingleUtterance = 1,
      }

    }
    #endregion

  }

  /// <summary>
  /// A streaming speech recognition result corresponding to a portion of the audio
  /// that is currently being processed.
  /// </summary>
  public sealed partial class StreamingRecognitionResult : pb::IMessage<StreamingRecognitionResult>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<StreamingRecognitionResult> _parser = new pb::MessageParser<StreamingRecognitionResult>(() => new StreamingRecognitionResult());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognitionResult> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[13]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult(StreamingRecognitionResult other) : this() {
      alternatives_ = other.alternatives_.Clone();
      isFinal_ = other.isFinal_;
      stability_ = other.stability_;
      resultEndTime_ = other.resultEndTime_ != null ? other.resultEndTime_.Clone() : null;
      channelTag_ = other.channelTag_;
      languageCode_ = other.languageCode_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult Clone() {
      return new StreamingRecognitionResult(this);
    }

    /// <summary>Field number for the "alternatives" field.</summary>
    public const int AlternativesFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> _repeated_alternatives_codec
        = pb::FieldCodec.ForMessage(10, global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> alternatives_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative>();
    /// <summary>
    /// May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// These alternatives are ordered in terms of accuracy, with the top (first)
    /// alternative being the most probable, as ranked by the recognizer.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> Alternatives {
      get { return alternatives_; }
    }

    /// <summary>Field number for the "is_final" field.</summary>
    public const int IsFinalFieldNumber = 2;
    private bool isFinal_;
    /// <summary>
    /// If `false`, this `StreamingRecognitionResult` represents an
    /// interim result that may change. If `true`, this is the final time the
    /// speech service will return this particular `StreamingRecognitionResult`,
    /// the recognizer will not return any further hypotheses for this portion of
    /// the transcript and corresponding audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool IsFinal {
      get { return isFinal_; }
      set {
        isFinal_ = value;
      }
    }

    /// <summary>Field number for the "stability" field.</summary>
    public const int StabilityFieldNumber = 3;
    private float stability_;
    /// <summary>
    /// An estimate of the likelihood that the recognizer will not
    /// change its guess about this interim result. Values range from 0.0
    /// (completely unstable) to 1.0 (completely stable).
    /// This field is only provided for interim results (`is_final=false`).
    /// The default of 0.0 is a sentinel value indicating `stability` was not set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Stability {
      get { return stability_; }
      set {
        stability_ = value;
      }
    }

    /// <summary>Field number for the "result_end_time" field.</summary>
    public const int ResultEndTimeFieldNumber = 4;
    private global::Google.Protobuf.WellKnownTypes.Duration resultEndTime_;
    /// <summary>
    /// Time offset of the end of this result relative to the
    /// beginning of the audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration ResultEndTime {
      get { return resultEndTime_; }
      set {
        resultEndTime_ = value;
      }
    }

    /// <summary>Field number for the "channel_tag" field.</summary>
    public const int ChannelTagFieldNumber = 5;
    private int channelTag_;
    /// <summary>
    /// For multi-channel audio, this is the channel number corresponding to the
    /// recognized result for the audio from that channel.
    /// For audio_channel_count = N, its output values can range from '1' to 'N'.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int ChannelTag {
      get { return channelTag_; }
      set {
        channelTag_ = value;
      }
    }

    /// <summary>Field number for the "language_code" field.</summary>
    public const int LanguageCodeFieldNumber = 6;
    private string languageCode_ = "";
    /// <summary>
    /// The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of
    /// the language in this result. This language code was detected to have the
    /// most likelihood of being spoken in the audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string LanguageCode {
      get { return languageCode_; }
      set {
        languageCode_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognitionResult);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognitionResult other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!alternatives_.Equals(other.alternatives_)) return false;
      if (IsFinal != other.IsFinal) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.Equals(Stability, other.Stability)) return false;
      if (!object.Equals(ResultEndTime, other.ResultEndTime)) return false;
      if (ChannelTag != other.ChannelTag) return false;
      if (LanguageCode != other.LanguageCode) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= alternatives_.GetHashCode();
      if (IsFinal != false) hash ^= IsFinal.GetHashCode();
      if (Stability != 0F) hash ^= pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.GetHashCode(Stability);
      if (resultEndTime_ != null) hash ^= ResultEndTime.GetHashCode();
      if (ChannelTag != 0) hash ^= ChannelTag.GetHashCode();
      if (LanguageCode.Length != 0) hash ^= LanguageCode.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      alternatives_.WriteTo(output, _repeated_alternatives_codec);
      if (IsFinal != false) {
        output.WriteRawTag(16);
        output.WriteBool(IsFinal);
      }
      if (Stability != 0F) {
        output.WriteRawTag(29);
        output.WriteFloat(Stability);
      }
      if (resultEndTime_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(ResultEndTime);
      }
      if (ChannelTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(ChannelTag);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(50);
        output.WriteString(LanguageCode);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      alternatives_.WriteTo(ref output, _repeated_alternatives_codec);
      if (IsFinal != false) {
        output.WriteRawTag(16);
        output.WriteBool(IsFinal);
      }
      if (Stability != 0F) {
        output.WriteRawTag(29);
        output.WriteFloat(Stability);
      }
      if (resultEndTime_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(ResultEndTime);
      }
      if (ChannelTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(ChannelTag);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(50);
        output.WriteString(LanguageCode);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += alternatives_.CalculateSize(_repeated_alternatives_codec);
      if (IsFinal != false) {
        size += 1 + 1;
      }
      if (Stability != 0F) {
        size += 1 + 4;
      }
      if (resultEndTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(ResultEndTime);
      }
      if (ChannelTag != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(ChannelTag);
      }
      if (LanguageCode.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(LanguageCode);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognitionResult other) {
      if (other == null) {
        return;
      }
      alternatives_.Add(other.alternatives_);
      if (other.IsFinal != false) {
        IsFinal = other.IsFinal;
      }
      if (other.Stability != 0F) {
        Stability = other.Stability;
      }
      if (other.resultEndTime_ != null) {
        if (resultEndTime_ == null) {
          ResultEndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        ResultEndTime.MergeFrom(other.ResultEndTime);
      }
      if (other.ChannelTag != 0) {
        ChannelTag = other.ChannelTag;
      }
      if (other.LanguageCode.Length != 0) {
        LanguageCode = other.LanguageCode;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            alternatives_.AddEntriesFrom(input, _repeated_alternatives_codec);
            break;
          }
          case 16: {
            IsFinal = input.ReadBool();
            break;
          }
          case 29: {
            Stability = input.ReadFloat();
            break;
          }
          case 34: {
            if (resultEndTime_ == null) {
              ResultEndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(ResultEndTime);
            break;
          }
          case 40: {
            ChannelTag = input.ReadInt32();
            break;
          }
          case 50: {
            LanguageCode = input.ReadString();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            alternatives_.AddEntriesFrom(ref input, _repeated_alternatives_codec);
            break;
          }
          case 16: {
            IsFinal = input.ReadBool();
            break;
          }
          case 29: {
            Stability = input.ReadFloat();
            break;
          }
          case 34: {
            if (resultEndTime_ == null) {
              ResultEndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(ResultEndTime);
            break;
          }
          case 40: {
            ChannelTag = input.ReadInt32();
            break;
          }
          case 50: {
            LanguageCode = input.ReadString();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// A speech recognition result corresponding to a portion of the audio.
  /// </summary>
  public sealed partial class SpeechRecognitionResult : pb::IMessage<SpeechRecognitionResult>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechRecognitionResult> _parser = new pb::MessageParser<SpeechRecognitionResult>(() => new SpeechRecognitionResult());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechRecognitionResult> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[14]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult(SpeechRecognitionResult other) : this() {
      alternatives_ = other.alternatives_.Clone();
      channelTag_ = other.channelTag_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult Clone() {
      return new SpeechRecognitionResult(this);
    }

    /// <summary>Field number for the "alternatives" field.</summary>
    public const int AlternativesFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> _repeated_alternatives_codec
        = pb::FieldCodec.ForMessage(10, global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> alternatives_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative>();
    /// <summary>
    /// May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// These alternatives are ordered in terms of accuracy, with the top (first)
    /// alternative being the most probable, as ranked by the recognizer.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.SpeechRecognitionAlternative> Alternatives {
      get { return alternatives_; }
    }

    /// <summary>Field number for the "channel_tag" field.</summary>
    public const int ChannelTagFieldNumber = 2;
    private int channelTag_;
    /// <summary>
    /// For multi-channel audio, this is the channel number corresponding to the
    /// recognized result for the audio from that channel.
    /// For audio_channel_count = N, its output values can range from '1' to 'N'.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int ChannelTag {
      get { return channelTag_; }
      set {
        channelTag_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechRecognitionResult);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechRecognitionResult other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!alternatives_.Equals(other.alternatives_)) return false;
      if (ChannelTag != other.ChannelTag) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= alternatives_.GetHashCode();
      if (ChannelTag != 0) hash ^= ChannelTag.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      alternatives_.WriteTo(output, _repeated_alternatives_codec);
      if (ChannelTag != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(ChannelTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      alternatives_.WriteTo(ref output, _repeated_alternatives_codec);
      if (ChannelTag != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(ChannelTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += alternatives_.CalculateSize(_repeated_alternatives_codec);
      if (ChannelTag != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(ChannelTag);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechRecognitionResult other) {
      if (other == null) {
        return;
      }
      alternatives_.Add(other.alternatives_);
      if (other.ChannelTag != 0) {
        ChannelTag = other.ChannelTag;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            alternatives_.AddEntriesFrom(input, _repeated_alternatives_codec);
            break;
          }
          case 16: {
            ChannelTag = input.ReadInt32();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            alternatives_.AddEntriesFrom(ref input, _repeated_alternatives_codec);
            break;
          }
          case 16: {
            ChannelTag = input.ReadInt32();
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Alternative hypotheses (a.k.a. n-best list).
  /// </summary>
  public sealed partial class SpeechRecognitionAlternative : pb::IMessage<SpeechRecognitionAlternative>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<SpeechRecognitionAlternative> _parser = new pb::MessageParser<SpeechRecognitionAlternative>(() => new SpeechRecognitionAlternative());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechRecognitionAlternative> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[15]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative(SpeechRecognitionAlternative other) : this() {
      transcript_ = other.transcript_;
      confidence_ = other.confidence_;
      words_ = other.words_.Clone();
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative Clone() {
      return new SpeechRecognitionAlternative(this);
    }

    /// <summary>Field number for the "transcript" field.</summary>
    public const int TranscriptFieldNumber = 1;
    private string transcript_ = "";
    /// <summary>
    /// Transcript text representing the words that the user spoke.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Transcript {
      get { return transcript_; }
      set {
        transcript_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "confidence" field.</summary>
    public const int ConfidenceFieldNumber = 2;
    private float confidence_;
    /// <summary>
    /// The confidence estimate between 0.0 and 1.0. A higher number
    /// indicates an estimated greater likelihood that the recognized words are
    /// correct. This field is set only for the top alternative of a non-streaming
    /// result or, of a streaming result where `is_final=true`.
    /// This field is not guaranteed to be accurate and users should not rely on it
    /// to be always provided.
    /// The default of 0.0 is a sentinel value indicating `confidence` was not set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Confidence {
      get { return confidence_; }
      set {
        confidence_ = value;
      }
    }

    /// <summary>Field number for the "words" field.</summary>
    public const int WordsFieldNumber = 3;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1.WordInfo> _repeated_words_codec
        = pb::FieldCodec.ForMessage(26, global::Google.Cloud.Speech.V1.WordInfo.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1.WordInfo> words_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1.WordInfo>();
    /// <summary>
    /// A list of word-specific information for each recognized word.
    /// Note: When `enable_speaker_diarization` is true, you will see all the words
    /// from the beginning of the audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1.WordInfo> Words {
      get { return words_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechRecognitionAlternative);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechRecognitionAlternative other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Transcript != other.Transcript) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.Equals(Confidence, other.Confidence)) return false;
      if(!words_.Equals(other.words_)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Transcript.Length != 0) hash ^= Transcript.GetHashCode();
      if (Confidence != 0F) hash ^= pbc::ProtobufEqualityComparers.BitwiseSingleEqualityComparer.GetHashCode(Confidence);
      hash ^= words_.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (Transcript.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Transcript);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(21);
        output.WriteFloat(Confidence);
      }
      words_.WriteTo(output, _repeated_words_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (Transcript.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Transcript);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(21);
        output.WriteFloat(Confidence);
      }
      words_.WriteTo(ref output, _repeated_words_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Transcript.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Transcript);
      }
      if (Confidence != 0F) {
        size += 1 + 4;
      }
      size += words_.CalculateSize(_repeated_words_codec);
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechRecognitionAlternative other) {
      if (other == null) {
        return;
      }
      if (other.Transcript.Length != 0) {
        Transcript = other.Transcript;
      }
      if (other.Confidence != 0F) {
        Confidence = other.Confidence;
      }
      words_.Add(other.words_);
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            Transcript = input.ReadString();
            break;
          }
          case 21: {
            Confidence = input.ReadFloat();
            break;
          }
          case 26: {
            words_.AddEntriesFrom(input, _repeated_words_codec);
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            Transcript = input.ReadString();
            break;
          }
          case 21: {
            Confidence = input.ReadFloat();
            break;
          }
          case 26: {
            words_.AddEntriesFrom(ref input, _repeated_words_codec);
            break;
          }
        }
      }
    }
    #endif

  }

  /// <summary>
  /// Word-specific information for recognized words.
  /// </summary>
  public sealed partial class WordInfo : pb::IMessage<WordInfo>
  #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      , pb::IBufferMessage
  #endif
  {
    private static readonly pb::MessageParser<WordInfo> _parser = new pb::MessageParser<WordInfo>(() => new WordInfo());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<WordInfo> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.MessageTypes[16]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public WordInfo() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public WordInfo(WordInfo other) : this() {
      startTime_ = other.startTime_ != null ? other.startTime_.Clone() : null;
      endTime_ = other.endTime_ != null ? other.endTime_.Clone() : null;
      word_ = other.word_;
      speakerTag_ = other.speakerTag_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public WordInfo Clone() {
      return new WordInfo(this);
    }

    /// <summary>Field number for the "start_time" field.</summary>
    public const int StartTimeFieldNumber = 1;
    private global::Google.Protobuf.WellKnownTypes.Duration startTime_;
    /// <summary>
    /// Time offset relative to the beginning of the audio,
    /// and corresponding to the start of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration StartTime {
      get { return startTime_; }
      set {
        startTime_ = value;
      }
    }

    /// <summary>Field number for the "end_time" field.</summary>
    public const int EndTimeFieldNumber = 2;
    private global::Google.Protobuf.WellKnownTypes.Duration endTime_;
    /// <summary>
    /// Time offset relative to the beginning of the audio,
    /// and corresponding to the end of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Protobuf.WellKnownTypes.Duration EndTime {
      get { return endTime_; }
      set {
        endTime_ = value;
      }
    }

    /// <summary>Field number for the "word" field.</summary>
    public const int WordFieldNumber = 3;
    private string word_ = "";
    /// <summary>
    /// The word corresponding to this set of information.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Word {
      get { return word_; }
      set {
        word_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "speaker_tag" field.</summary>
    public const int SpeakerTagFieldNumber = 5;
    private int speakerTag_;
    /// <summary>
    /// Output only. A distinct integer value is assigned for every speaker within
    /// the audio. This field specifies which one of those speakers was detected to
    /// have spoken this word. Value ranges from '1' to diarization_speaker_count.
    /// speaker_tag is set if enable_speaker_diarization = 'true' and only in the
    /// top alternative.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SpeakerTag {
      get { return speakerTag_; }
      set {
        speakerTag_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as WordInfo);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(WordInfo other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(StartTime, other.StartTime)) return false;
      if (!object.Equals(EndTime, other.EndTime)) return false;
      if (Word != other.Word) return false;
      if (SpeakerTag != other.SpeakerTag) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (startTime_ != null) hash ^= StartTime.GetHashCode();
      if (endTime_ != null) hash ^= EndTime.GetHashCode();
      if (Word.Length != 0) hash ^= Word.GetHashCode();
      if (SpeakerTag != 0) hash ^= SpeakerTag.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      output.WriteRawMessage(this);
    #else
      if (startTime_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartTime);
      }
      if (endTime_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndTime);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (SpeakerTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(SpeakerTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalWriteTo(ref pb::WriteContext output) {
      if (startTime_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StartTime);
      }
      if (endTime_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(EndTime);
      }
      if (Word.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(Word);
      }
      if (SpeakerTag != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(SpeakerTag);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(ref output);
      }
    }
    #endif

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (startTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StartTime);
      }
      if (endTime_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(EndTime);
      }
      if (Word.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Word);
      }
      if (SpeakerTag != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SpeakerTag);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(WordInfo other) {
      if (other == null) {
        return;
      }
      if (other.startTime_ != null) {
        if (startTime_ == null) {
          StartTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        StartTime.MergeFrom(other.StartTime);
      }
      if (other.endTime_ != null) {
        if (endTime_ == null) {
          EndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
        }
        EndTime.MergeFrom(other.EndTime);
      }
      if (other.Word.Length != 0) {
        Word = other.Word;
      }
      if (other.SpeakerTag != 0) {
        SpeakerTag = other.SpeakerTag;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
      input.ReadRawMessage(this);
    #else
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            if (startTime_ == null) {
              StartTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartTime);
            break;
          }
          case 18: {
            if (endTime_ == null) {
              EndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndTime);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 40: {
            SpeakerTag = input.ReadInt32();
            break;
          }
        }
      }
    #endif
    }

    #if !GOOGLE_PROTOBUF_REFSTRUCT_COMPATIBILITY_MODE
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    void pb::IBufferMessage.InternalMergeFrom(ref pb::ParseContext input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, ref input);
            break;
          case 10: {
            if (startTime_ == null) {
              StartTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(StartTime);
            break;
          }
          case 18: {
            if (endTime_ == null) {
              EndTime = new global::Google.Protobuf.WellKnownTypes.Duration();
            }
            input.ReadMessage(EndTime);
            break;
          }
          case 26: {
            Word = input.ReadString();
            break;
          }
          case 40: {
            SpeakerTag = input.ReadInt32();
            break;
          }
        }
      }
    }
    #endif

  }

  #endregion

}

#endregion Designer generated code
