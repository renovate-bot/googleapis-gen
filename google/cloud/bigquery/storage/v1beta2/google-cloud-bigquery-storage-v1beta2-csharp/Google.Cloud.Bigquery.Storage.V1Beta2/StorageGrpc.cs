// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: google/cloud/bigquery/storage/v1beta2/storage.proto
// </auto-generated>
// Original file comments:
// Copyright 2021 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
#pragma warning disable 0414, 1591
#region Designer generated code

using grpc = global::Grpc.Core;

namespace Google.Cloud.Bigquery.Storage.V1Beta2 {
  /// <summary>
  /// BigQuery Read API.
  ///
  /// The Read API can be used to read data from BigQuery.
  ///
  /// New code should use the v1 Read API going forward, if they don't use Write
  /// API at the same time.
  /// </summary>
  public static partial class BigQueryRead
  {
    static readonly string __ServiceName = "google.cloud.bigquery.storage.v1beta2.BigQueryRead";

    static void __Helper_SerializeMessage(global::Google.Protobuf.IMessage message, grpc::SerializationContext context)
    {
      #if !GRPC_DISABLE_PROTOBUF_BUFFER_SERIALIZATION
      if (message is global::Google.Protobuf.IBufferMessage)
      {
        context.SetPayloadLength(message.CalculateSize());
        global::Google.Protobuf.MessageExtensions.WriteTo(message, context.GetBufferWriter());
        context.Complete();
        return;
      }
      #endif
      context.Complete(global::Google.Protobuf.MessageExtensions.ToByteArray(message));
    }

    static class __Helper_MessageCache<T>
    {
      public static readonly bool IsBufferMessage = global::System.Reflection.IntrospectionExtensions.GetTypeInfo(typeof(global::Google.Protobuf.IBufferMessage)).IsAssignableFrom(typeof(T));
    }

    static T __Helper_DeserializeMessage<T>(grpc::DeserializationContext context, global::Google.Protobuf.MessageParser<T> parser) where T : global::Google.Protobuf.IMessage<T>
    {
      #if !GRPC_DISABLE_PROTOBUF_BUFFER_SERIALIZATION
      if (__Helper_MessageCache<T>.IsBufferMessage)
      {
        return parser.ParseFrom(context.PayloadAsReadOnlySequence());
      }
      #endif
      return parser.ParseFrom(context.PayloadAsNewBuffer());
    }

    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_CreateReadSessionRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession> __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadSession = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadRowsRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadRowsResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_SplitReadStreamRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_SplitReadStreamResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse.Parser));

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession> __Method_CreateReadSession = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession>(
        grpc::MethodType.Unary,
        __ServiceName,
        "CreateReadSession",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_CreateReadSessionRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadSession);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse> __Method_ReadRows = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse>(
        grpc::MethodType.ServerStreaming,
        __ServiceName,
        "ReadRows",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadRowsRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_ReadRowsResponse);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse> __Method_SplitReadStream = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "SplitReadStream",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_SplitReadStreamRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_SplitReadStreamResponse);

    /// <summary>Service descriptor</summary>
    public static global::Google.Protobuf.Reflection.ServiceDescriptor Descriptor
    {
      get { return global::Google.Cloud.Bigquery.Storage.V1Beta2.StorageReflection.Descriptor.Services[0]; }
    }

    /// <summary>Base class for server-side implementations of BigQueryRead</summary>
    [grpc::BindServiceMethod(typeof(BigQueryRead), "BindService")]
    public abstract partial class BigQueryReadBase
    {
      /// <summary>
      /// Creates a new read session. A read session divides the contents of a
      /// BigQuery table into one or more streams, which can then be used to read
      /// data from the table. The read session also specifies properties of the
      /// data to be read, such as a list of columns or a push-down filter describing
      /// the rows to be returned.
      ///
      /// A particular row can be read by at most one stream. When the caller has
      /// reached the end of each stream in the session, then all the data in the
      /// table has been read.
      ///
      /// Data is assigned to each stream such that roughly the same number of
      /// rows can be read from each stream. Because the server-side unit for
      /// assigning data is collections of rows, the API does not guarantee that
      /// each stream will return the same number or rows. Additionally, the
      /// limits are enforced based on the number of pre-filtered rows, so some
      /// filters can lead to lopsided assignments.
      ///
      /// Read sessions automatically expire 6 hours after they are created and do
      /// not require manual clean-up by the caller.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession> CreateReadSession(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Reads rows from the stream in the format prescribed by the ReadSession.
      /// Each response contains one or more table rows, up to a maximum of 100 MiB
      /// per response; read requests which attempt to read individual rows larger
      /// than 100 MiB will fail.
      ///
      /// Each request also returns a set of stream statistics reflecting the current
      /// state of the stream.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="responseStream">Used for sending responses back to the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>A task indicating completion of the handler.</returns>
      public virtual global::System.Threading.Tasks.Task ReadRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest request, grpc::IServerStreamWriter<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse> responseStream, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Splits a given `ReadStream` into two `ReadStream` objects. These
      /// `ReadStream` objects are referred to as the primary and the residual
      /// streams of the split. The original `ReadStream` can still be read from in
      /// the same manner as before. Both of the returned `ReadStream` objects can
      /// also be read from, and the rows returned by both child streams will be
      /// the same as the rows read from the original stream.
      ///
      /// Moreover, the two child streams will be allocated back-to-back in the
      /// original `ReadStream`. Concretely, it is guaranteed that for streams
      /// original, primary, and residual, that original[0-j] = primary[0-j] and
      /// original[j-n] = residual[0-m] once the streams have been read to
      /// completion.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse> SplitReadStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

    }

    /// <summary>Client for BigQueryRead</summary>
    public partial class BigQueryReadClient : grpc::ClientBase<BigQueryReadClient>
    {
      /// <summary>Creates a new client for BigQueryRead</summary>
      /// <param name="channel">The channel to use to make remote calls.</param>
      public BigQueryReadClient(grpc::ChannelBase channel) : base(channel)
      {
      }
      /// <summary>Creates a new client for BigQueryRead that uses a custom <c>CallInvoker</c>.</summary>
      /// <param name="callInvoker">The callInvoker to use to make remote calls.</param>
      public BigQueryReadClient(grpc::CallInvoker callInvoker) : base(callInvoker)
      {
      }
      /// <summary>Protected parameterless constructor to allow creation of test doubles.</summary>
      protected BigQueryReadClient() : base()
      {
      }
      /// <summary>Protected constructor to allow creation of configured clients.</summary>
      /// <param name="configuration">The client configuration.</param>
      protected BigQueryReadClient(ClientBaseConfiguration configuration) : base(configuration)
      {
      }

      /// <summary>
      /// Creates a new read session. A read session divides the contents of a
      /// BigQuery table into one or more streams, which can then be used to read
      /// data from the table. The read session also specifies properties of the
      /// data to be read, such as a list of columns or a push-down filter describing
      /// the rows to be returned.
      ///
      /// A particular row can be read by at most one stream. When the caller has
      /// reached the end of each stream in the session, then all the data in the
      /// table has been read.
      ///
      /// Data is assigned to each stream such that roughly the same number of
      /// rows can be read from each stream. Because the server-side unit for
      /// assigning data is collections of rows, the API does not guarantee that
      /// each stream will return the same number or rows. Additionally, the
      /// limits are enforced based on the number of pre-filtered rows, so some
      /// filters can lead to lopsided assignments.
      ///
      /// Read sessions automatically expire 6 hours after they are created and do
      /// not require manual clean-up by the caller.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession CreateReadSession(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateReadSession(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Creates a new read session. A read session divides the contents of a
      /// BigQuery table into one or more streams, which can then be used to read
      /// data from the table. The read session also specifies properties of the
      /// data to be read, such as a list of columns or a push-down filter describing
      /// the rows to be returned.
      ///
      /// A particular row can be read by at most one stream. When the caller has
      /// reached the end of each stream in the session, then all the data in the
      /// table has been read.
      ///
      /// Data is assigned to each stream such that roughly the same number of
      /// rows can be read from each stream. Because the server-side unit for
      /// assigning data is collections of rows, the API does not guarantee that
      /// each stream will return the same number or rows. Additionally, the
      /// limits are enforced based on the number of pre-filtered rows, so some
      /// filters can lead to lopsided assignments.
      ///
      /// Read sessions automatically expire 6 hours after they are created and do
      /// not require manual clean-up by the caller.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession CreateReadSession(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_CreateReadSession, null, options, request);
      }
      /// <summary>
      /// Creates a new read session. A read session divides the contents of a
      /// BigQuery table into one or more streams, which can then be used to read
      /// data from the table. The read session also specifies properties of the
      /// data to be read, such as a list of columns or a push-down filter describing
      /// the rows to be returned.
      ///
      /// A particular row can be read by at most one stream. When the caller has
      /// reached the end of each stream in the session, then all the data in the
      /// table has been read.
      ///
      /// Data is assigned to each stream such that roughly the same number of
      /// rows can be read from each stream. Because the server-side unit for
      /// assigning data is collections of rows, the API does not guarantee that
      /// each stream will return the same number or rows. Additionally, the
      /// limits are enforced based on the number of pre-filtered rows, so some
      /// filters can lead to lopsided assignments.
      ///
      /// Read sessions automatically expire 6 hours after they are created and do
      /// not require manual clean-up by the caller.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession> CreateReadSessionAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateReadSessionAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Creates a new read session. A read session divides the contents of a
      /// BigQuery table into one or more streams, which can then be used to read
      /// data from the table. The read session also specifies properties of the
      /// data to be read, such as a list of columns or a push-down filter describing
      /// the rows to be returned.
      ///
      /// A particular row can be read by at most one stream. When the caller has
      /// reached the end of each stream in the session, then all the data in the
      /// table has been read.
      ///
      /// Data is assigned to each stream such that roughly the same number of
      /// rows can be read from each stream. Because the server-side unit for
      /// assigning data is collections of rows, the API does not guarantee that
      /// each stream will return the same number or rows. Additionally, the
      /// limits are enforced based on the number of pre-filtered rows, so some
      /// filters can lead to lopsided assignments.
      ///
      /// Read sessions automatically expire 6 hours after they are created and do
      /// not require manual clean-up by the caller.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession> CreateReadSessionAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_CreateReadSession, null, options, request);
      }
      /// <summary>
      /// Reads rows from the stream in the format prescribed by the ReadSession.
      /// Each response contains one or more table rows, up to a maximum of 100 MiB
      /// per response; read requests which attempt to read individual rows larger
      /// than 100 MiB will fail.
      ///
      /// Each request also returns a set of stream statistics reflecting the current
      /// state of the stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncServerStreamingCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse> ReadRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return ReadRows(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Reads rows from the stream in the format prescribed by the ReadSession.
      /// Each response contains one or more table rows, up to a maximum of 100 MiB
      /// per response; read requests which attempt to read individual rows larger
      /// than 100 MiB will fail.
      ///
      /// Each request also returns a set of stream statistics reflecting the current
      /// state of the stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncServerStreamingCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse> ReadRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncServerStreamingCall(__Method_ReadRows, null, options, request);
      }
      /// <summary>
      /// Splits a given `ReadStream` into two `ReadStream` objects. These
      /// `ReadStream` objects are referred to as the primary and the residual
      /// streams of the split. The original `ReadStream` can still be read from in
      /// the same manner as before. Both of the returned `ReadStream` objects can
      /// also be read from, and the rows returned by both child streams will be
      /// the same as the rows read from the original stream.
      ///
      /// Moreover, the two child streams will be allocated back-to-back in the
      /// original `ReadStream`. Concretely, it is guaranteed that for streams
      /// original, primary, and residual, that original[0-j] = primary[0-j] and
      /// original[j-n] = residual[0-m] once the streams have been read to
      /// completion.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse SplitReadStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return SplitReadStream(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Splits a given `ReadStream` into two `ReadStream` objects. These
      /// `ReadStream` objects are referred to as the primary and the residual
      /// streams of the split. The original `ReadStream` can still be read from in
      /// the same manner as before. Both of the returned `ReadStream` objects can
      /// also be read from, and the rows returned by both child streams will be
      /// the same as the rows read from the original stream.
      ///
      /// Moreover, the two child streams will be allocated back-to-back in the
      /// original `ReadStream`. Concretely, it is guaranteed that for streams
      /// original, primary, and residual, that original[0-j] = primary[0-j] and
      /// original[j-n] = residual[0-m] once the streams have been read to
      /// completion.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse SplitReadStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_SplitReadStream, null, options, request);
      }
      /// <summary>
      /// Splits a given `ReadStream` into two `ReadStream` objects. These
      /// `ReadStream` objects are referred to as the primary and the residual
      /// streams of the split. The original `ReadStream` can still be read from in
      /// the same manner as before. Both of the returned `ReadStream` objects can
      /// also be read from, and the rows returned by both child streams will be
      /// the same as the rows read from the original stream.
      ///
      /// Moreover, the two child streams will be allocated back-to-back in the
      /// original `ReadStream`. Concretely, it is guaranteed that for streams
      /// original, primary, and residual, that original[0-j] = primary[0-j] and
      /// original[j-n] = residual[0-m] once the streams have been read to
      /// completion.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse> SplitReadStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return SplitReadStreamAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Splits a given `ReadStream` into two `ReadStream` objects. These
      /// `ReadStream` objects are referred to as the primary and the residual
      /// streams of the split. The original `ReadStream` can still be read from in
      /// the same manner as before. Both of the returned `ReadStream` objects can
      /// also be read from, and the rows returned by both child streams will be
      /// the same as the rows read from the original stream.
      ///
      /// Moreover, the two child streams will be allocated back-to-back in the
      /// original `ReadStream`. Concretely, it is guaranteed that for streams
      /// original, primary, and residual, that original[0-j] = primary[0-j] and
      /// original[j-n] = residual[0-m] once the streams have been read to
      /// completion.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse> SplitReadStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_SplitReadStream, null, options, request);
      }
      /// <summary>Creates a new instance of client from given <c>ClientBaseConfiguration</c>.</summary>
      protected override BigQueryReadClient NewInstance(ClientBaseConfiguration configuration)
      {
        return new BigQueryReadClient(configuration);
      }
    }

    /// <summary>Creates service definition that can be registered with a server</summary>
    /// <param name="serviceImpl">An object implementing the server-side handling logic.</param>
    public static grpc::ServerServiceDefinition BindService(BigQueryReadBase serviceImpl)
    {
      return grpc::ServerServiceDefinition.CreateBuilder()
          .AddMethod(__Method_CreateReadSession, serviceImpl.CreateReadSession)
          .AddMethod(__Method_ReadRows, serviceImpl.ReadRows)
          .AddMethod(__Method_SplitReadStream, serviceImpl.SplitReadStream).Build();
    }

    /// <summary>Register service method with a service binder with or without implementation. Useful when customizing the  service binding logic.
    /// Note: this method is part of an experimental API that can change or be removed without any prior notice.</summary>
    /// <param name="serviceBinder">Service methods will be bound by calling <c>AddMethod</c> on this object.</param>
    /// <param name="serviceImpl">An object implementing the server-side handling logic.</param>
    public static void BindService(grpc::ServiceBinderBase serviceBinder, BigQueryReadBase serviceImpl)
    {
      serviceBinder.AddMethod(__Method_CreateReadSession, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateReadSessionRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadSession>(serviceImpl.CreateReadSession));
      serviceBinder.AddMethod(__Method_ReadRows, serviceImpl == null ? null : new grpc::ServerStreamingServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.ReadRowsResponse>(serviceImpl.ReadRows));
      serviceBinder.AddMethod(__Method_SplitReadStream, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.SplitReadStreamResponse>(serviceImpl.SplitReadStream));
    }

  }
  /// <summary>
  /// BigQuery Write API.
  ///
  /// The Write API can be used to write data to BigQuery.
  /// </summary>
  public static partial class BigQueryWrite
  {
    static readonly string __ServiceName = "google.cloud.bigquery.storage.v1beta2.BigQueryWrite";

    static void __Helper_SerializeMessage(global::Google.Protobuf.IMessage message, grpc::SerializationContext context)
    {
      #if !GRPC_DISABLE_PROTOBUF_BUFFER_SERIALIZATION
      if (message is global::Google.Protobuf.IBufferMessage)
      {
        context.SetPayloadLength(message.CalculateSize());
        global::Google.Protobuf.MessageExtensions.WriteTo(message, context.GetBufferWriter());
        context.Complete();
        return;
      }
      #endif
      context.Complete(global::Google.Protobuf.MessageExtensions.ToByteArray(message));
    }

    static class __Helper_MessageCache<T>
    {
      public static readonly bool IsBufferMessage = global::System.Reflection.IntrospectionExtensions.GetTypeInfo(typeof(global::Google.Protobuf.IBufferMessage)).IsAssignableFrom(typeof(T));
    }

    static T __Helper_DeserializeMessage<T>(grpc::DeserializationContext context, global::Google.Protobuf.MessageParser<T> parser) where T : global::Google.Protobuf.IMessage<T>
    {
      #if !GRPC_DISABLE_PROTOBUF_BUFFER_SERIALIZATION
      if (__Helper_MessageCache<T>.IsBufferMessage)
      {
        return parser.ParseFrom(context.PayloadAsReadOnlySequence());
      }
      #endif
      return parser.ParseFrom(context.PayloadAsNewBuffer());
    }

    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_CreateWriteStreamRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> __Marshaller_google_cloud_bigquery_storage_v1beta2_WriteStream = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_AppendRowsRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_AppendRowsResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_GetWriteStreamRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_FinalizeWriteStreamRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_FinalizeWriteStreamResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_BatchCommitWriteStreamsRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_BatchCommitWriteStreamsResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest> __Marshaller_google_cloud_bigquery_storage_v1beta2_FlushRowsRequest = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest.Parser));
    static readonly grpc::Marshaller<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse> __Marshaller_google_cloud_bigquery_storage_v1beta2_FlushRowsResponse = grpc::Marshallers.Create(__Helper_SerializeMessage, context => __Helper_DeserializeMessage(context, global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse.Parser));

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> __Method_CreateWriteStream = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream>(
        grpc::MethodType.Unary,
        __ServiceName,
        "CreateWriteStream",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_CreateWriteStreamRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_WriteStream);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse> __Method_AppendRows = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse>(
        grpc::MethodType.DuplexStreaming,
        __ServiceName,
        "AppendRows",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_AppendRowsRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_AppendRowsResponse);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> __Method_GetWriteStream = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream>(
        grpc::MethodType.Unary,
        __ServiceName,
        "GetWriteStream",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_GetWriteStreamRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_WriteStream);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse> __Method_FinalizeWriteStream = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "FinalizeWriteStream",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_FinalizeWriteStreamRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_FinalizeWriteStreamResponse);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse> __Method_BatchCommitWriteStreams = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "BatchCommitWriteStreams",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_BatchCommitWriteStreamsRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_BatchCommitWriteStreamsResponse);

    static readonly grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse> __Method_FlushRows = new grpc::Method<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "FlushRows",
        __Marshaller_google_cloud_bigquery_storage_v1beta2_FlushRowsRequest,
        __Marshaller_google_cloud_bigquery_storage_v1beta2_FlushRowsResponse);

    /// <summary>Service descriptor</summary>
    public static global::Google.Protobuf.Reflection.ServiceDescriptor Descriptor
    {
      get { return global::Google.Cloud.Bigquery.Storage.V1Beta2.StorageReflection.Descriptor.Services[1]; }
    }

    /// <summary>Base class for server-side implementations of BigQueryWrite</summary>
    [grpc::BindServiceMethod(typeof(BigQueryWrite), "BindService")]
    public abstract partial class BigQueryWriteBase
    {
      /// <summary>
      /// Creates a write stream to the given table.
      /// Additionally, every table has a special COMMITTED stream named '_default'
      /// to which data can be written. This stream doesn't need to be created using
      /// CreateWriteStream. It is a stream that can be used simultaneously by any
      /// number of clients. Data written to this stream is considered committed as
      /// soon as an acknowledgement is received.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> CreateWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Appends data to the given stream.
      ///
      /// If `offset` is specified, the `offset` is checked against the end of
      /// stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
      /// attempt is made to append to an offset beyond the current end of the stream
      /// or `ALREADY_EXISTS` if user provids an `offset` that has already been
      /// written to. User can retry with adjusted offset within the same RPC
      /// stream. If `offset` is not specified, append happens at the end of the
      /// stream.
      ///
      /// The response contains the offset at which the append happened. Responses
      /// are received in the same order in which requests are sent. There will be
      /// one response for each successful request. If the `offset` is not set in
      /// response, it means append didn't happen due to some errors. If one request
      /// fails, all the subsequent requests will also fail until a success request
      /// is made again.
      ///
      /// If the stream is of `PENDING` type, data will only be available for read
      /// operations after the stream is committed.
      /// </summary>
      /// <param name="requestStream">Used for reading requests from the client.</param>
      /// <param name="responseStream">Used for sending responses back to the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>A task indicating completion of the handler.</returns>
      public virtual global::System.Threading.Tasks.Task AppendRows(grpc::IAsyncStreamReader<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest> requestStream, grpc::IServerStreamWriter<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse> responseStream, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Gets a write stream.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> GetWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Finalize a write stream so that no new data can be appended to the
      /// stream. Finalize is not supported on the '_default' stream.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse> FinalizeWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Atomically commits a group of `PENDING` streams that belong to the same
      /// `parent` table.
      /// Streams must be finalized before commit and cannot be committed multiple
      /// times. Once a stream is committed, data in the stream becomes available
      /// for read operations.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse> BatchCommitWriteStreams(global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

      /// <summary>
      /// Flushes rows to a BUFFERED stream.
      /// If users are appending rows to BUFFERED stream, flush operation is
      /// required in order for the rows to become available for reading. A
      /// Flush operation flushes up to any previously flushed offset in a BUFFERED
      /// stream, to the offset specified in the request.
      /// Flush is not supported on the _default stream, since it is not BUFFERED.
      /// </summary>
      /// <param name="request">The request received from the client.</param>
      /// <param name="context">The context of the server-side call handler being invoked.</param>
      /// <returns>The response to send back to the client (wrapped by a task).</returns>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse> FlushRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest request, grpc::ServerCallContext context)
      {
        throw new grpc::RpcException(new grpc::Status(grpc::StatusCode.Unimplemented, ""));
      }

    }

    /// <summary>Client for BigQueryWrite</summary>
    public partial class BigQueryWriteClient : grpc::ClientBase<BigQueryWriteClient>
    {
      /// <summary>Creates a new client for BigQueryWrite</summary>
      /// <param name="channel">The channel to use to make remote calls.</param>
      public BigQueryWriteClient(grpc::ChannelBase channel) : base(channel)
      {
      }
      /// <summary>Creates a new client for BigQueryWrite that uses a custom <c>CallInvoker</c>.</summary>
      /// <param name="callInvoker">The callInvoker to use to make remote calls.</param>
      public BigQueryWriteClient(grpc::CallInvoker callInvoker) : base(callInvoker)
      {
      }
      /// <summary>Protected parameterless constructor to allow creation of test doubles.</summary>
      protected BigQueryWriteClient() : base()
      {
      }
      /// <summary>Protected constructor to allow creation of configured clients.</summary>
      /// <param name="configuration">The client configuration.</param>
      protected BigQueryWriteClient(ClientBaseConfiguration configuration) : base(configuration)
      {
      }

      /// <summary>
      /// Creates a write stream to the given table.
      /// Additionally, every table has a special COMMITTED stream named '_default'
      /// to which data can be written. This stream doesn't need to be created using
      /// CreateWriteStream. It is a stream that can be used simultaneously by any
      /// number of clients. Data written to this stream is considered committed as
      /// soon as an acknowledgement is received.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream CreateWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateWriteStream(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Creates a write stream to the given table.
      /// Additionally, every table has a special COMMITTED stream named '_default'
      /// to which data can be written. This stream doesn't need to be created using
      /// CreateWriteStream. It is a stream that can be used simultaneously by any
      /// number of clients. Data written to this stream is considered committed as
      /// soon as an acknowledgement is received.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream CreateWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_CreateWriteStream, null, options, request);
      }
      /// <summary>
      /// Creates a write stream to the given table.
      /// Additionally, every table has a special COMMITTED stream named '_default'
      /// to which data can be written. This stream doesn't need to be created using
      /// CreateWriteStream. It is a stream that can be used simultaneously by any
      /// number of clients. Data written to this stream is considered committed as
      /// soon as an acknowledgement is received.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> CreateWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateWriteStreamAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Creates a write stream to the given table.
      /// Additionally, every table has a special COMMITTED stream named '_default'
      /// to which data can be written. This stream doesn't need to be created using
      /// CreateWriteStream. It is a stream that can be used simultaneously by any
      /// number of clients. Data written to this stream is considered committed as
      /// soon as an acknowledgement is received.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> CreateWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_CreateWriteStream, null, options, request);
      }
      /// <summary>
      /// Appends data to the given stream.
      ///
      /// If `offset` is specified, the `offset` is checked against the end of
      /// stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
      /// attempt is made to append to an offset beyond the current end of the stream
      /// or `ALREADY_EXISTS` if user provids an `offset` that has already been
      /// written to. User can retry with adjusted offset within the same RPC
      /// stream. If `offset` is not specified, append happens at the end of the
      /// stream.
      ///
      /// The response contains the offset at which the append happened. Responses
      /// are received in the same order in which requests are sent. There will be
      /// one response for each successful request. If the `offset` is not set in
      /// response, it means append didn't happen due to some errors. If one request
      /// fails, all the subsequent requests will also fail until a success request
      /// is made again.
      ///
      /// If the stream is of `PENDING` type, data will only be available for read
      /// operations after the stream is committed.
      /// </summary>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncDuplexStreamingCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse> AppendRows(grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return AppendRows(new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Appends data to the given stream.
      ///
      /// If `offset` is specified, the `offset` is checked against the end of
      /// stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
      /// attempt is made to append to an offset beyond the current end of the stream
      /// or `ALREADY_EXISTS` if user provids an `offset` that has already been
      /// written to. User can retry with adjusted offset within the same RPC
      /// stream. If `offset` is not specified, append happens at the end of the
      /// stream.
      ///
      /// The response contains the offset at which the append happened. Responses
      /// are received in the same order in which requests are sent. There will be
      /// one response for each successful request. If the `offset` is not set in
      /// response, it means append didn't happen due to some errors. If one request
      /// fails, all the subsequent requests will also fail until a success request
      /// is made again.
      ///
      /// If the stream is of `PENDING` type, data will only be available for read
      /// operations after the stream is committed.
      /// </summary>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncDuplexStreamingCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse> AppendRows(grpc::CallOptions options)
      {
        return CallInvoker.AsyncDuplexStreamingCall(__Method_AppendRows, null, options);
      }
      /// <summary>
      /// Gets a write stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream GetWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return GetWriteStream(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Gets a write stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream GetWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_GetWriteStream, null, options, request);
      }
      /// <summary>
      /// Gets a write stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> GetWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return GetWriteStreamAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Gets a write stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream> GetWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_GetWriteStream, null, options, request);
      }
      /// <summary>
      /// Finalize a write stream so that no new data can be appended to the
      /// stream. Finalize is not supported on the '_default' stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse FinalizeWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return FinalizeWriteStream(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Finalize a write stream so that no new data can be appended to the
      /// stream. Finalize is not supported on the '_default' stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse FinalizeWriteStream(global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_FinalizeWriteStream, null, options, request);
      }
      /// <summary>
      /// Finalize a write stream so that no new data can be appended to the
      /// stream. Finalize is not supported on the '_default' stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse> FinalizeWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return FinalizeWriteStreamAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Finalize a write stream so that no new data can be appended to the
      /// stream. Finalize is not supported on the '_default' stream.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse> FinalizeWriteStreamAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_FinalizeWriteStream, null, options, request);
      }
      /// <summary>
      /// Atomically commits a group of `PENDING` streams that belong to the same
      /// `parent` table.
      /// Streams must be finalized before commit and cannot be committed multiple
      /// times. Once a stream is committed, data in the stream becomes available
      /// for read operations.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse BatchCommitWriteStreams(global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return BatchCommitWriteStreams(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Atomically commits a group of `PENDING` streams that belong to the same
      /// `parent` table.
      /// Streams must be finalized before commit and cannot be committed multiple
      /// times. Once a stream is committed, data in the stream becomes available
      /// for read operations.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse BatchCommitWriteStreams(global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_BatchCommitWriteStreams, null, options, request);
      }
      /// <summary>
      /// Atomically commits a group of `PENDING` streams that belong to the same
      /// `parent` table.
      /// Streams must be finalized before commit and cannot be committed multiple
      /// times. Once a stream is committed, data in the stream becomes available
      /// for read operations.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse> BatchCommitWriteStreamsAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return BatchCommitWriteStreamsAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Atomically commits a group of `PENDING` streams that belong to the same
      /// `parent` table.
      /// Streams must be finalized before commit and cannot be committed multiple
      /// times. Once a stream is committed, data in the stream becomes available
      /// for read operations.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse> BatchCommitWriteStreamsAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_BatchCommitWriteStreams, null, options, request);
      }
      /// <summary>
      /// Flushes rows to a BUFFERED stream.
      /// If users are appending rows to BUFFERED stream, flush operation is
      /// required in order for the rows to become available for reading. A
      /// Flush operation flushes up to any previously flushed offset in a BUFFERED
      /// stream, to the offset specified in the request.
      /// Flush is not supported on the _default stream, since it is not BUFFERED.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse FlushRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return FlushRows(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Flushes rows to a BUFFERED stream.
      /// If users are appending rows to BUFFERED stream, flush operation is
      /// required in order for the rows to become available for reading. A
      /// Flush operation flushes up to any previously flushed offset in a BUFFERED
      /// stream, to the offset specified in the request.
      /// Flush is not supported on the _default stream, since it is not BUFFERED.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse FlushRows(global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_FlushRows, null, options, request);
      }
      /// <summary>
      /// Flushes rows to a BUFFERED stream.
      /// If users are appending rows to BUFFERED stream, flush operation is
      /// required in order for the rows to become available for reading. A
      /// Flush operation flushes up to any previously flushed offset in a BUFFERED
      /// stream, to the offset specified in the request.
      /// Flush is not supported on the _default stream, since it is not BUFFERED.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse> FlushRowsAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return FlushRowsAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Flushes rows to a BUFFERED stream.
      /// If users are appending rows to BUFFERED stream, flush operation is
      /// required in order for the rows to become available for reading. A
      /// Flush operation flushes up to any previously flushed offset in a BUFFERED
      /// stream, to the offset specified in the request.
      /// Flush is not supported on the _default stream, since it is not BUFFERED.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse> FlushRowsAsync(global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_FlushRows, null, options, request);
      }
      /// <summary>Creates a new instance of client from given <c>ClientBaseConfiguration</c>.</summary>
      protected override BigQueryWriteClient NewInstance(ClientBaseConfiguration configuration)
      {
        return new BigQueryWriteClient(configuration);
      }
    }

    /// <summary>Creates service definition that can be registered with a server</summary>
    /// <param name="serviceImpl">An object implementing the server-side handling logic.</param>
    public static grpc::ServerServiceDefinition BindService(BigQueryWriteBase serviceImpl)
    {
      return grpc::ServerServiceDefinition.CreateBuilder()
          .AddMethod(__Method_CreateWriteStream, serviceImpl.CreateWriteStream)
          .AddMethod(__Method_AppendRows, serviceImpl.AppendRows)
          .AddMethod(__Method_GetWriteStream, serviceImpl.GetWriteStream)
          .AddMethod(__Method_FinalizeWriteStream, serviceImpl.FinalizeWriteStream)
          .AddMethod(__Method_BatchCommitWriteStreams, serviceImpl.BatchCommitWriteStreams)
          .AddMethod(__Method_FlushRows, serviceImpl.FlushRows).Build();
    }

    /// <summary>Register service method with a service binder with or without implementation. Useful when customizing the  service binding logic.
    /// Note: this method is part of an experimental API that can change or be removed without any prior notice.</summary>
    /// <param name="serviceBinder">Service methods will be bound by calling <c>AddMethod</c> on this object.</param>
    /// <param name="serviceImpl">An object implementing the server-side handling logic.</param>
    public static void BindService(grpc::ServiceBinderBase serviceBinder, BigQueryWriteBase serviceImpl)
    {
      serviceBinder.AddMethod(__Method_CreateWriteStream, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.CreateWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream>(serviceImpl.CreateWriteStream));
      serviceBinder.AddMethod(__Method_AppendRows, serviceImpl == null ? null : new grpc::DuplexStreamingServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.AppendRowsResponse>(serviceImpl.AppendRows));
      serviceBinder.AddMethod(__Method_GetWriteStream, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.GetWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.WriteStream>(serviceImpl.GetWriteStream));
      serviceBinder.AddMethod(__Method_FinalizeWriteStream, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FinalizeWriteStreamResponse>(serviceImpl.FinalizeWriteStream));
      serviceBinder.AddMethod(__Method_BatchCommitWriteStreams, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.BatchCommitWriteStreamsResponse>(serviceImpl.BatchCommitWriteStreams));
      serviceBinder.AddMethod(__Method_FlushRows, serviceImpl == null ? null : new grpc::UnaryServerMethod<global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsRequest, global::Google.Cloud.Bigquery.Storage.V1Beta2.FlushRowsResponse>(serviceImpl.FlushRows));
    }

  }
}
#endregion
